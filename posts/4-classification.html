<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-12-04">
<meta name="description" content="In which we overview classification, applying it to a simple and then a more complicated dataset.">

<title>blog - Classification</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
if (typeof require !== 'undefined') {
require.undef("plotly");
requirejs.config({
    paths: {
        'plotly': ['https://cdn.plot.ly/plotly-2.32.0.min']
    }
});
require(['plotly'], function(Plotly) {
    window._Plotly = Plotly;
});
}
</script>


  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#learning-theory" id="toc-learning-theory" class="nav-link active" data-scroll-target="#learning-theory">Learning theory</a></li>
  <li><a href="#simple-dataset" id="toc-simple-dataset" class="nav-link" data-scroll-target="#simple-dataset">Simple dataset</a>
  <ul class="collapse">
  <li><a href="#naive-bayes" id="toc-naive-bayes" class="nav-link" data-scroll-target="#naive-bayes">Naive Bayes</a></li>
  <li><a href="#iris" id="toc-iris" class="nav-link" data-scroll-target="#iris">Iris</a></li>
  <li><a href="#evaluation" id="toc-evaluation" class="nav-link" data-scroll-target="#evaluation">Evaluation</a></li>
  </ul></li>
  <li><a href="#complex-dataset" id="toc-complex-dataset" class="nav-link" data-scroll-target="#complex-dataset">Complex dataset</a>
  <ul class="collapse">
  <li><a href="#mnist" id="toc-mnist" class="nav-link" data-scroll-target="#mnist">MNIST</a></li>
  <li><a href="#neural-network" id="toc-neural-network" class="nav-link" data-scroll-target="#neural-network">Neural network</a></li>
  <li><a href="#evaluation-1" id="toc-evaluation-1" class="nav-link" data-scroll-target="#evaluation-1">Evaluation</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/adidenkova/blog/blob/main/posts/4-classification.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Classification</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
  <div class="quarto-categories">
    <div class="quarto-category">Classification</div>
    <div class="quarto-category">Supervised learning</div>
    <div class="quarto-category">Learning theory</div>
    <div class="quarto-category">Naive Bayes</div>
    <div class="quarto-category">Neural network</div>
  </div>
  </div>

<div>
  <div class="description">
    In which we overview classification, applying it to a simple and then a more complicated dataset.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 4, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<!-- Describe the algorithms, theories, and applications related to machine learning/data mining for classification. -->
<p>Classification is a <strong>supervised learning</strong> method, much like <a href="../posts/3-regression.html">regression</a>. Unlike <a href="../posts/3-regression.html">regression</a>, it predicts features not continuous, but categorical and unordered. Such features then denote the <em>class</em> that each point belongs to - not unlike assigning a cluster. Indeed, both classification and <a href="../posts/2-clustering.html">clustering</a> work with data that is typically sufficiently distinct, that they must then learn to separate into groups. The crucial difference is that classification is given the <em>labels</em> of the training data, which it then must generalize to the <em>testing</em> set.</p>
<p>Various considerations and regimes for classification exist:</p>
<ul>
<li><strong>Offline vs.&nbsp;online:</strong> most algorithms are of the former type, where they are given data first and queried only after all such data has been made available. On the contrary, others such as <a href="../posts/1-probability.html#multi-armed-bandits">bandit algorithms</a> and <a href="../posts/5-anomaly.html#changepoint-detection">changepoint detection</a> learn only by making mistakes on the already evaluated examples. While such algorithms commonly relate to reinforcement learning, they could be applied to all kinds of areas - including clustering and classification.</li>
<li><strong>Eager vs.&nbsp;lazy:</strong> out of the offline algorithms, some may choose not to even process given data, instead only looking at it when being queried. Such algorithms are known as lazy; one example would be <span class="math inline">\(k\)</span>-nearest neighbors classification.</li>
<li><strong>Binary/multi-class/multi-label:</strong> the most straightforward type of classification is distinguishing between two classes, or equivalently answering a yes/no question. Many algorithms extend to output one of many clusters, yet some others need nontrivial modifications. Lastly, specially-generalized algorithms exist that can assign multiple class labels to one point.</li>
<li><strong>Balanced/imbalanced:</strong> many algorithms assume that the ground truth clusters are of approximately the same size. Yet, many datasets have an abundance of one label compared to another - such as when detecting a rare disease. In such cases, certain assumptions may break down; for instance, having a dataset with <span class="math inline">\(95%\)</span> labels class <span class="math inline">\(A\)</span> and <span class="math inline">\(5%\)</span> class <span class="math inline">\(B\)</span> makes the trivial algorithm that always picks <span class="math inline">\(A\)</span> perform with <span class="math inline">\(95%\)</span> accuracy. As such, the “random” baseline is now <span class="math inline">\(95%\)</span> instead of <span class="math inline">\(50%\)</span>. This imbalance can force even the more powerful models to shy away from predicting the rare class, stumping learning. To combat this, one can apply strategies such as <em>oversampling</em> and <em>undersampling</em>.</li>
</ul>
<div id="fig-classification" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-classification-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-classification-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: A comparison of various classification methods. Image credit: <a href="https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html">sklearn</a>.
</figcaption>
</figure>
</div>
<section id="learning-theory" class="level2">
<h2 class="anchored" data-anchor-id="learning-theory">Learning theory</h2>
<p>Before we dive into specific algorithms and their applications, it would be useful to review the mathematical theory behind clustering (and machine learning more broadly). This is a fairly mature and encompassing theory, being an umbrella term for many important concepts such as VC theory, online learning, and PAC learning.</p>
<p>Suppose we have some unknown target function <span class="math inline">\(f^\dagger: \mathcal{X} \to \mathcal{Y}\)</span> that maps data to labels. We wish to model this function, but the only information we have about it is how it acts on the data. In addition, we only have a finite amount of training examples <span class="math inline">\(D = \{(x_1,y_1), \ldots (x_n,y_n)\} \sim \mathcal{D}\)</span>. We wish to approximate <span class="math inline">\(f^\dagger\)</span> via some other function <span class="math inline">\(\hat{f}\)</span> that not only maps each <span class="math inline">\(x_i \mapsto y_i\)</span>, but also <em>generalizes</em> to doing this for any <span class="math inline">\((x,y) \sim \mathcal{D}\)</span>. The approximation <span class="math inline">\(\hat{f}\)</span> will instead map <span class="math inline">\(x\)</span> to some <span class="math inline">\(\hat{y}\)</span>, and to measure the quality of this output, we will choose a <em>loss function</em> <span class="math inline">\(L(\hat{y},y)\)</span> of interest (often, the indicator function). More formally, we can evaluate an approximation <span class="math inline">\(f\)</span> via its <strong>risk</strong>, defined as <span id="eq-risk"><span class="math display">\[
R(f) = \mathbb{E}[L(f(x), y)] = \int L(f(x), y) \mathrm{dP}(x,y)\ .
\tag{1}\]</span></span></p>
<p>This metric choice may seem a bit odd, but necessary since sampling <span class="math inline">\((x,y)\)</span> from <span class="math inline">\(\mathcal{D}\)</span> means they are <a href="../posts/1-probability.html#random-variables">random variables</a>. In addition, we can’t even evaluate the above quantity since we don’t know <span class="math inline">\(\mathcal{D}\)</span> in the first place.</p>
<p>So, what to do? Instead, we just evaluate on the available data to obtain the <strong>empirical risk</strong> of <span class="math inline">\(f\)</span>, <span id="eq-empirical"><span class="math display">\[
R_\text{emp}(f) = \frac{1}{n} \sum_{i=1}^n L(f(x_i), y_i)\ .
\tag{2}\]</span></span></p>
<p>Outside of learning theory, risk and empirical risk may be referred to as testing and training loss.</p>
<p>The next question is how to find our approximation <span class="math inline">\(\hat{f}\)</span>. To do this, we need to start with picking a <em>hypothesis class</em> <span class="math inline">\(\mathcal{H}\)</span>, representing all possible models (and parameters) we could potentially end up with. We then compute <span id="eq-fhat"><span class="math display">\[
\hat{f} = \arg\min_{f \in \mathcal{H}} R_\text{emp}(f)\ ,
\tag{3}\]</span></span></p>
<p>and hope that it is close to <span id="eq-fstar"><span class="math display">\[
f^* = \arg\min_{f \in \mathcal{H}} R(f)\ .
\tag{4}\]</span></span></p>
<p>So, at this point we have already accumulated a couple potential sources of error. The following picture helps to illustrate them.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://hermite.jp/img/201802/estimation-approximation-error.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Image credit: <a href="https://hermite.jp/post/erm-optimal-convergence-rate/">Han Bao</a>.</figcaption>
</figure>
</div>
<p>When restricting ourselves to <span class="math inline">\(\mathcal{H}\)</span>, we demoted the best attainable function from <span class="math inline">\(f^\dagger\)</span> to <span class="math inline">\(f^*\)</span> resulting in an <span class="red">approximation error</span>. Then, since we only have a limited-size dataset, the best possible approximation to <span class="math inline">\(f^*\)</span> we can get is <span class="math inline">\(\hat{f}\)</span>, which incurs an <span class="blue">estimation error</span>.</p>
<p>So, what should we do to minimize these errors? The quality of the <span class="red">approximation</span> primarily depends on the chosen hypothesis class - making it include more complex models decreases the error. As for <span class="blue">estimation</span>, there are various bounds that relate it to parameters; though, the common theme is that generalization is improved with a larger <span class="math inline">\(|D| = n\)</span> and a smaller <span class="math inline">\(|\mathcal{H}|\)</span>. However, the latter condition seems almost directly contradictory to the one we need for better approximations, i.e., more complex models. The following graphic illustrates this tradeoff (occasionally also referred to as the underfitting/overfitting or bias/variance tradeoff)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="tradeoff.svg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Tradeoff of estimation and approximation errors.</figcaption>
</figure>
</div>
<p>So, is all lost? Not exactly; the conditions aren’t directly contradictory - we could minimize both by finding an <span class="math inline">\(\mathcal{H}\)</span> that contains as few models as possible, but the ones it contains are accurate at modeling the desired data. This is a task easier said than done, as we need to carefully discard all unnecessary models, while making sure the important ones are retained. The search for such a hypothesis class <span class="math inline">\(\mathcal{H}\)</span> is perhaps what drives the creation of many various types of machine learning algorithms.</p>
</section>
<section id="simple-dataset" class="level2">
<h2 class="anchored" data-anchor-id="simple-dataset">Simple dataset</h2>
<p>We start our evaluation by analyzing one of the algorithms featured in <a href="#fig-classification" class="quarto-xref">Figure&nbsp;1</a> (second column from the right), <strong>Naive Bayes</strong>. We can see that it performs fairly well on the artificial data, separating it sufficiently but also generalizing smoothly to outside of the provided domain. Let’s see how it fares against data with a couple more dimensions.</p>
<section id="naive-bayes" class="level3">
<h3 class="anchored" data-anchor-id="naive-bayes">Naive Bayes</h3>
<p>But first, a small introduction of the algorithm itself (mostly based on its <a href="https://en.wikipedia.org/wiki/Naive_Bayes_classifier">Wikipedia</a> article). As evident by its name, it relies on Bayes’ theorem <span id="eq-bayes"><span class="math display">\[
\mathrm{P}(k | x) = \frac{\mathrm{P}(x | k) \mathrm{P}(k)}{\mathrm{P}(x)}\ ,
\tag{5}\]</span></span></p>
<p>where <span class="math inline">\(k\)</span> is the event of the data <span class="math inline">\(x = x_1, \ldots x_n\)</span> belonging to class <span class="math inline">\(k\)</span>. Naturally, the quantity on the left of <a href="#eq-bayes" class="quarto-xref">Equation&nbsp;5</a> is exactly what would let us perform classification, so we use the quantity on the right (ignoring the denominator as it doesn’t depend on <span class="math inline">\(k\)</span>) to compute it. The numerator is equal to <span class="math inline">\(\mathrm{P}(x, k)\)</span>, which we may by chain rule write as <span id="eq-chain"><span class="math display">\[
\mathrm{P}(x_1, \ldots, x_n, k)
= \mathrm{P}(x_1 | x_2, \ldots x_n, k) \mathrm{P}(x_2 | x_3, \ldots x_n, k) \dots \mathrm{P}(x_n, k) \mathrm{P}(k)\ .
\tag{6}\]</span></span></p>
<p>To go further, we need an assumption - the <em>conditional independence</em> (a.k.a. naive Bayes) assumption. Specifically, we have that <span class="math inline">\(\mathrm{P}(x_i | x_{i+1}, \ldots, x_n, k) = \mathrm{P} (x_i | k)\)</span>, and thus <span id="eq-naive"><span class="math display">\[
\mathrm{P}(k | x) \propto \mathrm{P}(k, x) = \mathrm{P}(k) \prod_{i=1}^n \mathrm{P}(x_i | k)\ .
\tag{7}\]</span></span></p>
</section>
<section id="iris" class="level3">
<h3 class="anchored" data-anchor-id="iris">Iris</h3>
<p>I don’t think this dataset really needs an introduction, you’ve almost certainly seen it before. In any case, it has four features that describe the length and width of flower petals and sepals, as seen below.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://sebastianraschka.com/images/blog/2015/principal_component_analysis_files/iris.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption>Image credit: <a href="https://sebastianraschka.com/Articles/2015_pca_in_3_steps.html">Sebastian Raschka</a>.</figcaption>
</figure>
</div>
<p>The question is; could you tell which of the following three flowers you’re looking at?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://machinelearninghd.com/wp-content/uploads/2021/03/iris-dataset.png" class="img-fluid figure-img"></p>
<figcaption>Image credit: <a href="https://machinelearninghd.com/iris-dataset-uci-machine-learning-repository-project/">Gaurav Chauhan</a>.</figcaption>
</figure>
</div>
<p>Except, you wouldn’t be actually looking at the flowers but instead just those four numbers. It may instead be easier to see the difference if the values are plotted laterally. Below, petal length is denoted by size and petal width by transparency.</p>
<div id="62bbab38" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>2D scatterplot of iris</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> px.data.iris().drop(<span class="st">'species_id'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter(iris, x<span class="op">=</span><span class="st">"sepal_width"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, size<span class="op">=</span><span class="st">"petal_length"</span>,</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"species"</span>, marginal_y<span class="op">=</span><span class="st">"violin"</span>, marginal_x<span class="op">=</span><span class="st">"violin"</span>,</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    template<span class="op">=</span><span class="st">"simple_white"</span>, hover_data<span class="op">=</span>[<span class="st">'petal_width'</span>])</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>op <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>(<span class="fl">0.5</span>, <span class="fl">1.0</span>)).fit_transform(</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    iris[<span class="st">'petal_width'</span>].values[:, <span class="va">None</span>])</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(opacity<span class="op">=</span>op), selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>))</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>fig.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>                            <div id="9ca2fa4e-fd25-49ce-beeb-5d7d0df3f52d" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("9ca2fa4e-fd25-49ce-beeb-5d7d0df3f52d")) {                    Plotly.newPlot(                        "9ca2fa4e-fd25-49ce-beeb-5d7d0df3f52d",                        [{"customdata":[[0.2],[0.2],[0.2],[0.2],[0.2],[0.4],[0.3],[0.2],[0.2],[0.1],[0.2],[0.2],[0.1],[0.1],[0.2],[0.4],[0.4],[0.3],[0.3],[0.3],[0.2],[0.4],[0.2],[0.5],[0.2],[0.2],[0.4],[0.2],[0.2],[0.2],[0.2],[0.4],[0.1],[0.2],[0.1],[0.2],[0.2],[0.1],[0.2],[0.2],[0.3],[0.3],[0.2],[0.6],[0.4],[0.3],[0.2],[0.2],[0.2],[0.2]],"hovertemplate":"species=setosa\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_length=%{marker.size}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"setosa","marker":{"color":"#1F77B4","size":[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1.0,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.5,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4],"sizemode":"area","sizeref":0.01725,"symbol":"circle","opacity":[[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5],[0.5208333333333334],[0.5625],[0.5625],[0.5416666666666667],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5833333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.6041666666666667],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.7708333333333334],[0.7916666666666667],[0.7916666666666667],[0.75],[0.7916666666666667],[0.75],[0.8125],[0.6875],[0.75],[0.7708333333333334],[0.6875],[0.7916666666666667],[0.6875],[0.7708333333333334],[0.75],[0.7708333333333334],[0.7916666666666667],[0.6875],[0.7916666666666667],[0.7083333333333334],[0.8541666666666667],[0.75],[0.7916666666666667],[0.7291666666666667],[0.75],[0.7708333333333334],[0.7708333333333334],[0.8333333333333334],[0.7916666666666667],[0.6875],[0.7083333333333334],[0.6875],[0.7291666666666667],[0.8125],[0.7916666666666667],[0.8125],[0.7916666666666667],[0.75],[0.75],[0.75],[0.7291666666666667],[0.7708333333333334],[0.7291666666666667],[0.6875],[0.75],[0.7291666666666667],[0.75],[0.75],[0.7083333333333334],[0.75],[1.0],[0.875],[0.9166666666666667],[0.8541666666666667],[0.9375],[0.9166666666666667],[0.8333333333333334],[0.8541666666666667],[0.8541666666666667],[1.0],[0.8958333333333334],[0.875],[0.9166666666666667],[0.8958333333333334],[0.9791666666666667],[0.9583333333333333],[0.8541666666666667],[0.9375],[0.9583333333333333],[0.7916666666666667],[0.9583333333333333],[0.8958333333333334],[0.8958333333333334],[0.8541666666666667],[0.9166666666666667],[0.8541666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.8125],[0.875],[0.8958333333333334],[0.9375],[0.7916666666666667],[0.7708333333333334],[0.9583333333333333],[0.9791666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.9791666666666667],[0.9583333333333333],[0.875],[0.9583333333333333],[1.0],[0.9583333333333333],[0.875],[0.8958333333333334],[0.9583333333333333],[0.8541666666666667]]},"mode":"markers","name":"setosa","orientation":"v","showlegend":true,"x":[3.5,3.0,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3.0,3.0,4.0,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3.0,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.1,3.0,3.4,3.5,2.3,3.2,3.5,3.8,3.0,3.8,3.2,3.7,3.3],"xaxis":"x","y":[5.1,4.9,4.7,4.6,5.0,5.4,4.6,5.0,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5.0,5.0,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5.0,5.5,4.9,4.4,5.1,5.0,4.5,4.4,5.0,5.1,4.8,5.1,4.6,5.3,5.0],"yaxis":"y","type":"scatter"},{"alignmentgroup":"True","customdata":[[0.2],[0.2],[0.2],[0.2],[0.2],[0.4],[0.3],[0.2],[0.2],[0.1],[0.2],[0.2],[0.1],[0.1],[0.2],[0.4],[0.4],[0.3],[0.3],[0.3],[0.2],[0.4],[0.2],[0.5],[0.2],[0.2],[0.4],[0.2],[0.2],[0.2],[0.2],[0.4],[0.1],[0.2],[0.1],[0.2],[0.2],[0.1],[0.2],[0.2],[0.3],[0.3],[0.2],[0.6],[0.4],[0.3],[0.2],[0.2],[0.2],[0.2]],"hovertemplate":"species=setosa\u003cbr\u003esepal_width=%{x}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"setosa","marker":{"color":"#1F77B4","symbol":"circle"},"name":"setosa","offsetgroup":"setosa","scalegroup":"x","showlegend":false,"x":[3.5,3.0,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3.0,3.0,4.0,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3.0,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.1,3.0,3.4,3.5,2.3,3.2,3.5,3.8,3.0,3.8,3.2,3.7,3.3],"xaxis":"x3","yaxis":"y3","type":"violin"},{"alignmentgroup":"True","customdata":[[0.2],[0.2],[0.2],[0.2],[0.2],[0.4],[0.3],[0.2],[0.2],[0.1],[0.2],[0.2],[0.1],[0.1],[0.2],[0.4],[0.4],[0.3],[0.3],[0.3],[0.2],[0.4],[0.2],[0.5],[0.2],[0.2],[0.4],[0.2],[0.2],[0.2],[0.2],[0.4],[0.1],[0.2],[0.1],[0.2],[0.2],[0.1],[0.2],[0.2],[0.3],[0.3],[0.2],[0.6],[0.4],[0.3],[0.2],[0.2],[0.2],[0.2]],"hovertemplate":"species=setosa\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"setosa","marker":{"color":"#1F77B4","symbol":"circle"},"name":"setosa","offsetgroup":"setosa","scalegroup":"y","showlegend":false,"xaxis":"x2","y":[5.1,4.9,4.7,4.6,5.0,5.4,4.6,5.0,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5.0,5.0,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5.0,5.5,4.9,4.4,5.1,5.0,4.5,4.4,5.0,5.1,4.8,5.1,4.6,5.3,5.0],"yaxis":"y2","type":"violin"},{"customdata":[[1.4],[1.5],[1.5],[1.3],[1.5],[1.3],[1.6],[1.0],[1.3],[1.4],[1.0],[1.5],[1.0],[1.4],[1.3],[1.4],[1.5],[1.0],[1.5],[1.1],[1.8],[1.3],[1.5],[1.2],[1.3],[1.4],[1.4],[1.7],[1.5],[1.0],[1.1],[1.0],[1.2],[1.6],[1.5],[1.6],[1.5],[1.3],[1.3],[1.3],[1.2],[1.4],[1.2],[1.0],[1.3],[1.2],[1.3],[1.3],[1.1],[1.3]],"hovertemplate":"species=versicolor\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_length=%{marker.size}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor","marker":{"color":"#FF7F0E","size":[4.7,4.5,4.9,4.0,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4.0,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4.0,4.9,4.7,4.3,4.4,4.8,5.0,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4.0,4.4,4.6,4.0,3.3,4.2,4.2,4.2,4.3,3.0,4.1],"sizemode":"area","sizeref":0.01725,"symbol":"circle","opacity":[[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5],[0.5208333333333334],[0.5625],[0.5625],[0.5416666666666667],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5833333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.6041666666666667],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.7708333333333334],[0.7916666666666667],[0.7916666666666667],[0.75],[0.7916666666666667],[0.75],[0.8125],[0.6875],[0.75],[0.7708333333333334],[0.6875],[0.7916666666666667],[0.6875],[0.7708333333333334],[0.75],[0.7708333333333334],[0.7916666666666667],[0.6875],[0.7916666666666667],[0.7083333333333334],[0.8541666666666667],[0.75],[0.7916666666666667],[0.7291666666666667],[0.75],[0.7708333333333334],[0.7708333333333334],[0.8333333333333334],[0.7916666666666667],[0.6875],[0.7083333333333334],[0.6875],[0.7291666666666667],[0.8125],[0.7916666666666667],[0.8125],[0.7916666666666667],[0.75],[0.75],[0.75],[0.7291666666666667],[0.7708333333333334],[0.7291666666666667],[0.6875],[0.75],[0.7291666666666667],[0.75],[0.75],[0.7083333333333334],[0.75],[1.0],[0.875],[0.9166666666666667],[0.8541666666666667],[0.9375],[0.9166666666666667],[0.8333333333333334],[0.8541666666666667],[0.8541666666666667],[1.0],[0.8958333333333334],[0.875],[0.9166666666666667],[0.8958333333333334],[0.9791666666666667],[0.9583333333333333],[0.8541666666666667],[0.9375],[0.9583333333333333],[0.7916666666666667],[0.9583333333333333],[0.8958333333333334],[0.8958333333333334],[0.8541666666666667],[0.9166666666666667],[0.8541666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.8125],[0.875],[0.8958333333333334],[0.9375],[0.7916666666666667],[0.7708333333333334],[0.9583333333333333],[0.9791666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.9791666666666667],[0.9583333333333333],[0.875],[0.9583333333333333],[1.0],[0.9583333333333333],[0.875],[0.8958333333333334],[0.9583333333333333],[0.8541666666666667]]},"mode":"markers","name":"versicolor","orientation":"v","showlegend":true,"x":[3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2.0,3.0,2.2,2.9,2.9,3.1,3.0,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3.0,2.8,3.0,2.9,2.6,2.4,2.4,2.7,2.7,3.0,3.4,3.1,2.3,3.0,2.5,2.6,3.0,2.6,2.3,2.7,3.0,2.9,2.9,2.5,2.8],"xaxis":"x","y":[7.0,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5.0,5.9,6.0,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6.0,5.7,5.5,5.5,5.8,6.0,5.4,6.0,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5.0,5.6,5.7,5.7,6.2,5.1,5.7],"yaxis":"y","type":"scatter"},{"alignmentgroup":"True","customdata":[[1.4],[1.5],[1.5],[1.3],[1.5],[1.3],[1.6],[1.0],[1.3],[1.4],[1.0],[1.5],[1.0],[1.4],[1.3],[1.4],[1.5],[1.0],[1.5],[1.1],[1.8],[1.3],[1.5],[1.2],[1.3],[1.4],[1.4],[1.7],[1.5],[1.0],[1.1],[1.0],[1.2],[1.6],[1.5],[1.6],[1.5],[1.3],[1.3],[1.3],[1.2],[1.4],[1.2],[1.0],[1.3],[1.2],[1.3],[1.3],[1.1],[1.3]],"hovertemplate":"species=versicolor\u003cbr\u003esepal_width=%{x}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor","marker":{"color":"#FF7F0E","symbol":"circle"},"name":"versicolor","offsetgroup":"versicolor","scalegroup":"x","showlegend":false,"x":[3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2.0,3.0,2.2,2.9,2.9,3.1,3.0,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3.0,2.8,3.0,2.9,2.6,2.4,2.4,2.7,2.7,3.0,3.4,3.1,2.3,3.0,2.5,2.6,3.0,2.6,2.3,2.7,3.0,2.9,2.9,2.5,2.8],"xaxis":"x3","yaxis":"y3","type":"violin"},{"alignmentgroup":"True","customdata":[[1.4],[1.5],[1.5],[1.3],[1.5],[1.3],[1.6],[1.0],[1.3],[1.4],[1.0],[1.5],[1.0],[1.4],[1.3],[1.4],[1.5],[1.0],[1.5],[1.1],[1.8],[1.3],[1.5],[1.2],[1.3],[1.4],[1.4],[1.7],[1.5],[1.0],[1.1],[1.0],[1.2],[1.6],[1.5],[1.6],[1.5],[1.3],[1.3],[1.3],[1.2],[1.4],[1.2],[1.0],[1.3],[1.2],[1.3],[1.3],[1.1],[1.3]],"hovertemplate":"species=versicolor\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor","marker":{"color":"#FF7F0E","symbol":"circle"},"name":"versicolor","offsetgroup":"versicolor","scalegroup":"y","showlegend":false,"xaxis":"x2","y":[7.0,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5.0,5.9,6.0,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6.0,5.7,5.5,5.5,5.8,6.0,5.4,6.0,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5.0,5.6,5.7,5.7,6.2,5.1,5.7],"yaxis":"y2","type":"violin"},{"customdata":[[2.5],[1.9],[2.1],[1.8],[2.2],[2.1],[1.7],[1.8],[1.8],[2.5],[2.0],[1.9],[2.1],[2.0],[2.4],[2.3],[1.8],[2.2],[2.3],[1.5],[2.3],[2.0],[2.0],[1.8],[2.1],[1.8],[1.8],[1.8],[2.1],[1.6],[1.9],[2.0],[2.2],[1.5],[1.4],[2.3],[2.4],[1.8],[1.8],[2.1],[2.4],[2.3],[1.9],[2.3],[2.5],[2.3],[1.9],[2.0],[2.3],[1.8]],"hovertemplate":"species=virginica\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_length=%{marker.size}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica","marker":{"color":"#2CA02C","size":[6.0,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5.0,5.1,5.3,5.5,6.7,6.9,5.0,5.7,4.9,6.7,4.9,5.7,6.0,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5.0,5.2,5.4,5.1],"sizemode":"area","sizeref":0.01725,"symbol":"circle","opacity":[[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5],[0.5208333333333334],[0.5625],[0.5625],[0.5416666666666667],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5833333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.6041666666666667],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.7708333333333334],[0.7916666666666667],[0.7916666666666667],[0.75],[0.7916666666666667],[0.75],[0.8125],[0.6875],[0.75],[0.7708333333333334],[0.6875],[0.7916666666666667],[0.6875],[0.7708333333333334],[0.75],[0.7708333333333334],[0.7916666666666667],[0.6875],[0.7916666666666667],[0.7083333333333334],[0.8541666666666667],[0.75],[0.7916666666666667],[0.7291666666666667],[0.75],[0.7708333333333334],[0.7708333333333334],[0.8333333333333334],[0.7916666666666667],[0.6875],[0.7083333333333334],[0.6875],[0.7291666666666667],[0.8125],[0.7916666666666667],[0.8125],[0.7916666666666667],[0.75],[0.75],[0.75],[0.7291666666666667],[0.7708333333333334],[0.7291666666666667],[0.6875],[0.75],[0.7291666666666667],[0.75],[0.75],[0.7083333333333334],[0.75],[1.0],[0.875],[0.9166666666666667],[0.8541666666666667],[0.9375],[0.9166666666666667],[0.8333333333333334],[0.8541666666666667],[0.8541666666666667],[1.0],[0.8958333333333334],[0.875],[0.9166666666666667],[0.8958333333333334],[0.9791666666666667],[0.9583333333333333],[0.8541666666666667],[0.9375],[0.9583333333333333],[0.7916666666666667],[0.9583333333333333],[0.8958333333333334],[0.8958333333333334],[0.8541666666666667],[0.9166666666666667],[0.8541666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.8125],[0.875],[0.8958333333333334],[0.9375],[0.7916666666666667],[0.7708333333333334],[0.9583333333333333],[0.9791666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.9791666666666667],[0.9583333333333333],[0.875],[0.9583333333333333],[1.0],[0.9583333333333333],[0.875],[0.8958333333333334],[0.9583333333333333],[0.8541666666666667]]},"mode":"markers","name":"virginica","orientation":"v","showlegend":true,"x":[3.3,2.7,3.0,2.9,3.0,3.0,2.5,2.9,2.5,3.6,3.2,2.7,3.0,2.5,2.8,3.2,3.0,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3.0,2.8,3.0,2.8,3.8,2.8,2.8,2.6,3.0,3.4,3.1,3.0,3.1,3.1,3.1,2.7,3.2,3.3,3.0,2.5,3.0,3.4,3.0],"xaxis":"x","y":[6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6.0,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6.0,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],"yaxis":"y","type":"scatter"},{"alignmentgroup":"True","customdata":[[2.5],[1.9],[2.1],[1.8],[2.2],[2.1],[1.7],[1.8],[1.8],[2.5],[2.0],[1.9],[2.1],[2.0],[2.4],[2.3],[1.8],[2.2],[2.3],[1.5],[2.3],[2.0],[2.0],[1.8],[2.1],[1.8],[1.8],[1.8],[2.1],[1.6],[1.9],[2.0],[2.2],[1.5],[1.4],[2.3],[2.4],[1.8],[1.8],[2.1],[2.4],[2.3],[1.9],[2.3],[2.5],[2.3],[1.9],[2.0],[2.3],[1.8]],"hovertemplate":"species=virginica\u003cbr\u003esepal_width=%{x}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica","marker":{"color":"#2CA02C","symbol":"circle"},"name":"virginica","offsetgroup":"virginica","scalegroup":"x","showlegend":false,"x":[3.3,2.7,3.0,2.9,3.0,3.0,2.5,2.9,2.5,3.6,3.2,2.7,3.0,2.5,2.8,3.2,3.0,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3.0,2.8,3.0,2.8,3.8,2.8,2.8,2.6,3.0,3.4,3.1,3.0,3.1,3.1,3.1,2.7,3.2,3.3,3.0,2.5,3.0,3.4,3.0],"xaxis":"x3","yaxis":"y3","type":"violin"},{"alignmentgroup":"True","customdata":[[2.5],[1.9],[2.1],[1.8],[2.2],[2.1],[1.7],[1.8],[1.8],[2.5],[2.0],[1.9],[2.1],[2.0],[2.4],[2.3],[1.8],[2.2],[2.3],[1.5],[2.3],[2.0],[2.0],[1.8],[2.1],[1.8],[1.8],[1.8],[2.1],[1.6],[1.9],[2.0],[2.2],[1.5],[1.4],[2.3],[2.4],[1.8],[1.8],[2.1],[2.4],[2.3],[1.9],[2.3],[2.5],[2.3],[1.9],[2.0],[2.3],[1.8]],"hovertemplate":"species=virginica\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica","marker":{"color":"#2CA02C","symbol":"circle"},"name":"virginica","offsetgroup":"virginica","scalegroup":"y","showlegend":false,"xaxis":"x2","y":[6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6.0,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6.0,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],"yaxis":"y2","type":"violin"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"rgb(36,36,36)"},"error_y":{"color":"rgb(36,36,36)"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"baxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2d"}],"histogram":[{"marker":{"line":{"color":"white","width":0.6}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"rgb(237,237,237)"},"line":{"color":"white"}},"header":{"fill":{"color":"rgb(217,217,217)"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"colorscale":{"diverging":[[0.0,"rgb(103,0,31)"],[0.1,"rgb(178,24,43)"],[0.2,"rgb(214,96,77)"],[0.3,"rgb(244,165,130)"],[0.4,"rgb(253,219,199)"],[0.5,"rgb(247,247,247)"],[0.6,"rgb(209,229,240)"],[0.7,"rgb(146,197,222)"],[0.8,"rgb(67,147,195)"],[0.9,"rgb(33,102,172)"],[1.0,"rgb(5,48,97)"]],"sequential":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"sequentialminus":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]]},"colorway":["#1F77B4","#FF7F0E","#2CA02C","#D62728","#9467BD","#8C564B","#E377C2","#7F7F7F","#BCBD22","#17BECF"],"font":{"color":"rgb(36,36,36)"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","radialaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"zaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"}},"shapedefaults":{"fillcolor":"black","line":{"width":0},"opacity":0.3},"ternary":{"aaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"baxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","caxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"}}},"xaxis":{"anchor":"y","domain":[0.0,0.7363],"title":{"text":"sepal_width"}},"yaxis":{"anchor":"x","domain":[0.0,0.7326],"title":{"text":"sepal_length"}},"xaxis2":{"anchor":"y2","domain":[0.7413,1.0],"matches":"x2","showticklabels":false,"showline":false,"ticks":""},"yaxis2":{"anchor":"x2","domain":[0.0,0.7326],"matches":"y","showticklabels":false},"xaxis3":{"anchor":"y3","domain":[0.0,0.7363],"matches":"x","showticklabels":false},"yaxis3":{"anchor":"x3","domain":[0.7426,1.0],"matches":"y3","showticklabels":false,"showline":false,"ticks":""},"xaxis4":{"anchor":"y4","domain":[0.7413,1.0],"matches":"x2","showticklabels":false,"showline":false,"ticks":""},"yaxis4":{"anchor":"x4","domain":[0.7426,1.0],"matches":"y3","showticklabels":false,"showline":false,"ticks":""},"legend":{"title":{"text":"species"},"tracegroupgap":0,"itemsizing":"constant"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('9ca2fa4e-fd25-49ce-beeb-5d7d0df3f52d');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>Or, perhaps in a 3D plot that shows all four features (petal length is still marker size).</p>
<div id="4043b2b0" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>3D scatterplot of iris</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter_3d(iris, x<span class="op">=</span><span class="st">"sepal_width"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, z<span class="op">=</span><span class="st">"petal_width"</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span><span class="st">"petal_length"</span>, color<span class="op">=</span><span class="st">"species"</span>, template<span class="op">=</span><span class="st">"simple_white"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>fig.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>                            <div id="4cce24ec-b5fd-4cf6-a5ac-3782296c041e" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("4cce24ec-b5fd-4cf6-a5ac-3782296c041e")) {                    Plotly.newPlot(                        "4cce24ec-b5fd-4cf6-a5ac-3782296c041e",                        [{"hovertemplate":"species=setosa\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{z}\u003cbr\u003epetal_length=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"setosa","marker":{"color":"#1F77B4","size":[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1.0,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.5,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4],"sizemode":"area","sizeref":0.01725,"symbol":"circle"},"mode":"markers","name":"setosa","scene":"scene","showlegend":true,"x":[3.5,3.0,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3.0,3.0,4.0,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3.0,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.1,3.0,3.4,3.5,2.3,3.2,3.5,3.8,3.0,3.8,3.2,3.7,3.3],"y":[5.1,4.9,4.7,4.6,5.0,5.4,4.6,5.0,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5.0,5.0,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5.0,5.5,4.9,4.4,5.1,5.0,4.5,4.4,5.0,5.1,4.8,5.1,4.6,5.3,5.0],"z":[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.1,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2],"type":"scatter3d"},{"hovertemplate":"species=versicolor\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{z}\u003cbr\u003epetal_length=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor","marker":{"color":"#FF7F0E","size":[4.7,4.5,4.9,4.0,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4.0,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4.0,4.9,4.7,4.3,4.4,4.8,5.0,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4.0,4.4,4.6,4.0,3.3,4.2,4.2,4.2,4.3,3.0,4.1],"sizemode":"area","sizeref":0.01725,"symbol":"circle"},"mode":"markers","name":"versicolor","scene":"scene","showlegend":true,"x":[3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2.0,3.0,2.2,2.9,2.9,3.1,3.0,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3.0,2.8,3.0,2.9,2.6,2.4,2.4,2.7,2.7,3.0,3.4,3.1,2.3,3.0,2.5,2.6,3.0,2.6,2.3,2.7,3.0,2.9,2.9,2.5,2.8],"y":[7.0,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5.0,5.9,6.0,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6.0,5.7,5.5,5.5,5.8,6.0,5.4,6.0,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5.0,5.6,5.7,5.7,6.2,5.1,5.7],"z":[1.4,1.5,1.5,1.3,1.5,1.3,1.6,1.0,1.3,1.4,1.0,1.5,1.0,1.4,1.3,1.4,1.5,1.0,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1.0,1.1,1.0,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1.0,1.3,1.2,1.3,1.3,1.1,1.3],"type":"scatter3d"},{"hovertemplate":"species=virginica\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{z}\u003cbr\u003epetal_length=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica","marker":{"color":"#2CA02C","size":[6.0,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5.0,5.1,5.3,5.5,6.7,6.9,5.0,5.7,4.9,6.7,4.9,5.7,6.0,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5.0,5.2,5.4,5.1],"sizemode":"area","sizeref":0.01725,"symbol":"circle"},"mode":"markers","name":"virginica","scene":"scene","showlegend":true,"x":[3.3,2.7,3.0,2.9,3.0,3.0,2.5,2.9,2.5,3.6,3.2,2.7,3.0,2.5,2.8,3.2,3.0,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3.0,2.8,3.0,2.8,3.8,2.8,2.8,2.6,3.0,3.4,3.1,3.0,3.1,3.1,3.1,2.7,3.2,3.3,3.0,2.5,3.0,3.4,3.0],"y":[6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6.0,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6.0,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],"z":[2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2.0,1.9,2.1,2.0,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2.0,2.0,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2.0,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2.0,2.3,1.8],"type":"scatter3d"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"rgb(36,36,36)"},"error_y":{"color":"rgb(36,36,36)"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"baxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2d"}],"histogram":[{"marker":{"line":{"color":"white","width":0.6}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"rgb(237,237,237)"},"line":{"color":"white"}},"header":{"fill":{"color":"rgb(217,217,217)"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"colorscale":{"diverging":[[0.0,"rgb(103,0,31)"],[0.1,"rgb(178,24,43)"],[0.2,"rgb(214,96,77)"],[0.3,"rgb(244,165,130)"],[0.4,"rgb(253,219,199)"],[0.5,"rgb(247,247,247)"],[0.6,"rgb(209,229,240)"],[0.7,"rgb(146,197,222)"],[0.8,"rgb(67,147,195)"],[0.9,"rgb(33,102,172)"],[1.0,"rgb(5,48,97)"]],"sequential":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"sequentialminus":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]]},"colorway":["#1F77B4","#FF7F0E","#2CA02C","#D62728","#9467BD","#8C564B","#E377C2","#7F7F7F","#BCBD22","#17BECF"],"font":{"color":"rgb(36,36,36)"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","radialaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"zaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"}},"shapedefaults":{"fillcolor":"black","line":{"width":0},"opacity":0.3},"ternary":{"aaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"baxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","caxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"}}},"scene":{"domain":{"x":[0.0,1.0],"y":[0.0,1.0]},"xaxis":{"title":{"text":"sepal_width"}},"yaxis":{"title":{"text":"sepal_length"}},"zaxis":{"title":{"text":"petal_width"}}},"legend":{"title":{"text":"species"},"tracegroupgap":0,"itemsizing":"constant"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('4cce24ec-b5fd-4cf6-a5ac-3782296c041e');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>I don’t know about you, but some of the points between versicolor and virginia still seem pretty overlapping. Let’s see how the algorithm compares!</p>
</section>
<section id="evaluation" class="level3">
<h3 class="anchored" data-anchor-id="evaluation">Evaluation</h3>
<p>Lucky for us, Naive Bayes is a common algorithm with many implementations. We’ll be using one by <code>sklearn</code>.</p>
<div id="f80cfffe" class="cell" data-execution_count="3">
<details open="" class="code-fold">
<summary>Naive bayes classifier</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit and predict</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> iris.drop(<span class="st">'species'</span>, axis<span class="op">=</span><span class="dv">1</span>), iris[<span class="st">'species'</span>]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">5805</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> GaussianNB().fit(X_train, y_train)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>iris[<span class="st">'predict'</span>] <span class="op">=</span> nb.predict(X)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> nb.predict(X_test)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy:  </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy:  0.9467
Precision: 0.9444</code></pre>
</div>
</div>
<div id="576f57dd" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>Code for plotting the confusion matrix</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sn</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> iris[<span class="st">'species'</span>].unique()</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>conf <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>df_cm <span class="op">=</span> pd.DataFrame(conf, index<span class="op">=</span>names, columns<span class="op">=</span>names)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">4</span>,<span class="dv">3</span>))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>sn.heatmap(df_cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="4-classification_files/figure-html/cell-5-output-1.png" class="quarto-figure quarto-figure-center figure-img" width="332" height="263"></p>
</figure>
</div>
</div>
</div>
<p>From the above, we can gauge the performance as quite good - the algorithm only mislabels <span class="math inline">\(4\)</span> points out of a testing set of size <span class="math inline">\(75\)</span>, while being given a training set of only size <span class="math inline">\(75\)</span>.</p>
<p>Let’s see where it made mistakes. Predictions are denoted by outline colors, points where the inner color doesn’t match are mislabeled.</p>
<div id="979cc06b" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>2D scatterplot of iris &amp; predictions</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>fix <span class="op">=</span> {<span class="st">"circle"</span>: <span class="st">"#1F77B4"</span>, <span class="st">"diamond"</span>: <span class="st">"#FF7F0E"</span>, <span class="st">"square"</span>: <span class="st">"#2CA02C"</span>}</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter(iris, x<span class="op">=</span><span class="st">"sepal_width"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, size<span class="op">=</span><span class="st">"petal_length"</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"species"</span>, symbol<span class="op">=</span><span class="st">"predict"</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    template<span class="op">=</span><span class="st">"simple_white"</span>, hover_data<span class="op">=</span>[<span class="st">'petal_width'</span>])</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(opacity<span class="op">=</span>op), selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>))</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> symbol, color <span class="kw">in</span> fix.items():</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(line<span class="op">=</span><span class="bu">dict</span>(width<span class="op">=</span><span class="dv">3</span>, color<span class="op">=</span>color),</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>                      symbol<span class="op">=</span><span class="st">"circle"</span>),</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>                      selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>, marker_symbol<span class="op">=</span>symbol))</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>fig.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>                            <div id="3623da17-0f48-42f1-8bac-e38d3f8ed7d9" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("3623da17-0f48-42f1-8bac-e38d3f8ed7d9")) {                    Plotly.newPlot(                        "3623da17-0f48-42f1-8bac-e38d3f8ed7d9",                        [{"customdata":[[0.2],[0.2],[0.2],[0.2],[0.2],[0.4],[0.3],[0.2],[0.2],[0.1],[0.2],[0.2],[0.1],[0.1],[0.2],[0.4],[0.4],[0.3],[0.3],[0.3],[0.2],[0.4],[0.2],[0.5],[0.2],[0.2],[0.4],[0.2],[0.2],[0.2],[0.2],[0.4],[0.1],[0.2],[0.1],[0.2],[0.2],[0.1],[0.2],[0.2],[0.3],[0.3],[0.2],[0.6],[0.4],[0.3],[0.2],[0.2],[0.2],[0.2]],"hovertemplate":"species=setosa\u003cbr\u003epredict=setosa\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_length=%{marker.size}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"setosa, setosa","marker":{"color":"#1F77B4","size":[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1.0,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.5,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4],"sizemode":"area","sizeref":0.01725,"symbol":"circle","opacity":[[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5],[0.5208333333333334],[0.5625],[0.5625],[0.5416666666666667],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5833333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.6041666666666667],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.7708333333333334],[0.7916666666666667],[0.7916666666666667],[0.75],[0.7916666666666667],[0.75],[0.8125],[0.6875],[0.75],[0.7708333333333334],[0.6875],[0.7916666666666667],[0.6875],[0.7708333333333334],[0.75],[0.7708333333333334],[0.7916666666666667],[0.6875],[0.7916666666666667],[0.7083333333333334],[0.8541666666666667],[0.75],[0.7916666666666667],[0.7291666666666667],[0.75],[0.7708333333333334],[0.7708333333333334],[0.8333333333333334],[0.7916666666666667],[0.6875],[0.7083333333333334],[0.6875],[0.7291666666666667],[0.8125],[0.7916666666666667],[0.8125],[0.7916666666666667],[0.75],[0.75],[0.75],[0.7291666666666667],[0.7708333333333334],[0.7291666666666667],[0.6875],[0.75],[0.7291666666666667],[0.75],[0.75],[0.7083333333333334],[0.75],[1.0],[0.875],[0.9166666666666667],[0.8541666666666667],[0.9375],[0.9166666666666667],[0.8333333333333334],[0.8541666666666667],[0.8541666666666667],[1.0],[0.8958333333333334],[0.875],[0.9166666666666667],[0.8958333333333334],[0.9791666666666667],[0.9583333333333333],[0.8541666666666667],[0.9375],[0.9583333333333333],[0.7916666666666667],[0.9583333333333333],[0.8958333333333334],[0.8958333333333334],[0.8541666666666667],[0.9166666666666667],[0.8541666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.8125],[0.875],[0.8958333333333334],[0.9375],[0.7916666666666667],[0.7708333333333334],[0.9583333333333333],[0.9791666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.9791666666666667],[0.9583333333333333],[0.875],[0.9583333333333333],[1.0],[0.9583333333333333],[0.875],[0.8958333333333334],[0.9583333333333333],[0.8541666666666667]],"line":{"color":"#1F77B4","width":3}},"mode":"markers","name":"setosa, setosa","orientation":"v","showlegend":true,"x":[3.5,3.0,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3.0,3.0,4.0,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3.0,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.1,3.0,3.4,3.5,2.3,3.2,3.5,3.8,3.0,3.8,3.2,3.7,3.3],"xaxis":"x","y":[5.1,4.9,4.7,4.6,5.0,5.4,4.6,5.0,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5.0,5.0,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5.0,5.5,4.9,4.4,5.1,5.0,4.5,4.4,5.0,5.1,4.8,5.1,4.6,5.3,5.0],"yaxis":"y","type":"scatter"},{"customdata":[[1.4],[1.5],[1.5],[1.3],[1.5],[1.3],[1.6],[1.0],[1.3],[1.4],[1.0],[1.5],[1.0],[1.4],[1.3],[1.4],[1.5],[1.0],[1.5],[1.1],[1.3],[1.5],[1.2],[1.3],[1.4],[1.4],[1.5],[1.0],[1.1],[1.0],[1.2],[1.6],[1.5],[1.6],[1.5],[1.3],[1.3],[1.3],[1.2],[1.4],[1.2],[1.0],[1.3],[1.2],[1.3],[1.3],[1.1],[1.3]],"hovertemplate":"species=versicolor\u003cbr\u003epredict=versicolor\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_length=%{marker.size}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor, versicolor","marker":{"color":"#FF7F0E","size":[4.7,4.5,4.9,4.0,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4.0,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.0,4.9,4.7,4.3,4.4,4.8,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4.0,4.4,4.6,4.0,3.3,4.2,4.2,4.2,4.3,3.0,4.1],"sizemode":"area","sizeref":0.01725,"symbol":"circle","opacity":[[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5],[0.5208333333333334],[0.5625],[0.5625],[0.5416666666666667],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5833333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.6041666666666667],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.7708333333333334],[0.7916666666666667],[0.7916666666666667],[0.75],[0.7916666666666667],[0.75],[0.8125],[0.6875],[0.75],[0.7708333333333334],[0.6875],[0.7916666666666667],[0.6875],[0.7708333333333334],[0.75],[0.7708333333333334],[0.7916666666666667],[0.6875],[0.7916666666666667],[0.7083333333333334],[0.8541666666666667],[0.75],[0.7916666666666667],[0.7291666666666667],[0.75],[0.7708333333333334],[0.7708333333333334],[0.8333333333333334],[0.7916666666666667],[0.6875],[0.7083333333333334],[0.6875],[0.7291666666666667],[0.8125],[0.7916666666666667],[0.8125],[0.7916666666666667],[0.75],[0.75],[0.75],[0.7291666666666667],[0.7708333333333334],[0.7291666666666667],[0.6875],[0.75],[0.7291666666666667],[0.75],[0.75],[0.7083333333333334],[0.75],[1.0],[0.875],[0.9166666666666667],[0.8541666666666667],[0.9375],[0.9166666666666667],[0.8333333333333334],[0.8541666666666667],[0.8541666666666667],[1.0],[0.8958333333333334],[0.875],[0.9166666666666667],[0.8958333333333334],[0.9791666666666667],[0.9583333333333333],[0.8541666666666667],[0.9375],[0.9583333333333333],[0.7916666666666667],[0.9583333333333333],[0.8958333333333334],[0.8958333333333334],[0.8541666666666667],[0.9166666666666667],[0.8541666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.8125],[0.875],[0.8958333333333334],[0.9375],[0.7916666666666667],[0.7708333333333334],[0.9583333333333333],[0.9791666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.9791666666666667],[0.9583333333333333],[0.875],[0.9583333333333333],[1.0],[0.9583333333333333],[0.875],[0.8958333333333334],[0.9583333333333333],[0.8541666666666667]],"line":{"color":"#FF7F0E","width":3}},"mode":"markers","name":"versicolor, versicolor","orientation":"v","showlegend":true,"x":[3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2.0,3.0,2.2,2.9,2.9,3.1,3.0,2.7,2.2,2.5,2.8,2.5,2.8,2.9,3.0,2.8,2.9,2.6,2.4,2.4,2.7,2.7,3.0,3.4,3.1,2.3,3.0,2.5,2.6,3.0,2.6,2.3,2.7,3.0,2.9,2.9,2.5,2.8],"xaxis":"x","y":[7.0,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5.0,5.9,6.0,6.1,5.6,6.7,5.6,5.8,6.2,5.6,6.1,6.3,6.1,6.4,6.6,6.8,6.0,5.7,5.5,5.5,5.8,6.0,5.4,6.0,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5.0,5.6,5.7,5.7,6.2,5.1,5.7],"yaxis":"y","type":"scatter"},{"customdata":[[1.8],[1.7]],"hovertemplate":"species=versicolor\u003cbr\u003epredict=virginica\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_length=%{marker.size}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor, virginica","marker":{"color":"#FF7F0E","size":[4.8,5.0],"sizemode":"area","sizeref":0.01725,"symbol":"circle","opacity":[[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5],[0.5208333333333334],[0.5625],[0.5625],[0.5416666666666667],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5833333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.6041666666666667],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.7708333333333334],[0.7916666666666667],[0.7916666666666667],[0.75],[0.7916666666666667],[0.75],[0.8125],[0.6875],[0.75],[0.7708333333333334],[0.6875],[0.7916666666666667],[0.6875],[0.7708333333333334],[0.75],[0.7708333333333334],[0.7916666666666667],[0.6875],[0.7916666666666667],[0.7083333333333334],[0.8541666666666667],[0.75],[0.7916666666666667],[0.7291666666666667],[0.75],[0.7708333333333334],[0.7708333333333334],[0.8333333333333334],[0.7916666666666667],[0.6875],[0.7083333333333334],[0.6875],[0.7291666666666667],[0.8125],[0.7916666666666667],[0.8125],[0.7916666666666667],[0.75],[0.75],[0.75],[0.7291666666666667],[0.7708333333333334],[0.7291666666666667],[0.6875],[0.75],[0.7291666666666667],[0.75],[0.75],[0.7083333333333334],[0.75],[1.0],[0.875],[0.9166666666666667],[0.8541666666666667],[0.9375],[0.9166666666666667],[0.8333333333333334],[0.8541666666666667],[0.8541666666666667],[1.0],[0.8958333333333334],[0.875],[0.9166666666666667],[0.8958333333333334],[0.9791666666666667],[0.9583333333333333],[0.8541666666666667],[0.9375],[0.9583333333333333],[0.7916666666666667],[0.9583333333333333],[0.8958333333333334],[0.8958333333333334],[0.8541666666666667],[0.9166666666666667],[0.8541666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.8125],[0.875],[0.8958333333333334],[0.9375],[0.7916666666666667],[0.7708333333333334],[0.9583333333333333],[0.9791666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.9791666666666667],[0.9583333333333333],[0.875],[0.9583333333333333],[1.0],[0.9583333333333333],[0.875],[0.8958333333333334],[0.9583333333333333],[0.8541666666666667]],"line":{"color":"#2CA02C","width":3}},"mode":"markers","name":"versicolor, virginica","orientation":"v","showlegend":true,"x":[3.2,3.0],"xaxis":"x","y":[5.9,6.7],"yaxis":"y","type":"scatter"},{"customdata":[[1.7],[1.5],[1.5],[1.4]],"hovertemplate":"species=virginica\u003cbr\u003epredict=versicolor\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_length=%{marker.size}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica, versicolor","marker":{"color":"#2CA02C","size":[4.5,5.0,5.1,5.6],"sizemode":"area","sizeref":0.01725,"symbol":"circle","opacity":[[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5],[0.5208333333333334],[0.5625],[0.5625],[0.5416666666666667],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5833333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.6041666666666667],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.7708333333333334],[0.7916666666666667],[0.7916666666666667],[0.75],[0.7916666666666667],[0.75],[0.8125],[0.6875],[0.75],[0.7708333333333334],[0.6875],[0.7916666666666667],[0.6875],[0.7708333333333334],[0.75],[0.7708333333333334],[0.7916666666666667],[0.6875],[0.7916666666666667],[0.7083333333333334],[0.8541666666666667],[0.75],[0.7916666666666667],[0.7291666666666667],[0.75],[0.7708333333333334],[0.7708333333333334],[0.8333333333333334],[0.7916666666666667],[0.6875],[0.7083333333333334],[0.6875],[0.7291666666666667],[0.8125],[0.7916666666666667],[0.8125],[0.7916666666666667],[0.75],[0.75],[0.75],[0.7291666666666667],[0.7708333333333334],[0.7291666666666667],[0.6875],[0.75],[0.7291666666666667],[0.75],[0.75],[0.7083333333333334],[0.75],[1.0],[0.875],[0.9166666666666667],[0.8541666666666667],[0.9375],[0.9166666666666667],[0.8333333333333334],[0.8541666666666667],[0.8541666666666667],[1.0],[0.8958333333333334],[0.875],[0.9166666666666667],[0.8958333333333334],[0.9791666666666667],[0.9583333333333333],[0.8541666666666667],[0.9375],[0.9583333333333333],[0.7916666666666667],[0.9583333333333333],[0.8958333333333334],[0.8958333333333334],[0.8541666666666667],[0.9166666666666667],[0.8541666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.8125],[0.875],[0.8958333333333334],[0.9375],[0.7916666666666667],[0.7708333333333334],[0.9583333333333333],[0.9791666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.9791666666666667],[0.9583333333333333],[0.875],[0.9583333333333333],[1.0],[0.9583333333333333],[0.875],[0.8958333333333334],[0.9583333333333333],[0.8541666666666667]],"line":{"color":"#FF7F0E","width":3}},"mode":"markers","name":"virginica, versicolor","orientation":"v","showlegend":true,"x":[2.5,2.2,2.8,2.6],"xaxis":"x","y":[4.9,6.0,6.3,6.1],"yaxis":"y","type":"scatter"},{"customdata":[[2.5],[1.9],[2.1],[1.8],[2.2],[2.1],[1.8],[1.8],[2.5],[2.0],[1.9],[2.1],[2.0],[2.4],[2.3],[1.8],[2.2],[2.3],[2.3],[2.0],[2.0],[1.8],[2.1],[1.8],[1.8],[1.8],[2.1],[1.6],[1.9],[2.0],[2.2],[2.3],[2.4],[1.8],[1.8],[2.1],[2.4],[2.3],[1.9],[2.3],[2.5],[2.3],[1.9],[2.0],[2.3],[1.8]],"hovertemplate":"species=virginica\u003cbr\u003epredict=virginica\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_length=%{marker.size}\u003cbr\u003epetal_width=%{customdata[0]}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica, virginica","marker":{"color":"#2CA02C","size":[6.0,5.1,5.9,5.6,5.8,6.6,6.3,5.8,6.1,5.1,5.3,5.5,5.0,5.1,5.3,5.5,6.7,6.9,5.7,4.9,6.7,4.9,5.7,6.0,4.8,4.9,5.6,5.8,6.1,6.4,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5.0,5.2,5.4,5.1],"sizemode":"area","sizeref":0.01725,"symbol":"circle","opacity":[[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5],[0.5208333333333334],[0.5625],[0.5625],[0.5416666666666667],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5833333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5625],[0.5],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5],[0.5208333333333334],[0.5208333333333334],[0.5416666666666667],[0.5416666666666667],[0.5208333333333334],[0.6041666666666667],[0.5625],[0.5416666666666667],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.5208333333333334],[0.7708333333333334],[0.7916666666666667],[0.7916666666666667],[0.75],[0.7916666666666667],[0.75],[0.8125],[0.6875],[0.75],[0.7708333333333334],[0.6875],[0.7916666666666667],[0.6875],[0.7708333333333334],[0.75],[0.7708333333333334],[0.7916666666666667],[0.6875],[0.7916666666666667],[0.7083333333333334],[0.8541666666666667],[0.75],[0.7916666666666667],[0.7291666666666667],[0.75],[0.7708333333333334],[0.7708333333333334],[0.8333333333333334],[0.7916666666666667],[0.6875],[0.7083333333333334],[0.6875],[0.7291666666666667],[0.8125],[0.7916666666666667],[0.8125],[0.7916666666666667],[0.75],[0.75],[0.75],[0.7291666666666667],[0.7708333333333334],[0.7291666666666667],[0.6875],[0.75],[0.7291666666666667],[0.75],[0.75],[0.7083333333333334],[0.75],[1.0],[0.875],[0.9166666666666667],[0.8541666666666667],[0.9375],[0.9166666666666667],[0.8333333333333334],[0.8541666666666667],[0.8541666666666667],[1.0],[0.8958333333333334],[0.875],[0.9166666666666667],[0.8958333333333334],[0.9791666666666667],[0.9583333333333333],[0.8541666666666667],[0.9375],[0.9583333333333333],[0.7916666666666667],[0.9583333333333333],[0.8958333333333334],[0.8958333333333334],[0.8541666666666667],[0.9166666666666667],[0.8541666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.8125],[0.875],[0.8958333333333334],[0.9375],[0.7916666666666667],[0.7708333333333334],[0.9583333333333333],[0.9791666666666667],[0.8541666666666667],[0.8541666666666667],[0.9166666666666667],[0.9791666666666667],[0.9583333333333333],[0.875],[0.9583333333333333],[1.0],[0.9583333333333333],[0.875],[0.8958333333333334],[0.9583333333333333],[0.8541666666666667]],"line":{"color":"#2CA02C","width":3}},"mode":"markers","name":"virginica, virginica","orientation":"v","showlegend":true,"x":[3.3,2.7,3.0,2.9,3.0,3.0,2.9,2.5,3.6,3.2,2.7,3.0,2.5,2.8,3.2,3.0,3.8,2.6,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3.0,2.8,3.0,2.8,3.8,2.8,3.0,3.4,3.1,3.0,3.1,3.1,3.1,2.7,3.2,3.3,3.0,2.5,3.0,3.4,3.0],"xaxis":"x","y":[6.3,5.8,7.1,6.3,6.5,7.6,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,7.7,6.3,6.4,6.0,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],"yaxis":"y","type":"scatter"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"rgb(36,36,36)"},"error_y":{"color":"rgb(36,36,36)"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"baxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2d"}],"histogram":[{"marker":{"line":{"color":"white","width":0.6}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"rgb(237,237,237)"},"line":{"color":"white"}},"header":{"fill":{"color":"rgb(217,217,217)"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"colorscale":{"diverging":[[0.0,"rgb(103,0,31)"],[0.1,"rgb(178,24,43)"],[0.2,"rgb(214,96,77)"],[0.3,"rgb(244,165,130)"],[0.4,"rgb(253,219,199)"],[0.5,"rgb(247,247,247)"],[0.6,"rgb(209,229,240)"],[0.7,"rgb(146,197,222)"],[0.8,"rgb(67,147,195)"],[0.9,"rgb(33,102,172)"],[1.0,"rgb(5,48,97)"]],"sequential":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"sequentialminus":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]]},"colorway":["#1F77B4","#FF7F0E","#2CA02C","#D62728","#9467BD","#8C564B","#E377C2","#7F7F7F","#BCBD22","#17BECF"],"font":{"color":"rgb(36,36,36)"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","radialaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"zaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"}},"shapedefaults":{"fillcolor":"black","line":{"width":0},"opacity":0.3},"ternary":{"aaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"baxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","caxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"sepal_width"}},"yaxis":{"anchor":"x","domain":[0.0,1.0],"title":{"text":"sepal_length"}},"legend":{"title":{"text":"species, predict"},"tracegroupgap":0,"itemsizing":"constant"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('3623da17-0f48-42f1-8bac-e38d3f8ed7d9');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>As expected, only a few points are mislabeled. There were a tiny bit more than in the confusion matrix, as the scatterplot includes both the training and testing sets.</p>
<p>We can also display this on the 3D plot, but it unfortunately has a bug where the outline thickness cannot be increased and is barely visible. To compensate, predicted classes are additionally denoted by the marker shape.</p>
<div id="e9eab3d2" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>3D scatterplot of iris &amp; predictions</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter_3d(iris, x<span class="op">=</span><span class="st">"sepal_width"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, z<span class="op">=</span><span class="st">"petal_width"</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span><span class="st">"petal_length"</span>, color<span class="op">=</span><span class="st">"species"</span>, symbol<span class="op">=</span><span class="st">"predict"</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    template<span class="op">=</span><span class="st">"simple_white"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> symbol, color <span class="kw">in</span> fix.items():</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(line<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span>color)),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>                      selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>, marker_symbol<span class="op">=</span>symbol))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>fig.show()<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>                            <div id="21a52fe4-0c16-4daa-87aa-3005dc5bb4d0" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("21a52fe4-0c16-4daa-87aa-3005dc5bb4d0")) {                    Plotly.newPlot(                        "21a52fe4-0c16-4daa-87aa-3005dc5bb4d0",                        [{"hovertemplate":"species=setosa\u003cbr\u003epredict=setosa\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{z}\u003cbr\u003epetal_length=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"setosa, setosa","marker":{"color":"#1F77B4","size":[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1.0,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.5,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4],"sizemode":"area","sizeref":0.01725,"symbol":"circle","line":{"color":"#1F77B4"}},"mode":"markers","name":"setosa, setosa","scene":"scene","showlegend":true,"x":[3.5,3.0,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3.0,3.0,4.0,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3.0,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.1,3.0,3.4,3.5,2.3,3.2,3.5,3.8,3.0,3.8,3.2,3.7,3.3],"y":[5.1,4.9,4.7,4.6,5.0,5.4,4.6,5.0,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5.0,5.0,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5.0,5.5,4.9,4.4,5.1,5.0,4.5,4.4,5.0,5.1,4.8,5.1,4.6,5.3,5.0],"z":[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.1,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2],"type":"scatter3d"},{"hovertemplate":"species=versicolor\u003cbr\u003epredict=versicolor\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{z}\u003cbr\u003epetal_length=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor, versicolor","marker":{"color":"#FF7F0E","size":[4.7,4.5,4.9,4.0,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4.0,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.0,4.9,4.7,4.3,4.4,4.8,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4.0,4.4,4.6,4.0,3.3,4.2,4.2,4.2,4.3,3.0,4.1],"sizemode":"area","sizeref":0.01725,"symbol":"diamond","line":{"color":"#FF7F0E"}},"mode":"markers","name":"versicolor, versicolor","scene":"scene","showlegend":true,"x":[3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2.0,3.0,2.2,2.9,2.9,3.1,3.0,2.7,2.2,2.5,2.8,2.5,2.8,2.9,3.0,2.8,2.9,2.6,2.4,2.4,2.7,2.7,3.0,3.4,3.1,2.3,3.0,2.5,2.6,3.0,2.6,2.3,2.7,3.0,2.9,2.9,2.5,2.8],"y":[7.0,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5.0,5.9,6.0,6.1,5.6,6.7,5.6,5.8,6.2,5.6,6.1,6.3,6.1,6.4,6.6,6.8,6.0,5.7,5.5,5.5,5.8,6.0,5.4,6.0,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5.0,5.6,5.7,5.7,6.2,5.1,5.7],"z":[1.4,1.5,1.5,1.3,1.5,1.3,1.6,1.0,1.3,1.4,1.0,1.5,1.0,1.4,1.3,1.4,1.5,1.0,1.5,1.1,1.3,1.5,1.2,1.3,1.4,1.4,1.5,1.0,1.1,1.0,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1.0,1.3,1.2,1.3,1.3,1.1,1.3],"type":"scatter3d"},{"hovertemplate":"species=versicolor\u003cbr\u003epredict=virginica\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{z}\u003cbr\u003epetal_length=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"versicolor, virginica","marker":{"color":"#FF7F0E","size":[4.8,5.0],"sizemode":"area","sizeref":0.01725,"symbol":"square","line":{"color":"#2CA02C"}},"mode":"markers","name":"versicolor, virginica","scene":"scene","showlegend":true,"x":[3.2,3.0],"y":[5.9,6.7],"z":[1.8,1.7],"type":"scatter3d"},{"hovertemplate":"species=virginica\u003cbr\u003epredict=versicolor\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{z}\u003cbr\u003epetal_length=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica, versicolor","marker":{"color":"#2CA02C","size":[4.5,5.0,5.1,5.6],"sizemode":"area","sizeref":0.01725,"symbol":"diamond","line":{"color":"#FF7F0E"}},"mode":"markers","name":"virginica, versicolor","scene":"scene","showlegend":true,"x":[2.5,2.2,2.8,2.6],"y":[4.9,6.0,6.3,6.1],"z":[1.7,1.5,1.5,1.4],"type":"scatter3d"},{"hovertemplate":"species=virginica\u003cbr\u003epredict=virginica\u003cbr\u003esepal_width=%{x}\u003cbr\u003esepal_length=%{y}\u003cbr\u003epetal_width=%{z}\u003cbr\u003epetal_length=%{marker.size}\u003cextra\u003e\u003c\u002fextra\u003e","legendgroup":"virginica, virginica","marker":{"color":"#2CA02C","size":[6.0,5.1,5.9,5.6,5.8,6.6,6.3,5.8,6.1,5.1,5.3,5.5,5.0,5.1,5.3,5.5,6.7,6.9,5.7,4.9,6.7,4.9,5.7,6.0,4.8,4.9,5.6,5.8,6.1,6.4,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5.0,5.2,5.4,5.1],"sizemode":"area","sizeref":0.01725,"symbol":"square","line":{"color":"#2CA02C"}},"mode":"markers","name":"virginica, virginica","scene":"scene","showlegend":true,"x":[3.3,2.7,3.0,2.9,3.0,3.0,2.9,2.5,3.6,3.2,2.7,3.0,2.5,2.8,3.2,3.0,3.8,2.6,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3.0,2.8,3.0,2.8,3.8,2.8,3.0,3.4,3.1,3.0,3.1,3.1,3.1,2.7,3.2,3.3,3.0,2.5,3.0,3.4,3.0],"y":[6.3,5.8,7.1,6.3,6.5,7.6,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,7.7,6.3,6.4,6.0,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],"z":[2.5,1.9,2.1,1.8,2.2,2.1,1.8,1.8,2.5,2.0,1.9,2.1,2.0,2.4,2.3,1.8,2.2,2.3,2.3,2.0,2.0,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2.0,2.2,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2.0,2.3,1.8],"type":"scatter3d"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"rgb(36,36,36)"},"error_y":{"color":"rgb(36,36,36)"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"baxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2d"}],"histogram":[{"marker":{"line":{"color":"white","width":0.6}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"rgb(237,237,237)"},"line":{"color":"white"}},"header":{"fill":{"color":"rgb(217,217,217)"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"colorscale":{"diverging":[[0.0,"rgb(103,0,31)"],[0.1,"rgb(178,24,43)"],[0.2,"rgb(214,96,77)"],[0.3,"rgb(244,165,130)"],[0.4,"rgb(253,219,199)"],[0.5,"rgb(247,247,247)"],[0.6,"rgb(209,229,240)"],[0.7,"rgb(146,197,222)"],[0.8,"rgb(67,147,195)"],[0.9,"rgb(33,102,172)"],[1.0,"rgb(5,48,97)"]],"sequential":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"sequentialminus":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]]},"colorway":["#1F77B4","#FF7F0E","#2CA02C","#D62728","#9467BD","#8C564B","#E377C2","#7F7F7F","#BCBD22","#17BECF"],"font":{"color":"rgb(36,36,36)"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","radialaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"zaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"}},"shapedefaults":{"fillcolor":"black","line":{"width":0},"opacity":0.3},"ternary":{"aaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"baxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","caxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"}}},"scene":{"domain":{"x":[0.0,1.0],"y":[0.0,1.0]},"xaxis":{"title":{"text":"sepal_width"}},"yaxis":{"title":{"text":"sepal_length"}},"zaxis":{"title":{"text":"petal_width"}}},"legend":{"title":{"text":"species, predict"},"tracegroupgap":0,"itemsizing":"constant"}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('21a52fe4-0c16-4daa-87aa-3005dc5bb4d0');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
<p>This makes the mislabeled points a bit easier to identify, revealing that there are <span class="math inline">\(6\)</span> in total.</p>
</section>
</section>
<section id="complex-dataset" class="level2">
<h2 class="anchored" data-anchor-id="complex-dataset">Complex dataset</h2>
<p>That seems to have been too easy. Let’s try something harder.</p>
<section id="mnist" class="level3">
<h3 class="anchored" data-anchor-id="mnist">MNIST</h3>
<p>Once again, you’ve probably seen this one before. The data consists of hand-drawn digits, which we must then classify.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*XdCMCaHPt-pqtEibUfAnNw.png" class="img-fluid figure-img"></p>
<figcaption>Image credit: <a href="https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d">Orhan G. Yalçın</a>.</figcaption>
</figure>
</div>
</section>
<section id="neural-network" class="level3">
<h3 class="anchored" data-anchor-id="neural-network">Neural network</h3>
<p>Due to the high-dimensionality of the data, we now need to look beyond classical machine learning methods. One approach that has gained widespread popularity over the last decade is <strong>deep learning</strong>, i.e., models with many layers to model complex semantics.</p>
<p>Such models are commonly <strong>neural networks</strong> - architectures supposedly inspired by neurons in a brain. Each neuron takes inputs from several others, aggregates them (plus a bias), then passes through an activation function and onto the next layer. The nonlinearity of the activation step in particular makes it possible for complex behaviors to arise from this structure. Another important reason for these networks being so widespread is that the neurons are neatly arranged in layers, making their associated operations efficiently computable via <em>matrix multiplication</em> - an operation with abundant hardware dedicated to it thanks to computer graphics.</p>
<p>In the following example, we’ll be using a special type of neural network - a <strong>convolutional</strong> neural net (CNN) - specifically designed to process image inputs. Its layers replace the fully-connected structure by the convolution of a single kernel of weights. This makes the patterns learned by the kernels applicable to many parts of the image, reduces the number of model parameters (lower <span class="math inline">\(|\mathcal{H}|\)</span> - good!) while being able to model data effectively (lower approximation error - good!), and introducing spatial locality into the architecture.</p>
<p>For this example, we’ll be mostly following this <a href="https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"><code>pytorch</code> tutorial</a>. First, load and normalize the dataset. Note that <code>pytorch</code> does this through a class called <code>DataLoader</code>, which has the benefit of avoiding storing the entire dataset in memory.</p>
<div id="3c3fcdc4" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Import pytorch</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> MNIST</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Using device: cpu</code></pre>
</div>
</div>
<div id="bcda70dc" class="cell" data-execution_count="8">
<details open="" class="code-fold">
<summary>Load and preprocess data</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>), (<span class="fl">0.5</span>))</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>trainloader <span class="op">=</span> DataLoader(trainset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>testset <span class="op">=</span> MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>testloader <span class="op">=</span> DataLoader(testset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now, define the actual neural network. I’ve condensed<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> it quite a bit from the tutorial, keeping the two convolutional layers but removing some dense layers at the end.</p>
<div id="c8bc96d5" class="cell" data-execution_count="9">
<details open="" class="code-fold">
<summary>Create a neural network</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NeuralNet(nn.Module):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">5</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">6</span> <span class="op">*</span> <span class="dv">4</span> <span class="op">*</span> <span class="dv">4</span>, <span class="dv">10</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(F.relu(<span class="va">self</span>.conv1(x)))</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(F.relu(<span class="va">self</span>.conv2(x)))</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.flatten(x, <span class="dv">1</span>)</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc1(x)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> NeuralNet()</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>, momentum<span class="op">=</span><span class="fl">0.9</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="evaluation-1" class="level3">
<h3 class="anchored" data-anchor-id="evaluation-1">Evaluation</h3>
<p>And now, let’s actually train and evaluate it. If you’re following along, this step can take quite a while…</p>
<div id="6cbcb571" class="cell" data-execution_count="10">
<details open="" class="code-fold">
<summary>Train a neural network</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Do one pass over the dataset</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(trainloader, <span class="dv">0</span>):</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    inputs, labels <span class="op">=</span> data</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resent the gradients</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward/backward pass</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(inputs)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate network</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>y_test, y_pred <span class="op">=</span> [], []</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> data <span class="kw">in</span> testloader:</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        inputs, labels <span class="op">=</span> data</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(inputs)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>        _, pred <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data, <span class="dv">1</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>        y_test.extend(labels)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        y_pred.extend(pred)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy:  </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy:  0.8805
Precision: 0.8875</code></pre>
</div>
</div>
<div id="b92554a3" class="cell" data-execution_count="11">
<details class="code-fold">
<summary>Code for plotting the confusion matrix</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>conf <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>df_cm <span class="op">=</span> pd.DataFrame(conf, index<span class="op">=</span>names, columns<span class="op">=</span>names)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="fl">8.5</span>,<span class="dv">7</span>))</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>sn.heatmap(df_cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="4-classification_files/figure-html/cell-12-output-1.png" class="quarto-figure quarto-figure-center figure-img" width="648" height="559"></p>
</figure>
</div>
</div>
</div>
<p>Yay, it’s finished! The performance above is not too shabby, although bigger and better-trained models should attain a few more percent of accuracy.</p>
<p>The adjacency matrix also reveals some digit pairs that commonly confuse the model. Let’s find some mislabeled examples to see how fair they are.</p>
<details class="code-fold">
<summary>Show test samples with mistakes</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Get samples where mistakes were made</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> wrong(dataloader):</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (images, labels) <span class="kw">in</span> <span class="bu">enumerate</span>(testloader):</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, (image, label) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(images, labels)):</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>            label, pred <span class="op">=</span> label.item(), y_pred[batch_size<span class="op">*</span>i<span class="op">+</span>j].item()</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> pred <span class="op">!=</span> label:</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (image, label, pred)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot several examples</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>loader <span class="op">=</span> wrong(testloader)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    image, label, pred <span class="op">=</span> <span class="bu">next</span>(loader)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> np.transpose(image, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img, cmap<span class="op">=</span><span class="st">'Greys'</span>)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Actual: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ch">\n</span><span class="ss">Predicted: </span><span class="sc">{</span>pred<span class="sc">}</span><span class="ss">"</span>, size<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    plt.xticks([],[])</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    plt.yticks([],[])</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="1ca7ba9d" class="cell quarto-layout-panel" data-execution_count="12" data-layout-ncol="4">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: center;">
<p><img src="4-classification_files/figure-html/cell-13-output-1.png" width="389" height="505"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: center;">
<p><img src="4-classification_files/figure-html/cell-13-output-2.png" width="389" height="505"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: center;">
<p><img src="4-classification_files/figure-html/cell-13-output-3.png" width="389" height="505"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: center;">
<p><img src="4-classification_files/figure-html/cell-13-output-4.png" width="389" height="505"></p>
</div>
</div>
</div>
<p>Personally, I think these are still very comprehensible, maybe just a bit unusual. Even though the model does not get these, it apparently does many more - which I think is fair to call a success.</p>


<!-- -->

</section>
</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>As I’m running this code via GitHub actions, it runs on cpu. I don’t want to spend too long deploying, so I’ve simplified the model accordingly.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/zheng-alice\.github\.io\/blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="adidenkova/blog-comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb16" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Classification</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> In which we overview classification, applying it to a simple and then a more complicated dataset.</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2023/12/04</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - Classification</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Supervised learning</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - Learning theory</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - Naive Bayes</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - Neural network</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Describe the algorithms, theories, and applications related to machine learning/data mining for classification. --&gt;</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>Classification is a **supervised learning** method, much like <span class="co">[</span><span class="ot">regression</span><span class="co">](3-regression.qmd)</span>.</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>Unlike <span class="co">[</span><span class="ot">regression</span><span class="co">](3-regression.qmd)</span>, it predicts features not continuous, but categorical and unordered.</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>Such features then denote the *class* that each point belongs to - not unlike assigning a cluster.</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>Indeed, both classification and <span class="co">[</span><span class="ot">clustering</span><span class="co">](2-clustering.qmd)</span> work with data that is typically sufficiently distinct, that they must then learn to separate into groups.</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>The crucial difference is that classification is given the *labels* of the training data, which it then must generalize to the *testing* set.</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>Various considerations and regimes for classification exist:</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Offline vs. online:** most algorithms are of the former type, where they are given data first and queried only after all such data has been made available.</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>  On the contrary, others such as <span class="co">[</span><span class="ot">bandit algorithms</span><span class="co">](1-probability.qmd#multi-armed-bandits)</span> and <span class="co">[</span><span class="ot">changepoint detection</span><span class="co">](5-anomaly.qmd#changepoint-detection)</span> learn only by making mistakes on the already evaluated examples.</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>  While such algorithms commonly relate to reinforcement learning, they could be applied to all kinds of areas - including clustering and classification.</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Eager vs. lazy:** out of the offline algorithms, some may choose not to even process given data, instead only looking at it when being queried.</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>  Such algorithms are known as lazy; one example would be $k$-nearest neighbors classification.</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Binary/multi-class/multi-label:** the most straightforward type of classification is distinguishing between two classes, or equivalently answering a yes/no question.</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>  Many algorithms extend to output one of many clusters, yet some others need nontrivial modifications.</span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>  Lastly, specially-generalized algorithms exist that can assign multiple class labels to one point.</span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Balanced/imbalanced:** many algorithms assume that the ground truth clusters are of approximately the same size.</span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>  Yet, many datasets have an abundance of one label compared to another - such as when detecting a rare disease.</span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>  In such cases, certain assumptions may break down; for instance, having a dataset with $95%$ labels class $A$ and $5%$ class $B$ makes the trivial algorithm that always picks $A$ perform with $95%$ accuracy.</span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>  As such, the "random" baseline is now $95%$ instead of $50%$.</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>  This imbalance can force even the more powerful models to shy away from predicting the rare class, stumping learning.</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>  To combat this, one can apply strategies such as *oversampling* and *undersampling*.</span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">A comparison of various classification methods. Image credit: [sklearn](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).</span><span class="co">](https://scikit-learn.org/stable/_images/sphx_glr_plot_classifier_comparison_001.png)</span>{#fig-classification}</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="fu">## Learning theory</span></span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>Before we dive into specific algorithms and their applications, it would be useful to review the mathematical theory behind clustering (and machine learning more broadly).</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>This is a fairly mature and encompassing theory, being an umbrella term for many important concepts such as VC theory, online learning, and PAC learning.</span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>Suppose we have some unknown target function $f^\dagger: \mathcal{X} \to \mathcal{Y}$ that maps data to labels.</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>We wish to model this function, but the only information we have about it is how it acts on the data.</span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>In addition, we only have a finite amount of training examples $D = <span class="sc">\{</span>(x_1,y_1), \ldots (x_n,y_n)<span class="sc">\}</span> \sim \mathcal{D}$.</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a>We wish to approximate $f^\dagger$ via some other function $\hat{f}$ that not only maps each $x_i \mapsto y_i$, but also *generalizes* to doing this for any $(x,y) \sim \mathcal{D}$.</span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a>The approximation $\hat{f}$ will instead map $x$ to some $\hat{y}$, and to measure the quality of this output, we will choose a *loss function* $L(\hat{y},y)$ of interest (often, the indicator function).</span>
<span id="cb16-51"><a href="#cb16-51" aria-hidden="true" tabindex="-1"></a>More formally, we can evaluate an approximation $f$ via its **risk**, defined as</span>
<span id="cb16-52"><a href="#cb16-52" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb16-53"><a href="#cb16-53" aria-hidden="true" tabindex="-1"></a>R(f) = \mathbb{E}<span class="co">[</span><span class="ot">L(f(x), y)</span><span class="co">]</span> = \int L(f(x), y) \mathrm{dP}(x,y)\ .</span>
<span id="cb16-54"><a href="#cb16-54" aria-hidden="true" tabindex="-1"></a>$$ {#eq-risk}</span>
<span id="cb16-55"><a href="#cb16-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-56"><a href="#cb16-56" aria-hidden="true" tabindex="-1"></a>This metric choice may seem a bit odd, but necessary since sampling $(x,y)$ from $\mathcal{D}$ means they are <span class="co">[</span><span class="ot">random variables</span><span class="co">](1-probability.qmd#random-variables)</span>.</span>
<span id="cb16-57"><a href="#cb16-57" aria-hidden="true" tabindex="-1"></a>In addition, we can't even evaluate the above quantity since we don't know $\mathcal{D}$ in the first place.</span>
<span id="cb16-58"><a href="#cb16-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-59"><a href="#cb16-59" aria-hidden="true" tabindex="-1"></a>So, what to do?</span>
<span id="cb16-60"><a href="#cb16-60" aria-hidden="true" tabindex="-1"></a>Instead, we just evaluate on the available data to obtain the **empirical risk** of $f$,</span>
<span id="cb16-61"><a href="#cb16-61" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb16-62"><a href="#cb16-62" aria-hidden="true" tabindex="-1"></a>R_\text{emp}(f) = \frac{1}{n} \sum_{i=1}^n L(f(x_i), y_i)\ .</span>
<span id="cb16-63"><a href="#cb16-63" aria-hidden="true" tabindex="-1"></a>$$ {#eq-empirical}</span>
<span id="cb16-64"><a href="#cb16-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-65"><a href="#cb16-65" aria-hidden="true" tabindex="-1"></a>Outside of learning theory, risk and empirical risk may be referred to as testing and training loss.</span>
<span id="cb16-66"><a href="#cb16-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-67"><a href="#cb16-67" aria-hidden="true" tabindex="-1"></a>The next question is how to find our approximation $\hat{f}$.</span>
<span id="cb16-68"><a href="#cb16-68" aria-hidden="true" tabindex="-1"></a>To do this, we need to start with picking a *hypothesis class* $\mathcal{H}$, representing all possible models (and parameters) we could potentially end up with.</span>
<span id="cb16-69"><a href="#cb16-69" aria-hidden="true" tabindex="-1"></a>We then compute</span>
<span id="cb16-70"><a href="#cb16-70" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb16-71"><a href="#cb16-71" aria-hidden="true" tabindex="-1"></a>\hat{f} = \arg\min_{f \in \mathcal{H}} R_\text{emp}(f)\ ,</span>
<span id="cb16-72"><a href="#cb16-72" aria-hidden="true" tabindex="-1"></a>$$ {#eq-fhat}</span>
<span id="cb16-73"><a href="#cb16-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-74"><a href="#cb16-74" aria-hidden="true" tabindex="-1"></a>and hope that it is close to</span>
<span id="cb16-75"><a href="#cb16-75" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb16-76"><a href="#cb16-76" aria-hidden="true" tabindex="-1"></a>f^* = \arg\min_{f \in \mathcal{H}} R(f)\ .</span>
<span id="cb16-77"><a href="#cb16-77" aria-hidden="true" tabindex="-1"></a>$$ {#eq-fstar}</span>
<span id="cb16-78"><a href="#cb16-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-79"><a href="#cb16-79" aria-hidden="true" tabindex="-1"></a>So, at this point we have already accumulated a couple potential sources of error.</span>
<span id="cb16-80"><a href="#cb16-80" aria-hidden="true" tabindex="-1"></a>The following picture helps to illustrate them.</span>
<span id="cb16-81"><a href="#cb16-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-82"><a href="#cb16-82" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Image credit: [Han Bao](https://hermite.jp/post/erm-optimal-convergence-rate/).</span><span class="co">](https://hermite.jp/img/201802/estimation-approximation-error.png)</span>{width=50%}</span>
<span id="cb16-83"><a href="#cb16-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-84"><a href="#cb16-84" aria-hidden="true" tabindex="-1"></a>When restricting ourselves to $\mathcal{H}$, we demoted the best attainable function from $f^\dagger$ to $f^*$ resulting in an <span class="co">[</span><span class="ot">approximation error</span><span class="co">]</span>{.red}.</span>
<span id="cb16-85"><a href="#cb16-85" aria-hidden="true" tabindex="-1"></a>Then, since we only have a limited-size dataset, the best possible approximation to $f^*$ we can get is $\hat{f}$, which incurs an <span class="co">[</span><span class="ot">estimation error</span><span class="co">]</span>{.blue}.</span>
<span id="cb16-86"><a href="#cb16-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-87"><a href="#cb16-87" aria-hidden="true" tabindex="-1"></a>So, what should we do to minimize these errors?</span>
<span id="cb16-88"><a href="#cb16-88" aria-hidden="true" tabindex="-1"></a>The quality of the <span class="co">[</span><span class="ot">approximation</span><span class="co">]</span>{.red} primarily depends on the chosen hypothesis class - making it include more complex models decreases the error.</span>
<span id="cb16-89"><a href="#cb16-89" aria-hidden="true" tabindex="-1"></a>As for <span class="co">[</span><span class="ot">estimation</span><span class="co">]</span>{.blue}, there are various bounds that relate it to parameters; though, the common theme is that generalization is improved with a larger $|D| = n$ and a smaller $|\mathcal{H}|$.</span>
<span id="cb16-90"><a href="#cb16-90" aria-hidden="true" tabindex="-1"></a>However, the latter condition seems almost directly contradictory to the one we need for better approximations, i.e., more complex models.</span>
<span id="cb16-91"><a href="#cb16-91" aria-hidden="true" tabindex="-1"></a>The following graphic illustrates this tradeoff (occasionally also referred to as the underfitting/overfitting or bias/variance tradeoff)</span>
<span id="cb16-92"><a href="#cb16-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-93"><a href="#cb16-93" aria-hidden="true" tabindex="-1"></a><span class="al">![Tradeoff of estimation and approximation errors.](tradeoff.svg)</span>{width=50%}</span>
<span id="cb16-94"><a href="#cb16-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-95"><a href="#cb16-95" aria-hidden="true" tabindex="-1"></a>So, is all lost?</span>
<span id="cb16-96"><a href="#cb16-96" aria-hidden="true" tabindex="-1"></a>Not exactly; the conditions aren't directly contradictory - we could minimize both by finding an $\mathcal{H}$ that contains as few models as possible, but the ones it contains are accurate at modeling the desired data.</span>
<span id="cb16-97"><a href="#cb16-97" aria-hidden="true" tabindex="-1"></a>This is a task easier said than done, as we need to carefully discard all unnecessary models, while making sure the important ones are retained.</span>
<span id="cb16-98"><a href="#cb16-98" aria-hidden="true" tabindex="-1"></a>The search for such a hypothesis class $\mathcal{H}$ is perhaps what drives the creation of many various types of machine learning algorithms.</span>
<span id="cb16-99"><a href="#cb16-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-100"><a href="#cb16-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-101"><a href="#cb16-101" aria-hidden="true" tabindex="-1"></a><span class="fu">## Simple dataset</span></span>
<span id="cb16-102"><a href="#cb16-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-103"><a href="#cb16-103" aria-hidden="true" tabindex="-1"></a>We start our evaluation by analyzing one of the algorithms featured in @fig-classification (second column from the right), **Naive Bayes**.</span>
<span id="cb16-104"><a href="#cb16-104" aria-hidden="true" tabindex="-1"></a>We can see that it performs fairly well on the artificial data, separating it sufficiently but also generalizing smoothly to outside of the provided domain.</span>
<span id="cb16-105"><a href="#cb16-105" aria-hidden="true" tabindex="-1"></a>Let's see how it fares against data with a couple more dimensions.</span>
<span id="cb16-106"><a href="#cb16-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-107"><a href="#cb16-107" aria-hidden="true" tabindex="-1"></a><span class="fu">### Naive Bayes</span></span>
<span id="cb16-108"><a href="#cb16-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-109"><a href="#cb16-109" aria-hidden="true" tabindex="-1"></a>But first, a small introduction of the algorithm itself (mostly based on its <span class="co">[</span><span class="ot">Wikipedia</span><span class="co">](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)</span> article).</span>
<span id="cb16-110"><a href="#cb16-110" aria-hidden="true" tabindex="-1"></a>As evident by its name, it relies on Bayes' theorem</span>
<span id="cb16-111"><a href="#cb16-111" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb16-112"><a href="#cb16-112" aria-hidden="true" tabindex="-1"></a>\mathrm{P}(k | x) = \frac{\mathrm{P}(x | k) \mathrm{P}(k)}{\mathrm{P}(x)}\ ,</span>
<span id="cb16-113"><a href="#cb16-113" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bayes}</span>
<span id="cb16-114"><a href="#cb16-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-115"><a href="#cb16-115" aria-hidden="true" tabindex="-1"></a>where $k$ is the event of the data $x = x_1, \ldots x_n$ belonging to class $k$.</span>
<span id="cb16-116"><a href="#cb16-116" aria-hidden="true" tabindex="-1"></a>Naturally, the quantity on the left of @eq-bayes is exactly what would let us perform classification, so we use the quantity on the right (ignoring the denominator as it doesn't depend on $k$) to compute it.</span>
<span id="cb16-117"><a href="#cb16-117" aria-hidden="true" tabindex="-1"></a>The numerator is equal to $\mathrm{P}(x, k)$, which we may by chain rule write as</span>
<span id="cb16-118"><a href="#cb16-118" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb16-119"><a href="#cb16-119" aria-hidden="true" tabindex="-1"></a>\mathrm{P}(x_1, \ldots, x_n, k)</span>
<span id="cb16-120"><a href="#cb16-120" aria-hidden="true" tabindex="-1"></a>= \mathrm{P}(x_1 | x_2, \ldots x_n, k) \mathrm{P}(x_2 | x_3, \ldots x_n, k) \dots \mathrm{P}(x_n, k) \mathrm{P}(k)\ .</span>
<span id="cb16-121"><a href="#cb16-121" aria-hidden="true" tabindex="-1"></a>$$ {#eq-chain}</span>
<span id="cb16-122"><a href="#cb16-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-123"><a href="#cb16-123" aria-hidden="true" tabindex="-1"></a>To go further, we need an assumption - the *conditional independence* (a.k.a. naive Bayes) assumption.</span>
<span id="cb16-124"><a href="#cb16-124" aria-hidden="true" tabindex="-1"></a>Specifically, we have that $\mathrm{P}(x_i | x_{i+1}, \ldots, x_n, k) = \mathrm{P} (x_i | k)$, and thus</span>
<span id="cb16-125"><a href="#cb16-125" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb16-126"><a href="#cb16-126" aria-hidden="true" tabindex="-1"></a>\mathrm{P}(k | x) \propto \mathrm{P}(k, x) = \mathrm{P}(k) \prod_{i=1}^n \mathrm{P}(x_i | k)\ .</span>
<span id="cb16-127"><a href="#cb16-127" aria-hidden="true" tabindex="-1"></a>$$ {#eq-naive}</span>
<span id="cb16-128"><a href="#cb16-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-129"><a href="#cb16-129" aria-hidden="true" tabindex="-1"></a><span class="fu">### Iris</span></span>
<span id="cb16-130"><a href="#cb16-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-131"><a href="#cb16-131" aria-hidden="true" tabindex="-1"></a>I don't think this dataset really needs an introduction, you've almost certainly seen it before.</span>
<span id="cb16-132"><a href="#cb16-132" aria-hidden="true" tabindex="-1"></a>In any case, it has four features that describe the length and width of flower petals and sepals, as seen below.</span>
<span id="cb16-133"><a href="#cb16-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-134"><a href="#cb16-134" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Image credit: [Sebastian Raschka](https://sebastianraschka.com/Articles/2015_pca_in_3_steps.html).</span><span class="co">](https://sebastianraschka.com/images/blog/2015/principal_component_analysis_files/iris.png)</span>{width=75%}</span>
<span id="cb16-135"><a href="#cb16-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-136"><a href="#cb16-136" aria-hidden="true" tabindex="-1"></a>The question is; could you tell which of the following three flowers you're looking at?</span>
<span id="cb16-137"><a href="#cb16-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-138"><a href="#cb16-138" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Image credit: [Gaurav Chauhan](https://machinelearninghd.com/iris-dataset-uci-machine-learning-repository-project/).</span><span class="co">](https://machinelearninghd.com/wp-content/uploads/2021/03/iris-dataset.png)</span></span>
<span id="cb16-139"><a href="#cb16-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-140"><a href="#cb16-140" aria-hidden="true" tabindex="-1"></a>Except, you wouldn't be actually looking at the flowers but instead just those four numbers.</span>
<span id="cb16-141"><a href="#cb16-141" aria-hidden="true" tabindex="-1"></a>It may instead be easier to see the difference if the values are plotted laterally.</span>
<span id="cb16-142"><a href="#cb16-142" aria-hidden="true" tabindex="-1"></a>Below, petal length is denoted by size and petal width by transparency.</span>
<span id="cb16-143"><a href="#cb16-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-146"><a href="#cb16-146" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-147"><a href="#cb16-147" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-148"><a href="#cb16-148" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: 2D scatterplot of iris</span></span>
<span id="cb16-149"><a href="#cb16-149" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb16-150"><a href="#cb16-150" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> MinMaxScaler</span>
<span id="cb16-151"><a href="#cb16-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-152"><a href="#cb16-152" aria-hidden="true" tabindex="-1"></a>iris <span class="op">=</span> px.data.iris().drop(<span class="st">'species_id'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb16-153"><a href="#cb16-153" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter(iris, x<span class="op">=</span><span class="st">"sepal_width"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, size<span class="op">=</span><span class="st">"petal_length"</span>,</span>
<span id="cb16-154"><a href="#cb16-154" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"species"</span>, marginal_y<span class="op">=</span><span class="st">"violin"</span>, marginal_x<span class="op">=</span><span class="st">"violin"</span>,</span>
<span id="cb16-155"><a href="#cb16-155" aria-hidden="true" tabindex="-1"></a>    template<span class="op">=</span><span class="st">"simple_white"</span>, hover_data<span class="op">=</span>[<span class="st">'petal_width'</span>])</span>
<span id="cb16-156"><a href="#cb16-156" aria-hidden="true" tabindex="-1"></a>op <span class="op">=</span> MinMaxScaler(feature_range<span class="op">=</span>(<span class="fl">0.5</span>, <span class="fl">1.0</span>)).fit_transform(</span>
<span id="cb16-157"><a href="#cb16-157" aria-hidden="true" tabindex="-1"></a>    iris[<span class="st">'petal_width'</span>].values[:, <span class="va">None</span>])</span>
<span id="cb16-158"><a href="#cb16-158" aria-hidden="true" tabindex="-1"></a>fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(opacity<span class="op">=</span>op), selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>))</span>
<span id="cb16-159"><a href="#cb16-159" aria-hidden="true" tabindex="-1"></a>fig.show()<span class="op">;</span></span>
<span id="cb16-160"><a href="#cb16-160" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-161"><a href="#cb16-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-162"><a href="#cb16-162" aria-hidden="true" tabindex="-1"></a>Or, perhaps in a 3D plot that shows all four features (petal length is still marker size).</span>
<span id="cb16-163"><a href="#cb16-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-166"><a href="#cb16-166" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-167"><a href="#cb16-167" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-168"><a href="#cb16-168" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: 3D scatterplot of iris</span></span>
<span id="cb16-169"><a href="#cb16-169" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb16-170"><a href="#cb16-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-171"><a href="#cb16-171" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter_3d(iris, x<span class="op">=</span><span class="st">"sepal_width"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, z<span class="op">=</span><span class="st">"petal_width"</span>,</span>
<span id="cb16-172"><a href="#cb16-172" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span><span class="st">"petal_length"</span>, color<span class="op">=</span><span class="st">"species"</span>, template<span class="op">=</span><span class="st">"simple_white"</span>)</span>
<span id="cb16-173"><a href="#cb16-173" aria-hidden="true" tabindex="-1"></a>fig.show()<span class="op">;</span></span>
<span id="cb16-174"><a href="#cb16-174" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-175"><a href="#cb16-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-176"><a href="#cb16-176" aria-hidden="true" tabindex="-1"></a>I don't know about you, but some of the points between versicolor and virginia still seem pretty overlapping.</span>
<span id="cb16-177"><a href="#cb16-177" aria-hidden="true" tabindex="-1"></a>Let's see how the algorithm compares!</span>
<span id="cb16-178"><a href="#cb16-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-179"><a href="#cb16-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-180"><a href="#cb16-180" aria-hidden="true" tabindex="-1"></a><span class="fu">### Evaluation</span></span>
<span id="cb16-181"><a href="#cb16-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-182"><a href="#cb16-182" aria-hidden="true" tabindex="-1"></a>Lucky for us, Naive Bayes is a common algorithm with many implementations.</span>
<span id="cb16-183"><a href="#cb16-183" aria-hidden="true" tabindex="-1"></a>We'll be using one by <span class="in">`sklearn`</span>.</span>
<span id="cb16-184"><a href="#cb16-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-187"><a href="#cb16-187" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-188"><a href="#cb16-188" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Naive bayes classifier</span></span>
<span id="cb16-189"><a href="#cb16-189" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb16-190"><a href="#cb16-190" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</span>
<span id="cb16-191"><a href="#cb16-191" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score</span>
<span id="cb16-192"><a href="#cb16-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-193"><a href="#cb16-193" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit and predict</span></span>
<span id="cb16-194"><a href="#cb16-194" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> iris.drop(<span class="st">'species'</span>, axis<span class="op">=</span><span class="dv">1</span>), iris[<span class="st">'species'</span>]</span>
<span id="cb16-195"><a href="#cb16-195" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb16-196"><a href="#cb16-196" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">5805</span>)</span>
<span id="cb16-197"><a href="#cb16-197" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> GaussianNB().fit(X_train, y_train)</span>
<span id="cb16-198"><a href="#cb16-198" aria-hidden="true" tabindex="-1"></a>iris[<span class="st">'predict'</span>] <span class="op">=</span> nb.predict(X)</span>
<span id="cb16-199"><a href="#cb16-199" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> nb.predict(X_test)</span>
<span id="cb16-200"><a href="#cb16-200" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy:  </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb16-201"><a href="#cb16-201" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb16-202"><a href="#cb16-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-203"><a href="#cb16-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-206"><a href="#cb16-206" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-207"><a href="#cb16-207" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-208"><a href="#cb16-208" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Code for plotting the confusion matrix</span></span>
<span id="cb16-209"><a href="#cb16-209" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb16-210"><a href="#cb16-210" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sn</span>
<span id="cb16-211"><a href="#cb16-211" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb16-212"><a href="#cb16-212" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb16-213"><a href="#cb16-213" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix</span>
<span id="cb16-214"><a href="#cb16-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-215"><a href="#cb16-215" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> iris[<span class="st">'species'</span>].unique()</span>
<span id="cb16-216"><a href="#cb16-216" aria-hidden="true" tabindex="-1"></a>conf <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb16-217"><a href="#cb16-217" aria-hidden="true" tabindex="-1"></a>df_cm <span class="op">=</span> pd.DataFrame(conf, index<span class="op">=</span>names, columns<span class="op">=</span>names)</span>
<span id="cb16-218"><a href="#cb16-218" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">4</span>,<span class="dv">3</span>))</span>
<span id="cb16-219"><a href="#cb16-219" aria-hidden="true" tabindex="-1"></a>sn.heatmap(df_cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>)<span class="op">;</span></span>
<span id="cb16-220"><a href="#cb16-220" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-221"><a href="#cb16-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-222"><a href="#cb16-222" aria-hidden="true" tabindex="-1"></a>From the above, we can gauge the performance as quite good - the algorithm only mislabels $4$ points out of a testing set of size $75$, while being given a training set of only size $75$.</span>
<span id="cb16-223"><a href="#cb16-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-224"><a href="#cb16-224" aria-hidden="true" tabindex="-1"></a>Let's see where it made mistakes.</span>
<span id="cb16-225"><a href="#cb16-225" aria-hidden="true" tabindex="-1"></a>Predictions are denoted by outline colors, points where the inner color doesn't match are mislabeled.</span>
<span id="cb16-226"><a href="#cb16-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-229"><a href="#cb16-229" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-230"><a href="#cb16-230" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-231"><a href="#cb16-231" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: 2D scatterplot of iris &amp; predictions</span></span>
<span id="cb16-232"><a href="#cb16-232" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-233"><a href="#cb16-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-234"><a href="#cb16-234" aria-hidden="true" tabindex="-1"></a>fix <span class="op">=</span> {<span class="st">"circle"</span>: <span class="st">"#1F77B4"</span>, <span class="st">"diamond"</span>: <span class="st">"#FF7F0E"</span>, <span class="st">"square"</span>: <span class="st">"#2CA02C"</span>}</span>
<span id="cb16-235"><a href="#cb16-235" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter(iris, x<span class="op">=</span><span class="st">"sepal_width"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, size<span class="op">=</span><span class="st">"petal_length"</span>,</span>
<span id="cb16-236"><a href="#cb16-236" aria-hidden="true" tabindex="-1"></a>    color<span class="op">=</span><span class="st">"species"</span>, symbol<span class="op">=</span><span class="st">"predict"</span>,</span>
<span id="cb16-237"><a href="#cb16-237" aria-hidden="true" tabindex="-1"></a>    template<span class="op">=</span><span class="st">"simple_white"</span>, hover_data<span class="op">=</span>[<span class="st">'petal_width'</span>])</span>
<span id="cb16-238"><a href="#cb16-238" aria-hidden="true" tabindex="-1"></a>fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(opacity<span class="op">=</span>op), selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>))</span>
<span id="cb16-239"><a href="#cb16-239" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> symbol, color <span class="kw">in</span> fix.items():</span>
<span id="cb16-240"><a href="#cb16-240" aria-hidden="true" tabindex="-1"></a>    fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(line<span class="op">=</span><span class="bu">dict</span>(width<span class="op">=</span><span class="dv">3</span>, color<span class="op">=</span>color),</span>
<span id="cb16-241"><a href="#cb16-241" aria-hidden="true" tabindex="-1"></a>                      symbol<span class="op">=</span><span class="st">"circle"</span>),</span>
<span id="cb16-242"><a href="#cb16-242" aria-hidden="true" tabindex="-1"></a>                      selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>, marker_symbol<span class="op">=</span>symbol))</span>
<span id="cb16-243"><a href="#cb16-243" aria-hidden="true" tabindex="-1"></a>fig.show()<span class="op">;</span></span>
<span id="cb16-244"><a href="#cb16-244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-245"><a href="#cb16-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-246"><a href="#cb16-246" aria-hidden="true" tabindex="-1"></a>As expected, only a few points are mislabeled.</span>
<span id="cb16-247"><a href="#cb16-247" aria-hidden="true" tabindex="-1"></a>There were a tiny bit more than in the confusion matrix, as the scatterplot includes both the training and testing sets.</span>
<span id="cb16-248"><a href="#cb16-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-249"><a href="#cb16-249" aria-hidden="true" tabindex="-1"></a>We can also display this on the 3D plot, but it unfortunately has a bug where the outline thickness cannot be increased and is barely visible.</span>
<span id="cb16-250"><a href="#cb16-250" aria-hidden="true" tabindex="-1"></a>To compensate, predicted classes are additionally denoted by the marker shape.</span>
<span id="cb16-251"><a href="#cb16-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-254"><a href="#cb16-254" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-255"><a href="#cb16-255" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-256"><a href="#cb16-256" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: 3D scatterplot of iris &amp; predictions</span></span>
<span id="cb16-257"><a href="#cb16-257" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb16-258"><a href="#cb16-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-259"><a href="#cb16-259" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> px.scatter_3d(iris, x<span class="op">=</span><span class="st">"sepal_width"</span>, y<span class="op">=</span><span class="st">"sepal_length"</span>, z<span class="op">=</span><span class="st">"petal_width"</span>,</span>
<span id="cb16-260"><a href="#cb16-260" aria-hidden="true" tabindex="-1"></a>    size<span class="op">=</span><span class="st">"petal_length"</span>, color<span class="op">=</span><span class="st">"species"</span>, symbol<span class="op">=</span><span class="st">"predict"</span>,</span>
<span id="cb16-261"><a href="#cb16-261" aria-hidden="true" tabindex="-1"></a>    template<span class="op">=</span><span class="st">"simple_white"</span>)</span>
<span id="cb16-262"><a href="#cb16-262" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> symbol, color <span class="kw">in</span> fix.items():</span>
<span id="cb16-263"><a href="#cb16-263" aria-hidden="true" tabindex="-1"></a>    fig.update_traces(marker<span class="op">=</span><span class="bu">dict</span>(line<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span>color)),</span>
<span id="cb16-264"><a href="#cb16-264" aria-hidden="true" tabindex="-1"></a>                      selector<span class="op">=</span><span class="bu">dict</span>(mode<span class="op">=</span><span class="st">'markers'</span>, marker_symbol<span class="op">=</span>symbol))</span>
<span id="cb16-265"><a href="#cb16-265" aria-hidden="true" tabindex="-1"></a>fig.show()<span class="op">;</span></span>
<span id="cb16-266"><a href="#cb16-266" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-267"><a href="#cb16-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-268"><a href="#cb16-268" aria-hidden="true" tabindex="-1"></a>This makes the mislabeled points a bit easier to identify, revealing that there are $6$ in total.</span>
<span id="cb16-269"><a href="#cb16-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-270"><a href="#cb16-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-271"><a href="#cb16-271" aria-hidden="true" tabindex="-1"></a><span class="fu">## Complex dataset</span></span>
<span id="cb16-272"><a href="#cb16-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-273"><a href="#cb16-273" aria-hidden="true" tabindex="-1"></a>That seems to have been too easy.</span>
<span id="cb16-274"><a href="#cb16-274" aria-hidden="true" tabindex="-1"></a>Let's try something harder.</span>
<span id="cb16-275"><a href="#cb16-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-276"><a href="#cb16-276" aria-hidden="true" tabindex="-1"></a><span class="fu">### MNIST</span></span>
<span id="cb16-277"><a href="#cb16-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-278"><a href="#cb16-278" aria-hidden="true" tabindex="-1"></a>Once again, you've probably seen this one before.</span>
<span id="cb16-279"><a href="#cb16-279" aria-hidden="true" tabindex="-1"></a>The data consists of hand-drawn digits, which we must then classify.</span>
<span id="cb16-280"><a href="#cb16-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-281"><a href="#cb16-281" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Image credit: [Orhan G. Yalçın](https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d).</span><span class="co">](https://miro.medium.com/v2/resize:fit:720/format:webp/1*XdCMCaHPt-pqtEibUfAnNw.png)</span></span>
<span id="cb16-282"><a href="#cb16-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-283"><a href="#cb16-283" aria-hidden="true" tabindex="-1"></a><span class="fu">### Neural network</span></span>
<span id="cb16-284"><a href="#cb16-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-285"><a href="#cb16-285" aria-hidden="true" tabindex="-1"></a>Due to the high-dimensionality of the data, we now need to look beyond classical machine learning methods.</span>
<span id="cb16-286"><a href="#cb16-286" aria-hidden="true" tabindex="-1"></a>One approach that has gained widespread popularity over the last decade is **deep learning**, i.e., models with many layers to model complex semantics.</span>
<span id="cb16-287"><a href="#cb16-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-288"><a href="#cb16-288" aria-hidden="true" tabindex="-1"></a>Such models are commonly **neural networks** - architectures supposedly inspired by neurons in a brain.</span>
<span id="cb16-289"><a href="#cb16-289" aria-hidden="true" tabindex="-1"></a>Each neuron takes inputs from several others, aggregates them (plus a bias), then passes through an activation function and onto the next layer.</span>
<span id="cb16-290"><a href="#cb16-290" aria-hidden="true" tabindex="-1"></a>The nonlinearity of the activation step in particular makes it possible for complex behaviors to arise from this structure.</span>
<span id="cb16-291"><a href="#cb16-291" aria-hidden="true" tabindex="-1"></a>Another important reason for these networks being so widespread is that the neurons are neatly arranged in layers, making their associated operations efficiently computable via *matrix multiplication* - an operation with abundant hardware dedicated to it thanks to computer graphics.</span>
<span id="cb16-292"><a href="#cb16-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-293"><a href="#cb16-293" aria-hidden="true" tabindex="-1"></a>In the following example, we'll be using a special type of neural network - a **convolutional** neural net (CNN) - specifically designed to process image inputs.</span>
<span id="cb16-294"><a href="#cb16-294" aria-hidden="true" tabindex="-1"></a>Its layers replace the fully-connected structure by the convolution of a single kernel of weights.</span>
<span id="cb16-295"><a href="#cb16-295" aria-hidden="true" tabindex="-1"></a>This makes the patterns learned by the kernels applicable to many parts of the image, reduces the number of model parameters (lower $|\mathcal{H}|$ - good!) while being able to model data effectively (lower approximation error - good!), and introducing spatial locality into the architecture.</span>
<span id="cb16-296"><a href="#cb16-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-297"><a href="#cb16-297" aria-hidden="true" tabindex="-1"></a>For this example, we'll be mostly following this <span class="co">[</span><span class="ot">`pytorch` tutorial</span><span class="co">](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)</span>.</span>
<span id="cb16-298"><a href="#cb16-298" aria-hidden="true" tabindex="-1"></a>First, load and normalize the dataset.</span>
<span id="cb16-299"><a href="#cb16-299" aria-hidden="true" tabindex="-1"></a>Note that <span class="in">`pytorch`</span> does this through a class called <span class="in">`DataLoader`</span>, which has the benefit of avoiding storing the entire dataset in memory.</span>
<span id="cb16-300"><a href="#cb16-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-303"><a href="#cb16-303" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-304"><a href="#cb16-304" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-305"><a href="#cb16-305" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Import pytorch</span></span>
<span id="cb16-306"><a href="#cb16-306" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb16-307"><a href="#cb16-307" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch <span class="im">import</span> nn</span>
<span id="cb16-308"><a href="#cb16-308" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb16-309"><a href="#cb16-309" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb16-310"><a href="#cb16-310" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> MNIST</span>
<span id="cb16-311"><a href="#cb16-311" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb16-312"><a href="#cb16-312" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb16-313"><a href="#cb16-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-314"><a href="#cb16-314" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb16-315"><a href="#cb16-315" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Using device: </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb16-316"><a href="#cb16-316" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-317"><a href="#cb16-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-320"><a href="#cb16-320" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-321"><a href="#cb16-321" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Load and preprocess data</span></span>
<span id="cb16-322"><a href="#cb16-322" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb16-323"><a href="#cb16-323" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb16-324"><a href="#cb16-324" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb16-325"><a href="#cb16-325" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.5</span>), (<span class="fl">0.5</span>))</span>
<span id="cb16-326"><a href="#cb16-326" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb16-327"><a href="#cb16-327" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">4</span></span>
<span id="cb16-328"><a href="#cb16-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-329"><a href="#cb16-329" aria-hidden="true" tabindex="-1"></a>trainset <span class="op">=</span> MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb16-330"><a href="#cb16-330" aria-hidden="true" tabindex="-1"></a>trainloader <span class="op">=</span> DataLoader(trainset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb16-331"><a href="#cb16-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-332"><a href="#cb16-332" aria-hidden="true" tabindex="-1"></a>testset <span class="op">=</span> MNIST(root<span class="op">=</span><span class="st">'./data'</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb16-333"><a href="#cb16-333" aria-hidden="true" tabindex="-1"></a>testloader <span class="op">=</span> DataLoader(testset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb16-334"><a href="#cb16-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-335"><a href="#cb16-335" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(<span class="dv">10</span>))</span>
<span id="cb16-336"><a href="#cb16-336" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-337"><a href="#cb16-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-338"><a href="#cb16-338" aria-hidden="true" tabindex="-1"></a>Now, define the actual neural network.</span>
<span id="cb16-339"><a href="#cb16-339" aria-hidden="true" tabindex="-1"></a>I've condensed<span class="ot">[^runtime]</span> it quite a bit from the tutorial, keeping the two convolutional layers but removing some dense layers at the end.</span>
<span id="cb16-340"><a href="#cb16-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-341"><a href="#cb16-341" aria-hidden="true" tabindex="-1"></a><span class="ot">[^runtime]: </span>As I'm running this code via GitHub actions, it runs on cpu.</span>
<span id="cb16-342"><a href="#cb16-342" aria-hidden="true" tabindex="-1"></a>I don't want to spend too long deploying, so I've simplified the model accordingly.</span>
<span id="cb16-343"><a href="#cb16-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-346"><a href="#cb16-346" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-347"><a href="#cb16-347" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Create a neural network</span></span>
<span id="cb16-348"><a href="#cb16-348" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NeuralNet(nn.Module):</span>
<span id="cb16-349"><a href="#cb16-349" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb16-350"><a href="#cb16-350" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb16-351"><a href="#cb16-351" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>)</span>
<span id="cb16-352"><a href="#cb16-352" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb16-353"><a href="#cb16-353" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">6</span>, <span class="dv">5</span>)</span>
<span id="cb16-354"><a href="#cb16-354" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">6</span> <span class="op">*</span> <span class="dv">4</span> <span class="op">*</span> <span class="dv">4</span>, <span class="dv">10</span>)</span>
<span id="cb16-355"><a href="#cb16-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-356"><a href="#cb16-356" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb16-357"><a href="#cb16-357" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(F.relu(<span class="va">self</span>.conv1(x)))</span>
<span id="cb16-358"><a href="#cb16-358" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.pool(F.relu(<span class="va">self</span>.conv2(x)))</span>
<span id="cb16-359"><a href="#cb16-359" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> torch.flatten(x, <span class="dv">1</span>)</span>
<span id="cb16-360"><a href="#cb16-360" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.fc1(x)</span>
<span id="cb16-361"><a href="#cb16-361" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span>
<span id="cb16-362"><a href="#cb16-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-363"><a href="#cb16-363" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> NeuralNet()</span>
<span id="cb16-364"><a href="#cb16-364" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb16-365"><a href="#cb16-365" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">0.01</span>, momentum<span class="op">=</span><span class="fl">0.9</span>)</span>
<span id="cb16-366"><a href="#cb16-366" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-367"><a href="#cb16-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-368"><a href="#cb16-368" aria-hidden="true" tabindex="-1"></a><span class="fu">### Evaluation</span></span>
<span id="cb16-369"><a href="#cb16-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-370"><a href="#cb16-370" aria-hidden="true" tabindex="-1"></a>And now, let's actually train and evaluate it.</span>
<span id="cb16-371"><a href="#cb16-371" aria-hidden="true" tabindex="-1"></a>If you're following along, this step can take quite a while...</span>
<span id="cb16-372"><a href="#cb16-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-375"><a href="#cb16-375" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-376"><a href="#cb16-376" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Train a neural network</span></span>
<span id="cb16-377"><a href="#cb16-377" aria-hidden="true" tabindex="-1"></a><span class="co"># Do one pass over the dataset</span></span>
<span id="cb16-378"><a href="#cb16-378" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, data <span class="kw">in</span> <span class="bu">enumerate</span>(trainloader, <span class="dv">0</span>):</span>
<span id="cb16-379"><a href="#cb16-379" aria-hidden="true" tabindex="-1"></a>    inputs, labels <span class="op">=</span> data</span>
<span id="cb16-380"><a href="#cb16-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-381"><a href="#cb16-381" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Resent the gradients</span></span>
<span id="cb16-382"><a href="#cb16-382" aria-hidden="true" tabindex="-1"></a>    optimizer.zero_grad()</span>
<span id="cb16-383"><a href="#cb16-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-384"><a href="#cb16-384" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward/backward pass</span></span>
<span id="cb16-385"><a href="#cb16-385" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model(inputs)</span>
<span id="cb16-386"><a href="#cb16-386" aria-hidden="true" tabindex="-1"></a>    loss <span class="op">=</span> criterion(outputs, labels)</span>
<span id="cb16-387"><a href="#cb16-387" aria-hidden="true" tabindex="-1"></a>    loss.backward()</span>
<span id="cb16-388"><a href="#cb16-388" aria-hidden="true" tabindex="-1"></a>    optimizer.step()</span>
<span id="cb16-389"><a href="#cb16-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-390"><a href="#cb16-390" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate network</span></span>
<span id="cb16-391"><a href="#cb16-391" aria-hidden="true" tabindex="-1"></a>y_test, y_pred <span class="op">=</span> [], []</span>
<span id="cb16-392"><a href="#cb16-392" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb16-393"><a href="#cb16-393" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> data <span class="kw">in</span> testloader:</span>
<span id="cb16-394"><a href="#cb16-394" aria-hidden="true" tabindex="-1"></a>        inputs, labels <span class="op">=</span> data</span>
<span id="cb16-395"><a href="#cb16-395" aria-hidden="true" tabindex="-1"></a>        outputs <span class="op">=</span> model(inputs)</span>
<span id="cb16-396"><a href="#cb16-396" aria-hidden="true" tabindex="-1"></a>        _, pred <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data, <span class="dv">1</span>)</span>
<span id="cb16-397"><a href="#cb16-397" aria-hidden="true" tabindex="-1"></a>        y_test.extend(labels)</span>
<span id="cb16-398"><a href="#cb16-398" aria-hidden="true" tabindex="-1"></a>        y_pred.extend(pred)</span>
<span id="cb16-399"><a href="#cb16-399" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Accuracy:  </span><span class="sc">{</span>accuracy_score(y_test, y_pred)<span class="sc">:.4f}</span><span class="ch">\n</span><span class="ss">"</span></span>
<span id="cb16-400"><a href="#cb16-400" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"Precision: </span><span class="sc">{</span>precision_score(y_test, y_pred, average<span class="op">=</span><span class="st">'macro'</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb16-401"><a href="#cb16-401" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-402"><a href="#cb16-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-405"><a href="#cb16-405" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-406"><a href="#cb16-406" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-407"><a href="#cb16-407" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Code for plotting the confusion matrix</span></span>
<span id="cb16-408"><a href="#cb16-408" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-align: center</span></span>
<span id="cb16-409"><a href="#cb16-409" aria-hidden="true" tabindex="-1"></a>conf <span class="op">=</span> confusion_matrix(y_test, y_pred)</span>
<span id="cb16-410"><a href="#cb16-410" aria-hidden="true" tabindex="-1"></a>df_cm <span class="op">=</span> pd.DataFrame(conf, index<span class="op">=</span>names, columns<span class="op">=</span>names)</span>
<span id="cb16-411"><a href="#cb16-411" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="fl">8.5</span>,<span class="dv">7</span>))</span>
<span id="cb16-412"><a href="#cb16-412" aria-hidden="true" tabindex="-1"></a>sn.heatmap(df_cm, annot<span class="op">=</span><span class="va">True</span>, fmt<span class="op">=</span><span class="st">'d'</span>)<span class="op">;</span></span>
<span id="cb16-413"><a href="#cb16-413" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-414"><a href="#cb16-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-415"><a href="#cb16-415" aria-hidden="true" tabindex="-1"></a>Yay, it's finished!</span>
<span id="cb16-416"><a href="#cb16-416" aria-hidden="true" tabindex="-1"></a>The performance above is not too shabby, although bigger and better-trained models should attain a few more percent of accuracy.</span>
<span id="cb16-417"><a href="#cb16-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-418"><a href="#cb16-418" aria-hidden="true" tabindex="-1"></a>The adjacency matrix also reveals some digit pairs that commonly confuse the model.</span>
<span id="cb16-419"><a href="#cb16-419" aria-hidden="true" tabindex="-1"></a>Let's find some mislabeled examples to see how fair they are.</span>
<span id="cb16-420"><a href="#cb16-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-423"><a href="#cb16-423" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb16-424"><a href="#cb16-424" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb16-425"><a href="#cb16-425" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Show test samples with mistakes</span></span>
<span id="cb16-426"><a href="#cb16-426" aria-hidden="true" tabindex="-1"></a><span class="co">#| layout-ncol: 4</span></span>
<span id="cb16-427"><a href="#cb16-427" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb16-428"><a href="#cb16-428" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb16-429"><a href="#cb16-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-430"><a href="#cb16-430" aria-hidden="true" tabindex="-1"></a><span class="co"># Get samples where mistakes were made</span></span>
<span id="cb16-431"><a href="#cb16-431" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> wrong(dataloader):</span>
<span id="cb16-432"><a href="#cb16-432" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, (images, labels) <span class="kw">in</span> <span class="bu">enumerate</span>(testloader):</span>
<span id="cb16-433"><a href="#cb16-433" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j, (image, label) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(images, labels)):</span>
<span id="cb16-434"><a href="#cb16-434" aria-hidden="true" tabindex="-1"></a>            label, pred <span class="op">=</span> label.item(), y_pred[batch_size<span class="op">*</span>i<span class="op">+</span>j].item()</span>
<span id="cb16-435"><a href="#cb16-435" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> pred <span class="op">!=</span> label:</span>
<span id="cb16-436"><a href="#cb16-436" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> (image, label, pred)</span>
<span id="cb16-437"><a href="#cb16-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-438"><a href="#cb16-438" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot several examples</span></span>
<span id="cb16-439"><a href="#cb16-439" aria-hidden="true" tabindex="-1"></a>loader <span class="op">=</span> wrong(testloader)</span>
<span id="cb16-440"><a href="#cb16-440" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">4</span>):</span>
<span id="cb16-441"><a href="#cb16-441" aria-hidden="true" tabindex="-1"></a>    image, label, pred <span class="op">=</span> <span class="bu">next</span>(loader)</span>
<span id="cb16-442"><a href="#cb16-442" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> np.transpose(image, (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>))</span>
<span id="cb16-443"><a href="#cb16-443" aria-hidden="true" tabindex="-1"></a>    plt.imshow(img, cmap<span class="op">=</span><span class="st">'Greys'</span>)</span>
<span id="cb16-444"><a href="#cb16-444" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="ss">f"Actual: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ch">\n</span><span class="ss">Predicted: </span><span class="sc">{</span>pred<span class="sc">}</span><span class="ss">"</span>, size<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-445"><a href="#cb16-445" aria-hidden="true" tabindex="-1"></a>    plt.xticks([],[])</span>
<span id="cb16-446"><a href="#cb16-446" aria-hidden="true" tabindex="-1"></a>    plt.yticks([],[])</span>
<span id="cb16-447"><a href="#cb16-447" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb16-448"><a href="#cb16-448" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb16-449"><a href="#cb16-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-450"><a href="#cb16-450" aria-hidden="true" tabindex="-1"></a>Personally, I think these are still very comprehensible, maybe just a bit unusual.</span>
<span id="cb16-451"><a href="#cb16-451" aria-hidden="true" tabindex="-1"></a>Even though the model does not get these, it apparently does many more - which I think is fair to call a success.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/adidenkova/blog/blob/main/posts/4-classification.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li></ul></div></div></div></footer></body></html>