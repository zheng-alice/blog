<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-12-02">
<meta name="description" content="In which we overview common tasks and models for clustering. Includes an exploration of spectral clustering and sparse subspace clustering, and an implementation of the latter.">

<title>blog - Clustering</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
if (typeof require !== 'undefined') {
require.undef("plotly");
requirejs.config({
    paths: {
        'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']
    }
});
require(['plotly'], function(Plotly) {
    window._Plotly = Plotly;
});
}
</script>


  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#clustering" id="toc-clustering" class="nav-link active" data-scroll-target="#clustering">Clustering</a>
  <ul class="collapse">
  <li><a href="#examples" id="toc-examples" class="nav-link" data-scroll-target="#examples">Examples</a></li>
  <li><a href="#spectral-clustering" id="toc-spectral-clustering" class="nav-link" data-scroll-target="#spectral-clustering">Spectral Clustering</a></li>
  <li><a href="#linearity" id="toc-linearity" class="nav-link" data-scroll-target="#linearity">Linearity</a></li>
  </ul></li>
  <li><a href="#sparse-subspace-clustering" id="toc-sparse-subspace-clustering" class="nav-link" data-scroll-target="#sparse-subspace-clustering">Sparse Subspace Clustering</a>
  <ul class="collapse">
  <li><a href="#convex-optimization" id="toc-convex-optimization" class="nav-link" data-scroll-target="#convex-optimization">Convex optimization</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation">Implementation</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/adidenkova/blog/blob/main/posts/2-clustering.qmd" class="toc-action">View source</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Clustering</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Sparse subspace clustering</p>
  <div class="quarto-categories">
    <div class="quarto-category">Clustering</div>
    <div class="quarto-category">Unsupervised learning</div>
    <div class="quarto-category">Eigenvalues</div>
    <div class="quarto-category">Convex optimization</div>
  </div>
  </div>

<div>
  <div class="description">
    In which we overview common tasks and models for clustering. Includes an exploration of spectral clustering and sparse subspace clustering, and an implementation of the latter.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 2, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<!-- Identify the common tasks in machine learning/data mining models for clustering. -->
<section id="clustering" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="clustering">Clustering</h2>
<p>Falling within the realm of <strong>unsupervised learning</strong>, this task deals with unlabeled but adequately distinct data. While both it and <a href="../posts/4-classification.html">classification</a> involve modeling such differences, clustering in particular starts with no prior informaiton about data labels. In cases where partial label information is known, the task is instead considered to be semi-supervised.</p>
<p>The common goal of clustering is to separate data into <strong>clusters</strong> - groups such that data within them is similar and between them is different. What this means precisely depends on the measure of similarity used; for raw Euclidean distances it would mean that clusters are far apart literally, whereas for feature embedding spaces they would be apart semantically/conceptually.</p>
<p>Clustering serves a variety of <strong>purposes</strong>:</p>
<ul>
<li><strong>Understanding:</strong> separating data into distinct groups may reveal patterns and highlight important features. Additionally, clustering may be viewed as a form of divide-and-conquer where the clusters may be easier to analyze in isolation.</li>
<li><strong>Preprocessing:</strong> similar to the above, the benefit of being able to analyze data separately can be extended to programmatic solutions. That is, cluster assignment can be used to split data and train models separately for each.</li>
<li><strong>Anomaly detection:</strong> the above would additionally get rid of outliers as they wouldn’t belong to any cluster. This makes clustering applicable to <a href="../posts/5-anomaly.html">anomaly detection</a> as it can identify points that are distant from all other data.</li>
</ul>
<p>Clustering in itself isn’t a method but a task. A plethora of algorithms exist to perform it, thanks to various relevant <strong>considerations</strong> about the type of clustered data:</p>
<ul>
<li><strong>Shape:</strong> while we may typically think of clusters as circular-like objects, they may instead be stretched, spread out, stretched out, bent, etc. For the stretched out type, it additionally becomes important whether data exhibits linear relationships or otherwise lies in nonlinear manifolds.</li>
<li><strong>Data type:</strong> the same considerations from other tasks in machine learning apply: is the data numerical or categorical, are any transforms applicable, is some of the data images/audio/text/etc?</li>
<li><strong>Dimensionality:</strong> for more complex data types, preprocessing or embedding may be in order. High-dimensional data in general poses a challenge due to the <em>curse of dimensionality</em>, a phenomenon where regular measures of distance break down and lose meaning. In some circumstances it thus becomes crucial to use methods specifically designed around high-dimensional data.</li>
</ul>
<section id="examples" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="examples">Examples</h3>
<p>To illustrate the former consideration particularly, we can take a look at some distinct sets of artificial data and the performances of various clustering algorithms. Here’s a pretty nice visualization of some common algorithms:</p>
<div class="cell page-columns page-full" data-execution_count="1">
<details>
<summary>Clustering scatterplot matrix code by <a href="https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html">sklearn</a></summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> cycle, islice</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> cluster, datasets, mixture</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> kneighbors_graph</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ssc <span class="im">import</span> linear, SparseSubspaceClustering</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ============</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate datasets. We choose the size big enough to see the scalability</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># of the algorithms, but not too big to avoid too long running times</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ============</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">5805</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>noisy_circles <span class="op">=</span> datasets.make_circles(</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span>n_samples, factor<span class="op">=</span><span class="fl">0.5</span>, noise<span class="op">=</span><span class="fl">0.05</span>, random_state<span class="op">=</span>seed</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>noisy_moons <span class="op">=</span> datasets.make_moons(n_samples<span class="op">=</span>n_samples, noise<span class="op">=</span><span class="fl">0.05</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>blobs <span class="op">=</span> datasets.make_blobs(n_samples<span class="op">=</span>n_samples, random_state<span class="op">=</span>seed)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(seed)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>no_structure <span class="op">=</span> rng.rand(n_samples, <span class="dv">2</span>), <span class="va">None</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Anisotropicly distributed data</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>random_state <span class="op">=</span> <span class="dv">5805</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> datasets.make_blobs(n_samples<span class="op">=</span>n_samples, random_state<span class="op">=</span>random_state)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>transformation <span class="op">=</span> [[<span class="fl">0.6</span>, <span class="op">-</span><span class="fl">0.6</span>], [<span class="op">-</span><span class="fl">0.4</span>, <span class="fl">0.8</span>]]</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>X_aniso <span class="op">=</span> np.dot(X, transformation)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>aniso <span class="op">=</span> (X_aniso, y)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># blobs with varied variances</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>varied <span class="op">=</span> datasets.make_blobs(</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span>n_samples, cluster_std<span class="op">=</span>[<span class="fl">1.0</span>, <span class="fl">2.5</span>, <span class="fl">0.5</span>], random_state<span class="op">=</span>random_state</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a><span class="co"># ============</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up cluster parameters</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co"># ============</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">10.5</span>, <span class="fl">6.5</span>))</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>    left<span class="op">=</span><span class="fl">0.02</span>, right<span class="op">=</span><span class="fl">0.98</span>, bottom<span class="op">=</span><span class="fl">0.001</span>, top<span class="op">=</span><span class="fl">0.95</span>, wspace<span class="op">=</span><span class="fl">0.01</span>, hspace<span class="op">=</span><span class="fl">0.01</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>plot_num <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>default_base <span class="op">=</span> {</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>    <span class="st">"quantile"</span>: <span class="fl">0.3</span>,</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eps"</span>: <span class="fl">0.3</span>,</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>    <span class="st">"damping"</span>: <span class="fl">0.9</span>,</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    <span class="st">"preference"</span>: <span class="op">-</span><span class="dv">200</span>,</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_neighbors"</span>: <span class="dv">3</span>,</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_clusters"</span>: <span class="dv">3</span>,</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">"xi"</span>: <span class="fl">0.05</span>,</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_cluster_size"</span>: <span class="fl">0.1</span>,</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>    <span class="st">"allow_single_cluster"</span>: <span class="va">True</span>,</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    <span class="st">"hdbscan_min_cluster_size"</span>: <span class="dv">15</span>,</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    <span class="st">"hdbscan_min_samples"</span>: <span class="dv">3</span>,</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    <span class="st">"random_state"</span>: <span class="dv">42</span>,</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>datasets <span class="op">=</span> [</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>        noisy_circles,</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>            <span class="st">"damping"</span>: <span class="fl">0.77</span>,</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>            <span class="st">"preference"</span>: <span class="op">-</span><span class="dv">240</span>,</span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>            <span class="st">"quantile"</span>: <span class="fl">0.2</span>,</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_clusters"</span>: <span class="dv">2</span>,</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>            <span class="st">"xi"</span>: <span class="fl">0.08</span>,</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>        noisy_moons,</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>            <span class="st">"damping"</span>: <span class="fl">0.75</span>,</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>            <span class="st">"preference"</span>: <span class="op">-</span><span class="dv">220</span>,</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_clusters"</span>: <span class="dv">2</span>,</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>            <span class="st">"xi"</span>: <span class="fl">0.1</span>,</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>        varied,</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>            <span class="st">"eps"</span>: <span class="fl">0.18</span>,</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_neighbors"</span>: <span class="dv">2</span>,</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>            <span class="st">"xi"</span>: <span class="fl">0.01</span>,</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_cluster_size"</span>: <span class="fl">0.2</span>,</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>        aniso,</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>            <span class="st">"eps"</span>: <span class="fl">0.15</span>,</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_neighbors"</span>: <span class="dv">2</span>,</span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a>            <span class="st">"xi"</span>: <span class="fl">0.1</span>,</span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_cluster_size"</span>: <span class="fl">0.2</span>,</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a>    (blobs, {<span class="st">"min_samples"</span>: <span class="dv">7</span>, <span class="st">"xi"</span>: <span class="fl">0.1</span>, <span class="st">"min_cluster_size"</span>: <span class="fl">0.2</span>}),</span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a>    (linear, {}),</span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a>    (no_structure, {}),</span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i_dataset, (dataset, algo_params) <span class="kw">in</span> <span class="bu">enumerate</span>(datasets):</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a>    <span class="co"># update parameters with dataset-specific values</span></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> default_base.copy()</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a>    params.update(algo_params)</span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-118"><a href="#cb1-118" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> dataset</span>
<span id="cb1-119"><a href="#cb1-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-120"><a href="#cb1-120" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize dataset for easier parameter selection</span></span>
<span id="cb1-121"><a href="#cb1-121" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> StandardScaler().fit_transform(X)</span>
<span id="cb1-122"><a href="#cb1-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-123"><a href="#cb1-123" aria-hidden="true" tabindex="-1"></a>    <span class="co"># estimate bandwidth for mean shift</span></span>
<span id="cb1-124"><a href="#cb1-124" aria-hidden="true" tabindex="-1"></a>    bandwidth <span class="op">=</span> cluster.estimate_bandwidth(X, quantile<span class="op">=</span>params[<span class="st">"quantile"</span>])</span>
<span id="cb1-125"><a href="#cb1-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-126"><a href="#cb1-126" aria-hidden="true" tabindex="-1"></a>    <span class="co"># connectivity matrix for structured Ward</span></span>
<span id="cb1-127"><a href="#cb1-127" aria-hidden="true" tabindex="-1"></a>    connectivity <span class="op">=</span> kneighbors_graph(</span>
<span id="cb1-128"><a href="#cb1-128" aria-hidden="true" tabindex="-1"></a>        X, n_neighbors<span class="op">=</span>params[<span class="st">"n_neighbors"</span>], include_self<span class="op">=</span><span class="va">False</span></span>
<span id="cb1-129"><a href="#cb1-129" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-130"><a href="#cb1-130" aria-hidden="true" tabindex="-1"></a>    <span class="co"># make connectivity symmetric</span></span>
<span id="cb1-131"><a href="#cb1-131" aria-hidden="true" tabindex="-1"></a>    connectivity <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> (connectivity <span class="op">+</span> connectivity.T)</span>
<span id="cb1-132"><a href="#cb1-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-133"><a href="#cb1-133" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============</span></span>
<span id="cb1-134"><a href="#cb1-134" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create cluster objects</span></span>
<span id="cb1-135"><a href="#cb1-135" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============</span></span>
<span id="cb1-136"><a href="#cb1-136" aria-hidden="true" tabindex="-1"></a>    ms <span class="op">=</span> cluster.MeanShift(bandwidth<span class="op">=</span>bandwidth, bin_seeding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-137"><a href="#cb1-137" aria-hidden="true" tabindex="-1"></a>    two_means <span class="op">=</span> cluster.MiniBatchKMeans(</span>
<span id="cb1-138"><a href="#cb1-138" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb1-139"><a href="#cb1-139" aria-hidden="true" tabindex="-1"></a>        n_init<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb1-140"><a href="#cb1-140" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span>params[<span class="st">"random_state"</span>],</span>
<span id="cb1-141"><a href="#cb1-141" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-142"><a href="#cb1-142" aria-hidden="true" tabindex="-1"></a>    ward <span class="op">=</span> cluster.AgglomerativeClustering(</span>
<span id="cb1-143"><a href="#cb1-143" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>], linkage<span class="op">=</span><span class="st">"ward"</span>, connectivity<span class="op">=</span>connectivity</span>
<span id="cb1-144"><a href="#cb1-144" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-145"><a href="#cb1-145" aria-hidden="true" tabindex="-1"></a>    spectral <span class="op">=</span> cluster.SpectralClustering(</span>
<span id="cb1-146"><a href="#cb1-146" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb1-147"><a href="#cb1-147" aria-hidden="true" tabindex="-1"></a>        eigen_solver<span class="op">=</span><span class="st">"arpack"</span>,</span>
<span id="cb1-148"><a href="#cb1-148" aria-hidden="true" tabindex="-1"></a>        affinity<span class="op">=</span><span class="st">"nearest_neighbors"</span>,</span>
<span id="cb1-149"><a href="#cb1-149" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span>params[<span class="st">"random_state"</span>],</span>
<span id="cb1-150"><a href="#cb1-150" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-151"><a href="#cb1-151" aria-hidden="true" tabindex="-1"></a>    dbscan <span class="op">=</span> cluster.DBSCAN(eps<span class="op">=</span>params[<span class="st">"eps"</span>])</span>
<span id="cb1-152"><a href="#cb1-152" aria-hidden="true" tabindex="-1"></a>    hdbscan <span class="op">=</span> cluster.HDBSCAN(</span>
<span id="cb1-153"><a href="#cb1-153" aria-hidden="true" tabindex="-1"></a>        min_samples<span class="op">=</span>params[<span class="st">"hdbscan_min_samples"</span>],</span>
<span id="cb1-154"><a href="#cb1-154" aria-hidden="true" tabindex="-1"></a>        min_cluster_size<span class="op">=</span>params[<span class="st">"hdbscan_min_cluster_size"</span>],</span>
<span id="cb1-155"><a href="#cb1-155" aria-hidden="true" tabindex="-1"></a>        allow_single_cluster<span class="op">=</span>params[<span class="st">"allow_single_cluster"</span>],</span>
<span id="cb1-156"><a href="#cb1-156" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-157"><a href="#cb1-157" aria-hidden="true" tabindex="-1"></a>    optics <span class="op">=</span> cluster.OPTICS(</span>
<span id="cb1-158"><a href="#cb1-158" aria-hidden="true" tabindex="-1"></a>        min_samples<span class="op">=</span>params[<span class="st">"min_samples"</span>],</span>
<span id="cb1-159"><a href="#cb1-159" aria-hidden="true" tabindex="-1"></a>        xi<span class="op">=</span>params[<span class="st">"xi"</span>],</span>
<span id="cb1-160"><a href="#cb1-160" aria-hidden="true" tabindex="-1"></a>        min_cluster_size<span class="op">=</span>params[<span class="st">"min_cluster_size"</span>],</span>
<span id="cb1-161"><a href="#cb1-161" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-162"><a href="#cb1-162" aria-hidden="true" tabindex="-1"></a>    affinity_propagation <span class="op">=</span> cluster.AffinityPropagation(</span>
<span id="cb1-163"><a href="#cb1-163" aria-hidden="true" tabindex="-1"></a>        damping<span class="op">=</span>params[<span class="st">"damping"</span>],</span>
<span id="cb1-164"><a href="#cb1-164" aria-hidden="true" tabindex="-1"></a>        preference<span class="op">=</span>params[<span class="st">"preference"</span>],</span>
<span id="cb1-165"><a href="#cb1-165" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span>params[<span class="st">"random_state"</span>],</span>
<span id="cb1-166"><a href="#cb1-166" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-167"><a href="#cb1-167" aria-hidden="true" tabindex="-1"></a>    average_linkage <span class="op">=</span> cluster.AgglomerativeClustering(</span>
<span id="cb1-168"><a href="#cb1-168" aria-hidden="true" tabindex="-1"></a>        linkage<span class="op">=</span><span class="st">"average"</span>,</span>
<span id="cb1-169"><a href="#cb1-169" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span><span class="st">"cityblock"</span>,</span>
<span id="cb1-170"><a href="#cb1-170" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb1-171"><a href="#cb1-171" aria-hidden="true" tabindex="-1"></a>        connectivity<span class="op">=</span>connectivity,</span>
<span id="cb1-172"><a href="#cb1-172" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-173"><a href="#cb1-173" aria-hidden="true" tabindex="-1"></a>    birch <span class="op">=</span> cluster.Birch(n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>])</span>
<span id="cb1-174"><a href="#cb1-174" aria-hidden="true" tabindex="-1"></a>    gmm <span class="op">=</span> mixture.GaussianMixture(</span>
<span id="cb1-175"><a href="#cb1-175" aria-hidden="true" tabindex="-1"></a>        n_components<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb1-176"><a href="#cb1-176" aria-hidden="true" tabindex="-1"></a>        covariance_type<span class="op">=</span><span class="st">"full"</span>,</span>
<span id="cb1-177"><a href="#cb1-177" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span>params[<span class="st">"random_state"</span>],</span>
<span id="cb1-178"><a href="#cb1-178" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-179"><a href="#cb1-179" aria-hidden="true" tabindex="-1"></a>    ssc <span class="op">=</span> SparseSubspaceClustering(</span>
<span id="cb1-180"><a href="#cb1-180" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb1-181"><a href="#cb1-181" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-182"><a href="#cb1-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-183"><a href="#cb1-183" aria-hidden="true" tabindex="-1"></a>    clustering_algorithms <span class="op">=</span> (</span>
<span id="cb1-184"><a href="#cb1-184" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"MiniBatch</span><span class="ch">\n</span><span class="st">KMeans"</span>, two_means),</span>
<span id="cb1-185"><a href="#cb1-185" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Affinity</span><span class="ch">\n</span><span class="st">Propagation"</span>, affinity_propagation),</span>
<span id="cb1-186"><a href="#cb1-186" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"MeanShift"</span>, ms),</span>
<span id="cb1-187"><a href="#cb1-187" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Spectral</span><span class="ch">\n</span><span class="st">Clustering"</span>, spectral),</span>
<span id="cb1-188"><a href="#cb1-188" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Ward"</span>, ward),</span>
<span id="cb1-189"><a href="#cb1-189" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Agglomerative</span><span class="ch">\n</span><span class="st">Clustering"</span>, average_linkage),</span>
<span id="cb1-190"><a href="#cb1-190" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"DBSCAN"</span>, dbscan),</span>
<span id="cb1-191"><a href="#cb1-191" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"HDBSCAN"</span>, hdbscan),</span>
<span id="cb1-192"><a href="#cb1-192" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"OPTICS"</span>, optics),</span>
<span id="cb1-193"><a href="#cb1-193" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"BIRCH"</span>, birch),</span>
<span id="cb1-194"><a href="#cb1-194" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Gaussian</span><span class="ch">\n</span><span class="st">Mixture"</span>, gmm),</span>
<span id="cb1-195"><a href="#cb1-195" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Sparse</span><span class="ch">\n</span><span class="st">Subspace</span><span class="ch">\n</span><span class="st">Clustering"</span>, ssc),</span>
<span id="cb1-196"><a href="#cb1-196" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-197"><a href="#cb1-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-198"><a href="#cb1-198" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, algorithm <span class="kw">in</span> clustering_algorithms:</span>
<span id="cb1-199"><a href="#cb1-199" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb1-200"><a href="#cb1-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-201"><a href="#cb1-201" aria-hidden="true" tabindex="-1"></a>        <span class="co"># catch warnings related to kneighbors_graph, subspace clustering</span></span>
<span id="cb1-202"><a href="#cb1-202" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb1-203"><a href="#cb1-203" aria-hidden="true" tabindex="-1"></a>            warnings.filterwarnings(</span>
<span id="cb1-204"><a href="#cb1-204" aria-hidden="true" tabindex="-1"></a>                <span class="st">"ignore"</span>,</span>
<span id="cb1-205"><a href="#cb1-205" aria-hidden="true" tabindex="-1"></a>                message<span class="op">=</span><span class="st">"the number of connected components of the "</span></span>
<span id="cb1-206"><a href="#cb1-206" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">"connectivity matrix is [0-9]{1,2}"</span></span>
<span id="cb1-207"><a href="#cb1-207" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">" &gt; 1. Completing it to avoid stopping the tree early."</span>,</span>
<span id="cb1-208"><a href="#cb1-208" aria-hidden="true" tabindex="-1"></a>                category<span class="op">=</span><span class="pp">UserWarning</span>,</span>
<span id="cb1-209"><a href="#cb1-209" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-210"><a href="#cb1-210" aria-hidden="true" tabindex="-1"></a>            warnings.filterwarnings(</span>
<span id="cb1-211"><a href="#cb1-211" aria-hidden="true" tabindex="-1"></a>                <span class="st">"ignore"</span>,</span>
<span id="cb1-212"><a href="#cb1-212" aria-hidden="true" tabindex="-1"></a>                message<span class="op">=</span><span class="st">"Graph is not fully connected, spectral embedding"</span></span>
<span id="cb1-213"><a href="#cb1-213" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">" may not work as expected."</span>,</span>
<span id="cb1-214"><a href="#cb1-214" aria-hidden="true" tabindex="-1"></a>                category<span class="op">=</span><span class="pp">UserWarning</span>,</span>
<span id="cb1-215"><a href="#cb1-215" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-216"><a href="#cb1-216" aria-hidden="true" tabindex="-1"></a>            warnings.filterwarnings(</span>
<span id="cb1-217"><a href="#cb1-217" aria-hidden="true" tabindex="-1"></a>                <span class="st">"ignore"</span>,</span>
<span id="cb1-218"><a href="#cb1-218" aria-hidden="true" tabindex="-1"></a>                message<span class="op">=</span><span class="st">"Solution may be inaccurate. Try another solver,"</span></span>
<span id="cb1-219"><a href="#cb1-219" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">" adjusting the solver settings, or solve with"</span></span>
<span id="cb1-220"><a href="#cb1-220" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">" verbose=True for more information."</span>,</span>
<span id="cb1-221"><a href="#cb1-221" aria-hidden="true" tabindex="-1"></a>                category<span class="op">=</span><span class="pp">UserWarning</span>,</span>
<span id="cb1-222"><a href="#cb1-222" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-223"><a href="#cb1-223" aria-hidden="true" tabindex="-1"></a>            algorithm.fit(X)</span>
<span id="cb1-224"><a href="#cb1-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-225"><a href="#cb1-225" aria-hidden="true" tabindex="-1"></a>        t1 <span class="op">=</span> time.time()</span>
<span id="cb1-226"><a href="#cb1-226" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(algorithm, <span class="st">"labels_"</span>):</span>
<span id="cb1-227"><a href="#cb1-227" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> algorithm.labels_.astype(<span class="bu">int</span>)</span>
<span id="cb1-228"><a href="#cb1-228" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-229"><a href="#cb1-229" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> algorithm.predict(X)</span>
<span id="cb1-230"><a href="#cb1-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-231"><a href="#cb1-231" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="bu">len</span>(datasets), <span class="bu">len</span>(clustering_algorithms), plot_num)</span>
<span id="cb1-232"><a href="#cb1-232" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i_dataset <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb1-233"><a href="#cb1-233" aria-hidden="true" tabindex="-1"></a>            plt.title(name, size<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb1-234"><a href="#cb1-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-235"><a href="#cb1-235" aria-hidden="true" tabindex="-1"></a>        colors <span class="op">=</span> np.array(</span>
<span id="cb1-236"><a href="#cb1-236" aria-hidden="true" tabindex="-1"></a>            <span class="bu">list</span>(</span>
<span id="cb1-237"><a href="#cb1-237" aria-hidden="true" tabindex="-1"></a>                islice(</span>
<span id="cb1-238"><a href="#cb1-238" aria-hidden="true" tabindex="-1"></a>                    cycle(</span>
<span id="cb1-239"><a href="#cb1-239" aria-hidden="true" tabindex="-1"></a>                        [</span>
<span id="cb1-240"><a href="#cb1-240" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#377eb8"</span>,</span>
<span id="cb1-241"><a href="#cb1-241" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#ff7f00"</span>,</span>
<span id="cb1-242"><a href="#cb1-242" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#4daf4a"</span>,</span>
<span id="cb1-243"><a href="#cb1-243" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#f781bf"</span>,</span>
<span id="cb1-244"><a href="#cb1-244" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#a65628"</span>,</span>
<span id="cb1-245"><a href="#cb1-245" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#984ea3"</span>,</span>
<span id="cb1-246"><a href="#cb1-246" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#999999"</span>,</span>
<span id="cb1-247"><a href="#cb1-247" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#e41a1c"</span>,</span>
<span id="cb1-248"><a href="#cb1-248" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#dede00"</span>,</span>
<span id="cb1-249"><a href="#cb1-249" aria-hidden="true" tabindex="-1"></a>                        ]</span>
<span id="cb1-250"><a href="#cb1-250" aria-hidden="true" tabindex="-1"></a>                    ),</span>
<span id="cb1-251"><a href="#cb1-251" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">int</span>(<span class="bu">max</span>(y_pred) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb1-252"><a href="#cb1-252" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb1-253"><a href="#cb1-253" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb1-254"><a href="#cb1-254" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-255"><a href="#cb1-255" aria-hidden="true" tabindex="-1"></a>        <span class="co"># add black color for outliers (if any)</span></span>
<span id="cb1-256"><a href="#cb1-256" aria-hidden="true" tabindex="-1"></a>        colors <span class="op">=</span> np.append(colors, [<span class="st">"#000000"</span>])</span>
<span id="cb1-257"><a href="#cb1-257" aria-hidden="true" tabindex="-1"></a>        plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">5</span>, color<span class="op">=</span>colors[y_pred])</span>
<span id="cb1-258"><a href="#cb1-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-259"><a href="#cb1-259" aria-hidden="true" tabindex="-1"></a>        plt.xlim(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>)</span>
<span id="cb1-260"><a href="#cb1-260" aria-hidden="true" tabindex="-1"></a>        plt.ylim(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>)</span>
<span id="cb1-261"><a href="#cb1-261" aria-hidden="true" tabindex="-1"></a>        plt.xticks(())</span>
<span id="cb1-262"><a href="#cb1-262" aria-hidden="true" tabindex="-1"></a>        plt.yticks(())</span>
<span id="cb1-263"><a href="#cb1-263" aria-hidden="true" tabindex="-1"></a>        plt.text(</span>
<span id="cb1-264"><a href="#cb1-264" aria-hidden="true" tabindex="-1"></a>            <span class="fl">0.99</span>,</span>
<span id="cb1-265"><a href="#cb1-265" aria-hidden="true" tabindex="-1"></a>            <span class="fl">0.01</span>,</span>
<span id="cb1-266"><a href="#cb1-266" aria-hidden="true" tabindex="-1"></a>            (<span class="st">"</span><span class="sc">%.2f</span><span class="st">s"</span> <span class="op">%</span> (t1 <span class="op">-</span> t0)).lstrip(<span class="st">"0"</span>),</span>
<span id="cb1-267"><a href="#cb1-267" aria-hidden="true" tabindex="-1"></a>            transform<span class="op">=</span>plt.gca().transAxes,</span>
<span id="cb1-268"><a href="#cb1-268" aria-hidden="true" tabindex="-1"></a>            size<span class="op">=</span><span class="fl">7.5</span>,</span>
<span id="cb1-269"><a href="#cb1-269" aria-hidden="true" tabindex="-1"></a>            horizontalalignment<span class="op">=</span><span class="st">"right"</span>,</span>
<span id="cb1-270"><a href="#cb1-270" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb1-271"><a href="#cb1-271" aria-hidden="true" tabindex="-1"></a>        plot_num <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-272"><a href="#cb1-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-273"><a href="#cb1-273" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display column-page">
<div id="fig-clustering" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="2-clustering_files/figure-html/fig-clustering-output-1.png" width="987" height="658" class="figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: A comparison of various clustering methods.</figcaption>
</figure>
</div>
</div>
</div>
<p>Whoa, that’s a lot of them! If you’ve seen this image before and are particularly observant, you may notice that I threw in an extra algorithm (rightmost column) and a dataset (second-bottom row) - more on those later.</p>
<p>Each of the above algorithms is deserving of a post of its own. Here, I will just briefly focus on one, which happens to be the only showcased algorithm that properly clusters the top 5 datasets:</p>
</section>
<section id="spectral-clustering" class="level3">
<h3 class="anchored" data-anchor-id="spectral-clustering">Spectral Clustering</h3>
<p>Yes, spectral as in <em>spectrum</em> - i.e., <strong>eigenvalues</strong>. I found out about this algorithm back when I was taking intro to linear algebra, and it really stuck with me precisely because it gives a pretty neat interpretation of eigenvalues (which at the time I had a really hard time exemplifying).</p>
<p>We start with a <em>similarity matrix</em> <span class="math inline">\(S\)</span>, where the <span class="math inline">\(ij\)</span>-th value denotes the similarity of data points indexed <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>. What constitutes as being similar may vary; the example in <a href="#fig-clustering">Figure&nbsp;1</a> simply uses Euclidean distance. We then use <span class="math inline">\(S\)</span> to construct a <em>similarity graph</em>, a weighted graph with weights <span class="math inline">\(w_{i,j} = s_{i,j}\)</span> if they are past a certain threshold and <span class="math inline">\(0\)</span> (no edge) otherwise. This graph’s <em>weighted adjacency matrix</em> <span class="math inline">\(W\)</span> is essentially <span class="math inline">\(S\)</span> with all sub-threshold values zeroed out. Assuming data from <span class="math inline">\(k\)</span> sufficiently distinct clusters is ordered by cluster, the adjacency matrix may look something like <span id="eq-block"><span class="math display">\[
W = \begin{bmatrix} W_1 &amp; &amp; &amp; \\ &amp; W_2 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; W_k \end{bmatrix}\ ,
\tag{1}\]</span></span></p>
<p>which you may recognize as a block diagonal matrix.</p>
<p>So, what role do eigenvalues play here? Turns out, if <span class="math inline">\(v\)</span> is an eigenvalue of <span class="math inline">\(W_1\)</span>, then the same <span class="math inline">\(v\)</span> padded by a bunch of zeros at the bottom is an eigenvalue of <span class="math inline">\(W\)</span>. You can verify this via <a href="#eq-block">Equation&nbsp;1</a>; <span class="math inline">\(W_1 v = v \lambda\)</span> necessarily implies <span class="math inline">\(W \begin{bmatrix} v \\ 0 \end{bmatrix} = \begin{bmatrix} v \\ 0 \end{bmatrix} \lambda\)</span>. The same applies for eigenvectors of any cluster, they just need to placed appropriately to act on their cluster’s similarity block <span class="math inline">\(W_i\)</span>. As such, the eigenvalues of <span class="math inline">\(W\)</span> will be grouped according to cluster, having zero values in all other locations. Finding these eigenvalues would then reveal the clusters.</p>
<p>Well… sort of. In reality, we still have some problems: the eigenvalues can have small/zero entries, and finding all <span class="math inline">\(n\)</span> eigenvalues is just too difficult. Instead, we define <span class="math inline">\(D\)</span> to be the diagonal degree matrix, its diagonal entries being the sum of the corresponding rows/columns of <span class="math inline">\(W\)</span>. We then obtain the <em>graph Laplacian</em> <span class="math inline">\(L = D - W\)</span>, another diagonal block matrix with an additional property that its rows/columns sum to zero. This makes it so multiplying each block <span class="math inline">\(L_i\)</span> by a vector with all entries being <span class="math inline">\(1\)</span> produces the zero vector, making it an eigenvector of <span class="math inline">\(L_i\)</span> with a zero eigenvalue. Additionally, the only vectors satisfying this property are just scalar multiples of that identity vector. As such, the Laplacian <span class="math inline">\(L\)</span> will have its zero eigenspace spanned by precisely <span class="math inline">\(k\)</span> such identity vectors. This adresses both of our previous problems, making it so we only have to find <span class="math inline">\(k\)</span> out of <span class="math inline">\(n\)</span> eigenvectors. Using <a href="https://en.wikipedia.org/wiki/Inverse_iteration">inverse iteration</a> will obtain these eigenvectors only, and do so very efficiently. Putting the eigenvectors together as a matrix would then make its rows indicators for which cluster a particular point belongs to. In case there is still any ambiguity, the rows can be grouped together using a simpler clustering algorithm like <a href="https://en.wikipedia.org/wiki/K-means_clustering"><span class="math inline">\(k\)</span>-means</a>. For more details about spectral clustering, see <span class="citation" data-cites="von_luxburg_tutorial_2007">Luxburg (<a href="#ref-von_luxburg_tutorial_2007" role="doc-biblioref">2007</a>)</span>.</p>
<section id="graph-resonance" class="level4">
<h4 class="anchored" data-anchor-id="graph-resonance">Graph resonance</h4>
<p>A pretty cool interpretation of this Laplacian comes from thinking of the nodes in the similarity graph as being connected by springs - the higher the weight between two nodes, the stronger their connecting spring. What happens if we move a single node by some amount? The nodes connected to it would be pulled in the same direction according to the strengths of the springs that connect them to the displaced node, the latter being pulled back with the sum of those strengths. Note that this force is precisely described by the (negative of) the column of <span class="math inline">\(L\)</span> corresponding to the displaced node. If <span class="math inline">\(x\)</span> is the vector representing the displacement of each node, the corresponding force (in the other direction) is given by <span class="math inline">\(Lx\)</span>. In the case where the displacement is an eigenvector of <span class="math inline">\(L\)</span>, we have <span id="eq-hookes"><span class="math display">\[
\sum F = - L v = - \lambda v\ ,
\tag{2}\]</span></span></p>
<p>which is precisely <a href="https://en.wikipedia.org/wiki/Hooke%27s_law">Hooke’s law</a>. Thus given an initial displacement <span class="math inline">\(v\)</span>, the graph will undergo simple harmonic motion with frequency <span class="math inline">\(\lambda^2\)</span>. In other words, the eigenpairs <span class="math inline">\((\lambda, v)\)</span> of <span class="math inline">\(L\)</span> actually describe the <strong>resonant frequencies</strong> <span class="math inline">\(\lambda^2\)</span> and corresponding <strong>vibration modes</strong> of its graph. It is for this reason that eigenvalues are crucial to analyzing mechanical resonance - where the graph represents connected parts of a physical object. This could be applied to, for intance, designing buildings that are resistant to strong winds and earthquakes.</p>
<p>In our case we saw that the similarity graph had some zero eigenvalues. This corresponds to zero frequency - i.e., once we displace the nodes of a single cluster, it experiences no force from the others and just stays in the same place.</p>
</section>
</section>
<section id="linearity" class="level3">
<h3 class="anchored" data-anchor-id="linearity">Linearity</h3>
<p>So, that’s all well and good when similarity relates to Euclidean distance - but as noted before, this becomes less true for high-dimensional data. Instead, data may lie in <em>linear subspaces</em>, such as when representing the same scene illuminated from different angles, or objects moving at different speeds <span class="citation" data-cites="elhamifar_sparse_2013">Elhamifar and Vidal (<a href="#ref-elhamifar_sparse_2013" role="doc-biblioref">2013</a>)</span>. A simplified image of what such data could look like is seen in <a href="#fig-subspaces">Figure&nbsp;2</a> below.</p>
<div id="fig-subspaces" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="subspaces.svg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Three linear subspaces. Figure by <span class="citation" data-cites="elhamifar_sparse_2013">Elhamifar and Vidal (<a href="#ref-elhamifar_sparse_2013" role="doc-biblioref">2013</a>)</span>.</figcaption>
</figure>
</div>
<p>The point where the lines and plane intersect is the origin. You may note that this matches the mathematical definiton of linear subspaces, i.e., non-empty and closed under addition and scalar multiplication. Alternatively, we may pick any number of vectors and have their span be a linear subspaces. Any point in the subspaces would then be a linear combination of such vectors, which are themselves points in the subspace.</p>
<p>You may note that the new dataset is somewhat like a flattened version of <a href="#fig-subspaces">Figure&nbsp;2</a>, with the lines <span class="math inline">\(\mathcal{S}_2\)</span> and <span class="math inline">\(\mathcal{S}_3\)</span> being the diagonals making up the ‘X’ shape, and the plane <span class="math inline">\(\mathcal{S}_1\)</span> being the remaining points in the background square.</p>
<div class="sourceCode" id="cb2" data-startfrom="9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python" style="counter-reset: source-line 8;"><span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'X'-looking dataset</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>linear <span class="op">=</span> np.concatenate((</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        rng.rand(n_samples<span class="op">//</span><span class="dv">2</span>, <span class="dv">2</span>),                              <span class="co"># □ Square</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        rng.rand(n_samples<span class="op">//</span><span class="dv">4</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.05</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> np.repeat(rng.rand(n_samples<span class="op">//</span><span class="dv">4</span>, <span class="dv">1</span>), <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">1</span>),  <span class="co"># / Diagonal</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        rng.rand(n_samples<span class="op">//</span><span class="dv">4</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.05</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            <span class="op">+</span> np.repeat(rng.rand(n_samples<span class="op">//</span><span class="dv">4</span>, <span class="dv">1</span>), <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">1</span>)   <span class="co"># \ Diagonal</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            <span class="op">*</span> [<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> [<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    ), axis<span class="op">=</span><span class="dv">0</span>) <span class="op">-</span> [<span class="fl">0.5</span>, <span class="fl">0.5</span>], <span class="va">None</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Our goal is then to separate the two diagonals and the square.</p>
</section>
</section>
<section id="sparse-subspace-clustering" class="level2">
<h2 class="anchored" data-anchor-id="sparse-subspace-clustering">Sparse Subspace Clustering</h2>
<p>To this end, we will analyze an algorithm based on <a href="#spectral-clustering">spectral clustering</a>, proposed by <span class="citation" data-cites="elhamifar_sparse_2013">Elhamifar and Vidal (<a href="#ref-elhamifar_sparse_2013" role="doc-biblioref">2013</a>)</span>. This algorithm relies on the <em>self-expressiveness</em> property described above, i.e., that points in a subspace can be described by a linear combination of other points from the same subspace. Specifically, let <span class="math inline">\(Y = \begin{bmatrix} y_1 &amp; y_2 &amp; \dots &amp; y_n \end{bmatrix}\)</span> be a <span class="math inline">\(d\)</span>-by-<span class="math inline">\(n\)</span> matrix of data. Then, with every data point <span class="math inline">\(y_i\)</span> we can associate a coefficient vector <span class="math inline">\(c_i\)</span> such that <span id="eq-vector"><span class="math display">\[
y_i = Y c_i\ ,\qquad
c_{ii} = 0\ .
\tag{3}\]</span></span></p>
<p>As the above has infinitely many solutions, we will additionally <span class="math inline">\(\text{minimize} ||c_i||_q\)</span>. Using smaller <span class="math inline">\(q\)</span> will make more coefficients zero, and for <span class="math inline">\(q=1\)</span> will generally only have nonzero coefficients for points within the same subspace.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<p>Letting <span class="math inline">\(C = \begin{bmatrix} c_1 &amp; c_2 &amp; \dots &amp; c_n \end{bmatrix}\)</span>, we can rewrite the problem in matrix form as <span id="eq-matrix"><span class="math display">\[
\begin{align}
    \text{minimize} \quad&amp; ||C||_1 \\
    \text{such that} \quad&amp; Y = Y C\ ,\\
    &amp; \mathrm{diag}(C) = 0\ .
\end{align}
\tag{4}\]</span></span></p>
<p>Note that the objective is convex and the constraints affine, so this can be solved efficiently using</p>
<section id="convex-optimization" class="level3">
<h3 class="anchored" data-anchor-id="convex-optimization">Convex optimization</h3>
<p>A framework for problems with certain nice properties, <a href="https://en.wikipedia.org/wiki/Convex_optimization">convex optimization</a> can be applied to a multitude of tasks in various fields. While I first encountered it in exactly this context of sparse subspace clustering, I now use a variant of it (semidefinite programming) all the time for quantum-related stuff.</p>
<p>Let’s solve an instance of <a href="#eq-matrix">Equation&nbsp;4</a> in practice to see why this matrix <span class="math inline">\(C\)</span> could be useful. First, let’s construct a simplified version of the dataset shown above, containing fewer points and only the diagonals.</p>
<div class="cell" data-execution_count="2">
<details>
<summary>Generate a simpler dataset</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.concatenate((</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    rng.rand(<span class="dv">2</span>, n<span class="op">//</span><span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> np.repeat(rng.rand(<span class="dv">1</span>, n<span class="op">//</span><span class="dv">2</span>), <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">0</span>),  <span class="co"># / Diagonal</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    rng.rand(<span class="dv">2</span>, n<span class="op">//</span><span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> np.repeat(rng.rand(<span class="dv">1</span>, n<span class="op">//</span><span class="dv">2</span>), <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">0</span>)   <span class="co"># \ Diagonal</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="op">*</span> [[<span class="dv">1</span>], [<span class="op">-</span><span class="dv">1</span>]] <span class="op">+</span> [[<span class="dv">0</span>], [<span class="dv">1</span>]]</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>), axis<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> [[<span class="fl">0.5</span>], [<span class="fl">0.5</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>To construct and solve the convex optimization problem, we will use the python package <code>cvxpy</code>. We essentially just need to declare <span class="math inline">\(C\)</span> as a variable, then specify our objective and constraints. The rest is handled by the solver - everything from verifying that the problem is convex to returning its solution.</p>
<div class="cell" data-execution_count="3">
<details open="">
<summary>Solve and visualize a convex optimization problem</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cvxpy <span class="im">import</span> Variable, Minimize, norm, diag, Problem, ECOS</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable matrix</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> Variable((n, n))</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimize ||C||_1</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>objective <span class="op">=</span> Minimize(norm(C,<span class="dv">1</span>))</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Subject to Y = YC, diag(C) = 0</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>constraints <span class="op">=</span> [Y <span class="op">==</span> Y <span class="op">@</span> C, diag(C) <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>prob <span class="op">=</span> Problem(objective, constraints)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>prob.solve(solver<span class="op">=</span>ECOS)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize coefficient matrix</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> C.value <span class="op">/</span> np.<span class="bu">max</span>(np.<span class="bu">abs</span>(C.value), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>px.imshow(C)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div id="fig-c" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">

<div>                            <div id="10dffaea-6d68-48bc-a557-1c63425d93ec" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("10dffaea-6d68-48bc-a557-1c63425d93ec")) {                    Plotly.newPlot(                        "10dffaea-6d68-48bc-a557-1c63425d93ec",                        [{"coloraxis":"coloraxis","name":"0","z":[[-7.238473697145243e-15,-0.00381399401187321,0.0022232378954670407,-0.007111811162024872,0.026745707763471707,-0.05989204744478483,-0.007960574976122495,0.025731253228524726,-0.07225733010780294,-0.0004792740799260078,-0.0021254313462934233,-1.954270565767838e-12,-0.006668548034197666,-0.0011062443235423849,-0.0044959435881701815,-0.1336892447799274,-0.0008439096385442703,-0.0006717202210984459,-0.0020157080656634445,-0.0123963214723545],[-0.7060716893551794,-1.4813666533096714e-14,-0.014200384878981401,0.06903170295652147,-0.27308923426542026,0.4814057060497696,0.07891729562668741,-0.2637140213215584,0.5340720881605056,0.0052787464049556705,0.005364263415350338,2.8657753786588918e-11,0.0167447647959166,0.004530343155683426,0.011271669631537438,0.3351788484636503,0.0021465764473575194,0.0018018451492394856,0.005032374446199622,0.031235533559649517],[0.85967196605838,-0.0753940017253434,-3.082108762613095e-14,-0.17896272093671298,0.5018048414625175,-0.7024514551846184,-0.20533070654987282,0.4968238779137317,-0.7450936429165693,-1.0,-0.004225819821951443,-3.493940989563685e-11,-0.019503497246085705,-0.005786927255417021,-0.013278844127276129,-0.34219066010677407,-0.0024286846605609653,-0.0018272484372578869,-0.006155632233745382,-0.028875600617906987],[-0.5491447800037031,0.01775666550905376,-0.01014050399203097,-9.11407895224538e-15,-0.15657228604449522,0.31831887011146703,0.04217440411126697,-0.15040646607830002,0.36653524902571294,0.0024872793588786757,0.005120068693086069,2.0032821105897653e-11,0.015239967969992513,0.0037297852854274293,0.01024325368781405,0.3108662582145092,0.001958348351602584,0.0016539174432245243,0.004548966085287393,0.029307959788041574],[0.3156536257225877,-0.00967200210417448,0.005923375168222432,-0.017854110161707445,-7.19898081173672e-15,-0.15172258631024688,-0.02000930617986109,0.06593493335456263,-0.1810859843516608,-0.0011918662790905965,-0.003439087249159253,-7.802686625089835e-12,-0.012634724072437804,-0.0024316437513935466,-0.008557756887242507,-0.23903816579706566,-0.0015851529636968006,-0.00122911816844981,-0.0038981453926841174,-0.021318321059485786],[-0.21786074398814256,0.006508730700462463,-0.0038777271243247784,0.011936387301454958,-0.04453975858224389,-7.518333483490008e-15,0.013315814617980235,-0.042789702700459724,0.11955909904297139,0.0008218741633158939,0.003564418826404658,4.222593136399472e-12,0.008972244690199735,0.0017094574220460513,0.005993996772527908,0.19634315136570635,0.0011651210551438121,0.001006637494696103,0.0026045266092056827,0.01927695974057478],[-0.5253333717739666,0.016664080493368306,-0.009828119013027777,0.03424248829286967,-0.1443443081097157,0.2974663334523625,-8.63735628763349e-15,-0.13907030801140677,0.34439444693807003,0.0022139473253830733,0.004323686490444071,1.82589948452238e-11,0.015935648477767204,0.003676944003908546,0.010789067811842915,0.3007135339922448,0.0020081260073432287,0.0015834533696836319,0.0049095546289667355,0.02683156305513437],[0.3207548927388353,-0.009796293196686715,0.006090998371199553,-0.01811194998767875,0.06992184033557658,-0.1544860967795026,-0.02038337211073164,-7.223995151734907e-15,-0.18442699932170337,-0.001185743717762706,-0.002370429900258139,-7.755780777874387e-12,-0.014179842426302134,-0.002535200961476549,-0.009717000660260754,-0.23303809330050662,-0.001722920981673823,-0.0011822957974942576,-0.004595670133571502,-0.01842422782365455],[-0.19792668711014133,0.005844608609370243,-0.0034751748027242397,0.010744893277994603,-0.040097299953731055,0.08959334088502531,0.012001163921008588,-0.03855661857395591,-7.558272520939412e-15,0.0007360725402437302,0.0030196632491504578,3.5420731724017444e-12,0.008788126737143395,0.0015795347193301148,0.005907124180607607,0.18123720679029534,0.001122576537205056,0.0009218671851436692,0.0026218276910990245,0.017142706245383558],[-1.0,1.0,-1.0,1.0,-1.0,1.0,1.0,-1.0,1.0,-5.509955355750525e-13,0.00533576951296534,4.3477750568609906e-11,0.01889114366145235,0.007941805270122827,0.012766562472694224,0.3608633191529927,0.0024016639903579285,0.0019595704247667954,0.005776627727154249,0.03258190199626101],[-0.004468023597454002,0.000576415756822837,0.0007331860548423473,0.000985769681573168,-0.00047971525664691273,0.00484746117254445,8.141186358868006e-05,0.0023471679562273133,0.003713355830809125,0.0003722226965386015,-6.5220880576051396e-15,2.5964885704138365e-11,-0.11040312680806863,-0.0033195774608347304,-0.084477179276924,0.5103158997531391,-0.0108379976883808,0.0052178496418659945,-0.05300880596593866,0.22971645113630082],[-0.007264517051091097,0.0010957110397786106,0.0016005968788900724,0.001857992740465924,-0.0006609901834724242,0.008801124751348763,7.984472837798431e-05,0.0048249069102030495,0.006464838581466836,0.0024611385263517806,1.0,5.483886537982416e-13,-1.0,-1.0,-1.0,1.0,-1.0,1.0,-1.0,1.0],[-0.004167038940177726,-0.00030846845488516074,-0.0007936419864912334,-0.00048313198840954023,-0.0011537797314192903,-0.0008298822538804917,0.0003880029714043077,-0.0036761111721745864,0.0009471107390402067,-0.00028582591989843615,-0.07539469044079636,-2.1614151346669872e-11,-6.642350284669878e-15,0.0029595424360832137,0.07401989877819384,-0.455049735225781,0.009380703476499682,-0.0043222638166239115,0.04624767046780864,-0.20085360795974652],[-0.002193909031640289,-0.000799153707026467,-0.001696063975226504,-0.0013051315205714913,-0.001133392731018682,-0.00442151286098647,0.0004367041482851904,-0.006352581723307962,-0.0013739358579836778,-0.0014215305268550356,-0.5963090490043521,-0.29918914833812016,0.6848490716494845,-3.859188950456782e-14,0.6112886680075179,-0.9445012949578163,0.13905843619123343,-0.04264936391741959,0.4752160706660365,-0.8279799807637219],[-0.0028197627615270562,-0.0003912799672810021,-0.0008618144308687144,-0.0006293963004290157,-0.0009330846851034282,-0.0017152759549197607,0.00032985335495168395,-0.003754865881405178,9.834295802802375e-05,-0.0003428178189113104,-0.08858716544856497,-2.5721396342164802e-11,0.11356466909232535,0.003569970728676967,-6.611989820834701e-15,-0.5092142711049492,0.011227961640787135,-0.005247972885657773,0.054440468969942875,-0.23283802999446063],[-0.005113366663691003,0.00016273170986372357,-2.4230647863003957e-05,0.00030487247008412487,-0.0009625849698280476,0.002411820890861126,0.0002758607097001073,-0.0007426226273221412,0.002775913766541018,3.440690328644806e-05,0.004565546684693298,1.201391649451629e-12,-0.005476559453917662,-9.556014673436332e-05,-0.004173044686891263,-1.1613084783884536e-15,-0.000450206482509883,0.00024189137538376798,-0.0025997973814249017,0.013012215041170826],[0.0021616218565875573,-0.0008225579240319751,-0.0013887918965603445,-0.0013746408765113363,-0.00021656737220578128,-0.0057483865115878,0.00015881133444414465,-0.004882059474617435,-0.0033950443541820785,-0.0009999057059617948,-0.29481681681541566,-9.362994857861275e-11,0.36084120759755356,0.011818338232276002,0.29054779720714297,-0.8459800828560098,-9.169519099915204e-15,-0.01724140290754488,0.19185426503102268,-0.5844458601750733],[-0.009525040619337902,0.0010958022534235043,0.00141354946077869,0.0018747155423288798,-0.0011459756068311379,0.009419889103137853,0.00022806829943478643,0.003988627828247172,0.0074816278867342895,0.0015947295972053089,0.49848352717622685,1.0,-0.5639155993595567,-0.017975289996900994,-0.4849907677912284,0.9352007887109891,-0.0805461298484786,-1.7840057632775118e-14,-0.354800482565347,0.7710657175506539],[-0.0003312934243699447,-0.0005339081496312493,-0.0009699945703841186,-0.0008822304877614877,-0.000516358952684697,-0.003282566295628324,0.000218434632612208,-0.0038236256700847834,-0.001437088439572869,-0.000455541870148628,-0.1150822076134814,-3.363259760332232e-11,0.14660733065314602,0.0047831276222131645,0.11263246404061304,-0.5974621676614155,0.014934413976021988,-0.007116283518756557,-6.4655022080462616e-15,-0.29338062617279126],[-0.006601052028247128,0.0004438057152346093,0.0003661078511353611,0.000781150022627893,-0.0010476831504376651,0.004591727644467771,0.0002700009281112336,0.0006553064659224836,0.004278468824752248,0.00020127594334736789,0.043976561710667585,1.217719835326554e-11,-0.05573395995444049,-0.001424123875244856,-0.042410881424007445,0.30584414395667775,-0.004996700514974796,0.0023494603394307004,-0.026359226406164716,-6.0031151540718386e-15]],"type":"heatmap","xaxis":"x","yaxis":"y","hovertemplate":"x: %{x}\u003cbr\u003ey: %{y}\u003cbr\u003ecolor: %{z}\u003cextra\u003e\u003c\u002fextra\u003e"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"scaleanchor":"y","constrain":"domain"},"yaxis":{"anchor":"x","domain":[0.0,1.0],"autorange":"reversed","constrain":"domain"},"coloraxis":{"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]},"margin":{"t":60}},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('10dffaea-6d68-48bc-a557-1c63425d93ec');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
<figcaption class="figure-caption">Figure&nbsp;3: A heatmap of the obtained coefficient matrix <span class="math inline">\(C\)</span>.</figcaption>
</figure>
</div>
</div>
<p><strong>?@fig-C</strong> above shows what the (normalized) solution looks like - you may note that it’s a block diagonal matrix much like <a href="#eq-block">Equation&nbsp;1</a>. This is due to the self-expressiveness property; points from a subspace will only have nonzero coefficients corresponding to other points from the same subspace. As such, we may essentially use this <span class="math inline">\(C\)</span> matrix as similarity for (spectral clustering)[#spectral-clustering].</p>
<p>More specifically, you may note that there are two rows with quite large coefficients whereas the others are quite small. This comes from minimizing the norm of <span class="math inline">\(C\)</span>, leading to us to prioritize points with larger distances from the origin. In the case of one-dimensional subspaces like this, we end up picking the farthest point from the origin and expressing the remaining points as scalar multiples of it. To better approximate the block structures and make the similarity graph undirected, we thus symmetrize the matrix via <span class="math inline">\(W = |C| + |C|^\top\)</span>.</p>
</section>
<section id="implementation" class="level3">
<h3 class="anchored" data-anchor-id="implementation">Implementation</h3>
<p>As one last detail, <span class="citation" data-cites="elhamifar_sparse_2013">Elhamifar and Vidal (<a href="#ref-elhamifar_sparse_2013" role="doc-biblioref">2013</a>)</span> proposes a modified version of <a href="#eq-matrix">Equation&nbsp;4</a> that deals with noise <span id="eq-noise"><span class="math display">\[
\begin{align}
    \text{minimize} \quad&amp; ||C||_1 + \lambda_e ||E||_1 + \frac{\lambda_z}{2} ||Z||_F^2 \\
    \text{such that} \quad&amp; Y = Y C + E + Z\ ,\\
    &amp; \mathrm{diag}(C) = 0\ .
\end{align}
\tag{5}\]</span></span></p>
<p>The <span class="math inline">\(E\)</span> matrix is meant to account for outliers and the <span class="math inline">\(Z\)</span> matrix for other noise. The reference material suggests setting <span class="math inline">\(\lambda_e = \alpha_e / \mu_e\)</span> and <span class="math inline">\(\lambda_e = \alpha_e / \mu_e\)</span> with <span id="eq-coef"><span class="math display">\[
\mu_e = \min_i \max_{j \neq i} ||y_j||_1\ ,\qquad
\mu_z = \min_i \max_{j \neq i} |y_i^\top y_j|\ .
\tag{6}\]</span></span></p>
<p>Putting everything together, the algorithm looks like this:</p>
<div class="sourceCode" id="cb5" data-startfrom="27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python" style="counter-reset: source-line 26;"><span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fit(<span class="va">self</span>, Y):</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> Y.T</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    d, n <span class="op">=</span> Y.shape</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> d <span class="op">&lt;</span> n</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">## 1. Solve sparse optimization problem</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Starting form, equation (5)</span></span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>    C <span class="op">=</span> Variable((n, n))</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    objective <span class="op">=</span> norm(C,<span class="dv">1</span>)</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    constraint <span class="op">=</span> Y <span class="op">@</span> C</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Account for outliers</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.use_E:</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        mu_e <span class="op">=</span> np.partition(np.<span class="bu">sum</span>(np.<span class="bu">abs</span>(Y), axis<span class="op">=</span><span class="dv">0</span>), <span class="op">-</span><span class="dv">2</span>)[<span class="op">-</span><span class="dv">2</span>]</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        l_e <span class="op">=</span> <span class="dv">20</span> <span class="op">/</span> mu_e</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        E <span class="op">=</span> Variable((d, n))</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        objective <span class="op">+=</span> l_e <span class="op">*</span> norm(E,<span class="dv">1</span>)</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        constraint <span class="op">+=</span> E</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Account for noise</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="va">self</span>.use_Z:</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> np.<span class="bu">abs</span>(Y.T <span class="op">@</span> Y)</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>        mu_z <span class="op">=</span> np.<span class="bu">min</span>(np.<span class="bu">max</span>(G <span class="op">-</span> np.diag(np.diag(G)), axis<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>        l_z <span class="op">=</span> <span class="dv">800</span> <span class="op">/</span> mu_z</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>        Z <span class="op">=</span> Variable((d, n))</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        objective <span class="op">+=</span> l_z<span class="op">/</span><span class="dv">2</span> <span class="op">*</span> norm(Z,<span class="st">"fro"</span>)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        constraint <span class="op">+=</span> Z</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>    constraints <span class="op">=</span> [Y <span class="op">==</span> constraint, diag(C) <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    prob <span class="op">=</span> Problem(Minimize(objective), constraints)</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">try</span>:</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>        prob.solve(solver<span class="op">=</span>ECOS)</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 2. Normalize the columns of C</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>        C <span class="op">=</span> C.value <span class="op">/</span> np.<span class="bu">max</span>(np.<span class="bu">abs</span>(C.value), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 3. Form the weights of a similarity graph</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>        W <span class="op">=</span> np.<span class="bu">abs</span>(C)</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>        W <span class="op">=</span> W <span class="op">+</span> W.T</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>        <span class="co">## 4. Apply spectral clustering on the graph</span></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels_ <span class="op">=</span> SpectralClustering(</span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>                n_clusters<span class="op">=</span><span class="va">self</span>.n_clusters,</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>                affinity<span class="op">=</span><span class="st">'precomputed'</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>            ).fit_predict(W)</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">except</span> SolverError:</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels_ <span class="op">=</span> np.zeros(n)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>


<!-- -->


</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-elhamifar_sparse_2013" class="csl-entry" role="listitem">
Elhamifar, Ehsan, and Rene Vidal. 2013. <span>“Sparse <span>Subspace</span> <span>Clustering</span>: <span>Algorithm</span>, <span>Theory</span>, and <span>Applications</span>.”</span> arXiv. <a href="http://arxiv.org/abs/1203.1005">http://arxiv.org/abs/1203.1005</a>.
</div>
<div id="ref-von_luxburg_tutorial_2007" class="csl-entry" role="listitem">
Luxburg, Ulrike von. 2007. <span>“A <span>Tutorial</span> on <span>Spectral</span> <span>Clustering</span>.”</span> arXiv. <a href="http://arxiv.org/abs/0711.0189">http://arxiv.org/abs/0711.0189</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Note that we could also solve for <span class="math inline">\(q=0\)</span>, but this is an <span class="math inline">\(\mathsf{NP}\)</span>-hard problem.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="adidenkova/blog-comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb6" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Clustering</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> Sparse subspace clustering</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> In which we overview common tasks and models for clustering. Includes an exploration of spectral clustering and sparse subspace clustering, and an implementation of the latter.</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2023/12/02</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Clustering</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - Unsupervised learning</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - Eigenvalues</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - Convex optimization</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> blog.bib</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="an">filters:</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">  - include-code-files</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Identify the common tasks in machine learning/data mining models for clustering. --&gt;</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="fu">## Clustering</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>Falling within the realm of **unsupervised learning**, this task deals with unlabeled but adequately distinct data.</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>While both it and <span class="co">[</span><span class="ot">classification</span><span class="co">](4-classification.qmd)</span> involve modeling such differences, clustering in particular starts with no prior informaiton about data labels.</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>In cases where partial label information is known, the task is instead considered to be semi-supervised.</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>The common goal of clustering is to separate data into **clusters** - groups such that data within them is similar and between them is different.</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>What this means precisely depends on the measure of similarity used; for raw Euclidean distances it would mean that clusters are far apart literally, whereas for feature embedding spaces they would be apart semantically/conceptually.</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>Clustering serves a variety of **purposes**:</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Understanding:** separating data into distinct groups may reveal patterns and highlight important features.</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>  Additionally, clustering may be viewed as a form of divide-and-conquer where the clusters may be easier to analyze in isolation.</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Preprocessing:** similar to the above, the benefit of being able to analyze data separately can be extended to programmatic solutions.</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>  That is, cluster assignment can be used to split data and train models separately for each.</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Anomaly detection:** the above would additionally get rid of outliers as they wouldn't belong to any cluster.</span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>  This makes clustering applicable to <span class="co">[</span><span class="ot">anomaly detection</span><span class="co">](5-anomaly.qmd)</span> as it can identify points that are distant from all other data.</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>Clustering in itself isn't a method but a task.</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>A plethora of algorithms exist to perform it, thanks to various relevant **considerations** about the type of clustered data:</span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Shape:** while we may typically think of clusters as circular-like objects, they may instead be stretched, spread out, stretched out, bent, etc.</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a>  For the stretched out type, it additionally becomes important whether data exhibits linear relationships or otherwise lies in nonlinear manifolds.</span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Data type:** the same considerations from other tasks in machine learning apply: is the data numerical or categorical, are any transforms applicable, is some of the data images/audio/text/etc?</span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Dimensionality:** for more complex data types, preprocessing or embedding may be in order.</span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>  High-dimensional data in general poses a challenge due to the *curse of dimensionality*, a phenomenon where regular measures of distance break down and lose meaning.</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>  In some circumstances it thus becomes crucial to use methods specifically designed around high-dimensional data.</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a><span class="fu">### Examples</span></span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>To illustrate the former consideration particularly, we can take a look at some distinct sets of artificial data and the performances of various clustering algorithms.</span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>Here's a pretty nice visualization of some common algorithms:</span>
<span id="cb6-50"><a href="#cb6-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-53"><a href="#cb6-53" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-54"><a href="#cb6-54" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb6-55"><a href="#cb6-55" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Clustering scatterplot matrix code by [sklearn](https://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html)</span></span>
<span id="cb6-56"><a href="#cb6-56" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: A comparison of various clustering methods.</span></span>
<span id="cb6-57"><a href="#cb6-57" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-clustering</span></span>
<span id="cb6-58"><a href="#cb6-58" aria-hidden="true" tabindex="-1"></a><span class="co">#| column: page</span></span>
<span id="cb6-59"><a href="#cb6-59" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb6-60"><a href="#cb6-60" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb6-61"><a href="#cb6-61" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> cycle, islice</span>
<span id="cb6-62"><a href="#cb6-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-63"><a href="#cb6-63" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb6-64"><a href="#cb6-64" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-65"><a href="#cb6-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-66"><a href="#cb6-66" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn <span class="im">import</span> cluster, datasets, mixture</span>
<span id="cb6-67"><a href="#cb6-67" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.neighbors <span class="im">import</span> kneighbors_graph</span>
<span id="cb6-68"><a href="#cb6-68" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-69"><a href="#cb6-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-70"><a href="#cb6-70" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> ssc <span class="im">import</span> linear, SparseSubspaceClustering</span>
<span id="cb6-71"><a href="#cb6-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-72"><a href="#cb6-72" aria-hidden="true" tabindex="-1"></a><span class="co"># ============</span></span>
<span id="cb6-73"><a href="#cb6-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate datasets. We choose the size big enough to see the scalability</span></span>
<span id="cb6-74"><a href="#cb6-74" aria-hidden="true" tabindex="-1"></a><span class="co"># of the algorithms, but not too big to avoid too long running times</span></span>
<span id="cb6-75"><a href="#cb6-75" aria-hidden="true" tabindex="-1"></a><span class="co"># ============</span></span>
<span id="cb6-76"><a href="#cb6-76" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb6-77"><a href="#cb6-77" aria-hidden="true" tabindex="-1"></a>seed <span class="op">=</span> <span class="dv">5805</span></span>
<span id="cb6-78"><a href="#cb6-78" aria-hidden="true" tabindex="-1"></a>noisy_circles <span class="op">=</span> datasets.make_circles(</span>
<span id="cb6-79"><a href="#cb6-79" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span>n_samples, factor<span class="op">=</span><span class="fl">0.5</span>, noise<span class="op">=</span><span class="fl">0.05</span>, random_state<span class="op">=</span>seed</span>
<span id="cb6-80"><a href="#cb6-80" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-81"><a href="#cb6-81" aria-hidden="true" tabindex="-1"></a>noisy_moons <span class="op">=</span> datasets.make_moons(n_samples<span class="op">=</span>n_samples, noise<span class="op">=</span><span class="fl">0.05</span>, random_state<span class="op">=</span>seed)</span>
<span id="cb6-82"><a href="#cb6-82" aria-hidden="true" tabindex="-1"></a>blobs <span class="op">=</span> datasets.make_blobs(n_samples<span class="op">=</span>n_samples, random_state<span class="op">=</span>seed)</span>
<span id="cb6-83"><a href="#cb6-83" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.RandomState(seed)</span>
<span id="cb6-84"><a href="#cb6-84" aria-hidden="true" tabindex="-1"></a>no_structure <span class="op">=</span> rng.rand(n_samples, <span class="dv">2</span>), <span class="va">None</span></span>
<span id="cb6-85"><a href="#cb6-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-86"><a href="#cb6-86" aria-hidden="true" tabindex="-1"></a><span class="co"># Anisotropicly distributed data</span></span>
<span id="cb6-87"><a href="#cb6-87" aria-hidden="true" tabindex="-1"></a>random_state <span class="op">=</span> <span class="dv">5805</span></span>
<span id="cb6-88"><a href="#cb6-88" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> datasets.make_blobs(n_samples<span class="op">=</span>n_samples, random_state<span class="op">=</span>random_state)</span>
<span id="cb6-89"><a href="#cb6-89" aria-hidden="true" tabindex="-1"></a>transformation <span class="op">=</span> [[<span class="fl">0.6</span>, <span class="op">-</span><span class="fl">0.6</span>], [<span class="op">-</span><span class="fl">0.4</span>, <span class="fl">0.8</span>]]</span>
<span id="cb6-90"><a href="#cb6-90" aria-hidden="true" tabindex="-1"></a>X_aniso <span class="op">=</span> np.dot(X, transformation)</span>
<span id="cb6-91"><a href="#cb6-91" aria-hidden="true" tabindex="-1"></a>aniso <span class="op">=</span> (X_aniso, y)</span>
<span id="cb6-92"><a href="#cb6-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-93"><a href="#cb6-93" aria-hidden="true" tabindex="-1"></a><span class="co"># blobs with varied variances</span></span>
<span id="cb6-94"><a href="#cb6-94" aria-hidden="true" tabindex="-1"></a>varied <span class="op">=</span> datasets.make_blobs(</span>
<span id="cb6-95"><a href="#cb6-95" aria-hidden="true" tabindex="-1"></a>    n_samples<span class="op">=</span>n_samples, cluster_std<span class="op">=</span>[<span class="fl">1.0</span>, <span class="fl">2.5</span>, <span class="fl">0.5</span>], random_state<span class="op">=</span>random_state</span>
<span id="cb6-96"><a href="#cb6-96" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-97"><a href="#cb6-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-98"><a href="#cb6-98" aria-hidden="true" tabindex="-1"></a><span class="co"># ============</span></span>
<span id="cb6-99"><a href="#cb6-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Set up cluster parameters</span></span>
<span id="cb6-100"><a href="#cb6-100" aria-hidden="true" tabindex="-1"></a><span class="co"># ============</span></span>
<span id="cb6-101"><a href="#cb6-101" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="fl">10.5</span>, <span class="fl">6.5</span>))</span>
<span id="cb6-102"><a href="#cb6-102" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(</span>
<span id="cb6-103"><a href="#cb6-103" aria-hidden="true" tabindex="-1"></a>    left<span class="op">=</span><span class="fl">0.02</span>, right<span class="op">=</span><span class="fl">0.98</span>, bottom<span class="op">=</span><span class="fl">0.001</span>, top<span class="op">=</span><span class="fl">0.95</span>, wspace<span class="op">=</span><span class="fl">0.01</span>, hspace<span class="op">=</span><span class="fl">0.01</span></span>
<span id="cb6-104"><a href="#cb6-104" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-105"><a href="#cb6-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-106"><a href="#cb6-106" aria-hidden="true" tabindex="-1"></a>plot_num <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-107"><a href="#cb6-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-108"><a href="#cb6-108" aria-hidden="true" tabindex="-1"></a>default_base <span class="op">=</span> {</span>
<span id="cb6-109"><a href="#cb6-109" aria-hidden="true" tabindex="-1"></a>    <span class="st">"quantile"</span>: <span class="fl">0.3</span>,</span>
<span id="cb6-110"><a href="#cb6-110" aria-hidden="true" tabindex="-1"></a>    <span class="st">"eps"</span>: <span class="fl">0.3</span>,</span>
<span id="cb6-111"><a href="#cb6-111" aria-hidden="true" tabindex="-1"></a>    <span class="st">"damping"</span>: <span class="fl">0.9</span>,</span>
<span id="cb6-112"><a href="#cb6-112" aria-hidden="true" tabindex="-1"></a>    <span class="st">"preference"</span>: <span class="op">-</span><span class="dv">200</span>,</span>
<span id="cb6-113"><a href="#cb6-113" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_neighbors"</span>: <span class="dv">3</span>,</span>
<span id="cb6-114"><a href="#cb6-114" aria-hidden="true" tabindex="-1"></a>    <span class="st">"n_clusters"</span>: <span class="dv">3</span>,</span>
<span id="cb6-115"><a href="#cb6-115" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb6-116"><a href="#cb6-116" aria-hidden="true" tabindex="-1"></a>    <span class="st">"xi"</span>: <span class="fl">0.05</span>,</span>
<span id="cb6-117"><a href="#cb6-117" aria-hidden="true" tabindex="-1"></a>    <span class="st">"min_cluster_size"</span>: <span class="fl">0.1</span>,</span>
<span id="cb6-118"><a href="#cb6-118" aria-hidden="true" tabindex="-1"></a>    <span class="st">"allow_single_cluster"</span>: <span class="va">True</span>,</span>
<span id="cb6-119"><a href="#cb6-119" aria-hidden="true" tabindex="-1"></a>    <span class="st">"hdbscan_min_cluster_size"</span>: <span class="dv">15</span>,</span>
<span id="cb6-120"><a href="#cb6-120" aria-hidden="true" tabindex="-1"></a>    <span class="st">"hdbscan_min_samples"</span>: <span class="dv">3</span>,</span>
<span id="cb6-121"><a href="#cb6-121" aria-hidden="true" tabindex="-1"></a>    <span class="st">"random_state"</span>: <span class="dv">42</span>,</span>
<span id="cb6-122"><a href="#cb6-122" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb6-123"><a href="#cb6-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-124"><a href="#cb6-124" aria-hidden="true" tabindex="-1"></a>datasets <span class="op">=</span> [</span>
<span id="cb6-125"><a href="#cb6-125" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb6-126"><a href="#cb6-126" aria-hidden="true" tabindex="-1"></a>        noisy_circles,</span>
<span id="cb6-127"><a href="#cb6-127" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb6-128"><a href="#cb6-128" aria-hidden="true" tabindex="-1"></a>            <span class="st">"damping"</span>: <span class="fl">0.77</span>,</span>
<span id="cb6-129"><a href="#cb6-129" aria-hidden="true" tabindex="-1"></a>            <span class="st">"preference"</span>: <span class="op">-</span><span class="dv">240</span>,</span>
<span id="cb6-130"><a href="#cb6-130" aria-hidden="true" tabindex="-1"></a>            <span class="st">"quantile"</span>: <span class="fl">0.2</span>,</span>
<span id="cb6-131"><a href="#cb6-131" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_clusters"</span>: <span class="dv">2</span>,</span>
<span id="cb6-132"><a href="#cb6-132" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb6-133"><a href="#cb6-133" aria-hidden="true" tabindex="-1"></a>            <span class="st">"xi"</span>: <span class="fl">0.08</span>,</span>
<span id="cb6-134"><a href="#cb6-134" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb6-135"><a href="#cb6-135" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb6-136"><a href="#cb6-136" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb6-137"><a href="#cb6-137" aria-hidden="true" tabindex="-1"></a>        noisy_moons,</span>
<span id="cb6-138"><a href="#cb6-138" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb6-139"><a href="#cb6-139" aria-hidden="true" tabindex="-1"></a>            <span class="st">"damping"</span>: <span class="fl">0.75</span>,</span>
<span id="cb6-140"><a href="#cb6-140" aria-hidden="true" tabindex="-1"></a>            <span class="st">"preference"</span>: <span class="op">-</span><span class="dv">220</span>,</span>
<span id="cb6-141"><a href="#cb6-141" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_clusters"</span>: <span class="dv">2</span>,</span>
<span id="cb6-142"><a href="#cb6-142" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb6-143"><a href="#cb6-143" aria-hidden="true" tabindex="-1"></a>            <span class="st">"xi"</span>: <span class="fl">0.1</span>,</span>
<span id="cb6-144"><a href="#cb6-144" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb6-145"><a href="#cb6-145" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb6-146"><a href="#cb6-146" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb6-147"><a href="#cb6-147" aria-hidden="true" tabindex="-1"></a>        varied,</span>
<span id="cb6-148"><a href="#cb6-148" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb6-149"><a href="#cb6-149" aria-hidden="true" tabindex="-1"></a>            <span class="st">"eps"</span>: <span class="fl">0.18</span>,</span>
<span id="cb6-150"><a href="#cb6-150" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_neighbors"</span>: <span class="dv">2</span>,</span>
<span id="cb6-151"><a href="#cb6-151" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb6-152"><a href="#cb6-152" aria-hidden="true" tabindex="-1"></a>            <span class="st">"xi"</span>: <span class="fl">0.01</span>,</span>
<span id="cb6-153"><a href="#cb6-153" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_cluster_size"</span>: <span class="fl">0.2</span>,</span>
<span id="cb6-154"><a href="#cb6-154" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb6-155"><a href="#cb6-155" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb6-156"><a href="#cb6-156" aria-hidden="true" tabindex="-1"></a>    (</span>
<span id="cb6-157"><a href="#cb6-157" aria-hidden="true" tabindex="-1"></a>        aniso,</span>
<span id="cb6-158"><a href="#cb6-158" aria-hidden="true" tabindex="-1"></a>        {</span>
<span id="cb6-159"><a href="#cb6-159" aria-hidden="true" tabindex="-1"></a>            <span class="st">"eps"</span>: <span class="fl">0.15</span>,</span>
<span id="cb6-160"><a href="#cb6-160" aria-hidden="true" tabindex="-1"></a>            <span class="st">"n_neighbors"</span>: <span class="dv">2</span>,</span>
<span id="cb6-161"><a href="#cb6-161" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_samples"</span>: <span class="dv">7</span>,</span>
<span id="cb6-162"><a href="#cb6-162" aria-hidden="true" tabindex="-1"></a>            <span class="st">"xi"</span>: <span class="fl">0.1</span>,</span>
<span id="cb6-163"><a href="#cb6-163" aria-hidden="true" tabindex="-1"></a>            <span class="st">"min_cluster_size"</span>: <span class="fl">0.2</span>,</span>
<span id="cb6-164"><a href="#cb6-164" aria-hidden="true" tabindex="-1"></a>        },</span>
<span id="cb6-165"><a href="#cb6-165" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb6-166"><a href="#cb6-166" aria-hidden="true" tabindex="-1"></a>    (blobs, {<span class="st">"min_samples"</span>: <span class="dv">7</span>, <span class="st">"xi"</span>: <span class="fl">0.1</span>, <span class="st">"min_cluster_size"</span>: <span class="fl">0.2</span>}),</span>
<span id="cb6-167"><a href="#cb6-167" aria-hidden="true" tabindex="-1"></a>    (linear, {}),</span>
<span id="cb6-168"><a href="#cb6-168" aria-hidden="true" tabindex="-1"></a>    (no_structure, {}),</span>
<span id="cb6-169"><a href="#cb6-169" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb6-170"><a href="#cb6-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-171"><a href="#cb6-171" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i_dataset, (dataset, algo_params) <span class="kw">in</span> <span class="bu">enumerate</span>(datasets):</span>
<span id="cb6-172"><a href="#cb6-172" aria-hidden="true" tabindex="-1"></a>    <span class="co"># update parameters with dataset-specific values</span></span>
<span id="cb6-173"><a href="#cb6-173" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> default_base.copy()</span>
<span id="cb6-174"><a href="#cb6-174" aria-hidden="true" tabindex="-1"></a>    params.update(algo_params)</span>
<span id="cb6-175"><a href="#cb6-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-176"><a href="#cb6-176" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> dataset</span>
<span id="cb6-177"><a href="#cb6-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-178"><a href="#cb6-178" aria-hidden="true" tabindex="-1"></a>    <span class="co"># normalize dataset for easier parameter selection</span></span>
<span id="cb6-179"><a href="#cb6-179" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> StandardScaler().fit_transform(X)</span>
<span id="cb6-180"><a href="#cb6-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-181"><a href="#cb6-181" aria-hidden="true" tabindex="-1"></a>    <span class="co"># estimate bandwidth for mean shift</span></span>
<span id="cb6-182"><a href="#cb6-182" aria-hidden="true" tabindex="-1"></a>    bandwidth <span class="op">=</span> cluster.estimate_bandwidth(X, quantile<span class="op">=</span>params[<span class="st">"quantile"</span>])</span>
<span id="cb6-183"><a href="#cb6-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-184"><a href="#cb6-184" aria-hidden="true" tabindex="-1"></a>    <span class="co"># connectivity matrix for structured Ward</span></span>
<span id="cb6-185"><a href="#cb6-185" aria-hidden="true" tabindex="-1"></a>    connectivity <span class="op">=</span> kneighbors_graph(</span>
<span id="cb6-186"><a href="#cb6-186" aria-hidden="true" tabindex="-1"></a>        X, n_neighbors<span class="op">=</span>params[<span class="st">"n_neighbors"</span>], include_self<span class="op">=</span><span class="va">False</span></span>
<span id="cb6-187"><a href="#cb6-187" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-188"><a href="#cb6-188" aria-hidden="true" tabindex="-1"></a>    <span class="co"># make connectivity symmetric</span></span>
<span id="cb6-189"><a href="#cb6-189" aria-hidden="true" tabindex="-1"></a>    connectivity <span class="op">=</span> <span class="fl">0.5</span> <span class="op">*</span> (connectivity <span class="op">+</span> connectivity.T)</span>
<span id="cb6-190"><a href="#cb6-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-191"><a href="#cb6-191" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============</span></span>
<span id="cb6-192"><a href="#cb6-192" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create cluster objects</span></span>
<span id="cb6-193"><a href="#cb6-193" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ============</span></span>
<span id="cb6-194"><a href="#cb6-194" aria-hidden="true" tabindex="-1"></a>    ms <span class="op">=</span> cluster.MeanShift(bandwidth<span class="op">=</span>bandwidth, bin_seeding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-195"><a href="#cb6-195" aria-hidden="true" tabindex="-1"></a>    two_means <span class="op">=</span> cluster.MiniBatchKMeans(</span>
<span id="cb6-196"><a href="#cb6-196" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb6-197"><a href="#cb6-197" aria-hidden="true" tabindex="-1"></a>        n_init<span class="op">=</span><span class="st">"auto"</span>,</span>
<span id="cb6-198"><a href="#cb6-198" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span>params[<span class="st">"random_state"</span>],</span>
<span id="cb6-199"><a href="#cb6-199" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-200"><a href="#cb6-200" aria-hidden="true" tabindex="-1"></a>    ward <span class="op">=</span> cluster.AgglomerativeClustering(</span>
<span id="cb6-201"><a href="#cb6-201" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>], linkage<span class="op">=</span><span class="st">"ward"</span>, connectivity<span class="op">=</span>connectivity</span>
<span id="cb6-202"><a href="#cb6-202" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-203"><a href="#cb6-203" aria-hidden="true" tabindex="-1"></a>    spectral <span class="op">=</span> cluster.SpectralClustering(</span>
<span id="cb6-204"><a href="#cb6-204" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb6-205"><a href="#cb6-205" aria-hidden="true" tabindex="-1"></a>        eigen_solver<span class="op">=</span><span class="st">"arpack"</span>,</span>
<span id="cb6-206"><a href="#cb6-206" aria-hidden="true" tabindex="-1"></a>        affinity<span class="op">=</span><span class="st">"nearest_neighbors"</span>,</span>
<span id="cb6-207"><a href="#cb6-207" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span>params[<span class="st">"random_state"</span>],</span>
<span id="cb6-208"><a href="#cb6-208" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-209"><a href="#cb6-209" aria-hidden="true" tabindex="-1"></a>    dbscan <span class="op">=</span> cluster.DBSCAN(eps<span class="op">=</span>params[<span class="st">"eps"</span>])</span>
<span id="cb6-210"><a href="#cb6-210" aria-hidden="true" tabindex="-1"></a>    hdbscan <span class="op">=</span> cluster.HDBSCAN(</span>
<span id="cb6-211"><a href="#cb6-211" aria-hidden="true" tabindex="-1"></a>        min_samples<span class="op">=</span>params[<span class="st">"hdbscan_min_samples"</span>],</span>
<span id="cb6-212"><a href="#cb6-212" aria-hidden="true" tabindex="-1"></a>        min_cluster_size<span class="op">=</span>params[<span class="st">"hdbscan_min_cluster_size"</span>],</span>
<span id="cb6-213"><a href="#cb6-213" aria-hidden="true" tabindex="-1"></a>        allow_single_cluster<span class="op">=</span>params[<span class="st">"allow_single_cluster"</span>],</span>
<span id="cb6-214"><a href="#cb6-214" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-215"><a href="#cb6-215" aria-hidden="true" tabindex="-1"></a>    optics <span class="op">=</span> cluster.OPTICS(</span>
<span id="cb6-216"><a href="#cb6-216" aria-hidden="true" tabindex="-1"></a>        min_samples<span class="op">=</span>params[<span class="st">"min_samples"</span>],</span>
<span id="cb6-217"><a href="#cb6-217" aria-hidden="true" tabindex="-1"></a>        xi<span class="op">=</span>params[<span class="st">"xi"</span>],</span>
<span id="cb6-218"><a href="#cb6-218" aria-hidden="true" tabindex="-1"></a>        min_cluster_size<span class="op">=</span>params[<span class="st">"min_cluster_size"</span>],</span>
<span id="cb6-219"><a href="#cb6-219" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-220"><a href="#cb6-220" aria-hidden="true" tabindex="-1"></a>    affinity_propagation <span class="op">=</span> cluster.AffinityPropagation(</span>
<span id="cb6-221"><a href="#cb6-221" aria-hidden="true" tabindex="-1"></a>        damping<span class="op">=</span>params[<span class="st">"damping"</span>],</span>
<span id="cb6-222"><a href="#cb6-222" aria-hidden="true" tabindex="-1"></a>        preference<span class="op">=</span>params[<span class="st">"preference"</span>],</span>
<span id="cb6-223"><a href="#cb6-223" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span>params[<span class="st">"random_state"</span>],</span>
<span id="cb6-224"><a href="#cb6-224" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-225"><a href="#cb6-225" aria-hidden="true" tabindex="-1"></a>    average_linkage <span class="op">=</span> cluster.AgglomerativeClustering(</span>
<span id="cb6-226"><a href="#cb6-226" aria-hidden="true" tabindex="-1"></a>        linkage<span class="op">=</span><span class="st">"average"</span>,</span>
<span id="cb6-227"><a href="#cb6-227" aria-hidden="true" tabindex="-1"></a>        metric<span class="op">=</span><span class="st">"cityblock"</span>,</span>
<span id="cb6-228"><a href="#cb6-228" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb6-229"><a href="#cb6-229" aria-hidden="true" tabindex="-1"></a>        connectivity<span class="op">=</span>connectivity,</span>
<span id="cb6-230"><a href="#cb6-230" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-231"><a href="#cb6-231" aria-hidden="true" tabindex="-1"></a>    birch <span class="op">=</span> cluster.Birch(n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>])</span>
<span id="cb6-232"><a href="#cb6-232" aria-hidden="true" tabindex="-1"></a>    gmm <span class="op">=</span> mixture.GaussianMixture(</span>
<span id="cb6-233"><a href="#cb6-233" aria-hidden="true" tabindex="-1"></a>        n_components<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb6-234"><a href="#cb6-234" aria-hidden="true" tabindex="-1"></a>        covariance_type<span class="op">=</span><span class="st">"full"</span>,</span>
<span id="cb6-235"><a href="#cb6-235" aria-hidden="true" tabindex="-1"></a>        random_state<span class="op">=</span>params[<span class="st">"random_state"</span>],</span>
<span id="cb6-236"><a href="#cb6-236" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-237"><a href="#cb6-237" aria-hidden="true" tabindex="-1"></a>    ssc <span class="op">=</span> SparseSubspaceClustering(</span>
<span id="cb6-238"><a href="#cb6-238" aria-hidden="true" tabindex="-1"></a>        n_clusters<span class="op">=</span>params[<span class="st">"n_clusters"</span>],</span>
<span id="cb6-239"><a href="#cb6-239" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-240"><a href="#cb6-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-241"><a href="#cb6-241" aria-hidden="true" tabindex="-1"></a>    clustering_algorithms <span class="op">=</span> (</span>
<span id="cb6-242"><a href="#cb6-242" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"MiniBatch</span><span class="ch">\n</span><span class="st">KMeans"</span>, two_means),</span>
<span id="cb6-243"><a href="#cb6-243" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Affinity</span><span class="ch">\n</span><span class="st">Propagation"</span>, affinity_propagation),</span>
<span id="cb6-244"><a href="#cb6-244" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"MeanShift"</span>, ms),</span>
<span id="cb6-245"><a href="#cb6-245" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Spectral</span><span class="ch">\n</span><span class="st">Clustering"</span>, spectral),</span>
<span id="cb6-246"><a href="#cb6-246" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Ward"</span>, ward),</span>
<span id="cb6-247"><a href="#cb6-247" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Agglomerative</span><span class="ch">\n</span><span class="st">Clustering"</span>, average_linkage),</span>
<span id="cb6-248"><a href="#cb6-248" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"DBSCAN"</span>, dbscan),</span>
<span id="cb6-249"><a href="#cb6-249" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"HDBSCAN"</span>, hdbscan),</span>
<span id="cb6-250"><a href="#cb6-250" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"OPTICS"</span>, optics),</span>
<span id="cb6-251"><a href="#cb6-251" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"BIRCH"</span>, birch),</span>
<span id="cb6-252"><a href="#cb6-252" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Gaussian</span><span class="ch">\n</span><span class="st">Mixture"</span>, gmm),</span>
<span id="cb6-253"><a href="#cb6-253" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"Sparse</span><span class="ch">\n</span><span class="st">Subspace</span><span class="ch">\n</span><span class="st">Clustering"</span>, ssc),</span>
<span id="cb6-254"><a href="#cb6-254" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb6-255"><a href="#cb6-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-256"><a href="#cb6-256" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, algorithm <span class="kw">in</span> clustering_algorithms:</span>
<span id="cb6-257"><a href="#cb6-257" aria-hidden="true" tabindex="-1"></a>        t0 <span class="op">=</span> time.time()</span>
<span id="cb6-258"><a href="#cb6-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-259"><a href="#cb6-259" aria-hidden="true" tabindex="-1"></a>        <span class="co"># catch warnings related to kneighbors_graph, subspace clustering</span></span>
<span id="cb6-260"><a href="#cb6-260" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> warnings.catch_warnings():</span>
<span id="cb6-261"><a href="#cb6-261" aria-hidden="true" tabindex="-1"></a>            warnings.filterwarnings(</span>
<span id="cb6-262"><a href="#cb6-262" aria-hidden="true" tabindex="-1"></a>                <span class="st">"ignore"</span>,</span>
<span id="cb6-263"><a href="#cb6-263" aria-hidden="true" tabindex="-1"></a>                message<span class="op">=</span><span class="st">"the number of connected components of the "</span></span>
<span id="cb6-264"><a href="#cb6-264" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">"connectivity matrix is [0-9]{1,2}"</span></span>
<span id="cb6-265"><a href="#cb6-265" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">" &gt; 1. Completing it to avoid stopping the tree early."</span>,</span>
<span id="cb6-266"><a href="#cb6-266" aria-hidden="true" tabindex="-1"></a>                category<span class="op">=</span><span class="pp">UserWarning</span>,</span>
<span id="cb6-267"><a href="#cb6-267" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-268"><a href="#cb6-268" aria-hidden="true" tabindex="-1"></a>            warnings.filterwarnings(</span>
<span id="cb6-269"><a href="#cb6-269" aria-hidden="true" tabindex="-1"></a>                <span class="st">"ignore"</span>,</span>
<span id="cb6-270"><a href="#cb6-270" aria-hidden="true" tabindex="-1"></a>                message<span class="op">=</span><span class="st">"Graph is not fully connected, spectral embedding"</span></span>
<span id="cb6-271"><a href="#cb6-271" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">" may not work as expected."</span>,</span>
<span id="cb6-272"><a href="#cb6-272" aria-hidden="true" tabindex="-1"></a>                category<span class="op">=</span><span class="pp">UserWarning</span>,</span>
<span id="cb6-273"><a href="#cb6-273" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-274"><a href="#cb6-274" aria-hidden="true" tabindex="-1"></a>            warnings.filterwarnings(</span>
<span id="cb6-275"><a href="#cb6-275" aria-hidden="true" tabindex="-1"></a>                <span class="st">"ignore"</span>,</span>
<span id="cb6-276"><a href="#cb6-276" aria-hidden="true" tabindex="-1"></a>                message<span class="op">=</span><span class="st">"Solution may be inaccurate. Try another solver,"</span></span>
<span id="cb6-277"><a href="#cb6-277" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">" adjusting the solver settings, or solve with"</span></span>
<span id="cb6-278"><a href="#cb6-278" aria-hidden="true" tabindex="-1"></a>                <span class="op">+</span> <span class="st">" verbose=True for more information."</span>,</span>
<span id="cb6-279"><a href="#cb6-279" aria-hidden="true" tabindex="-1"></a>                category<span class="op">=</span><span class="pp">UserWarning</span>,</span>
<span id="cb6-280"><a href="#cb6-280" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-281"><a href="#cb6-281" aria-hidden="true" tabindex="-1"></a>            algorithm.fit(X)</span>
<span id="cb6-282"><a href="#cb6-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-283"><a href="#cb6-283" aria-hidden="true" tabindex="-1"></a>        t1 <span class="op">=</span> time.time()</span>
<span id="cb6-284"><a href="#cb6-284" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">hasattr</span>(algorithm, <span class="st">"labels_"</span>):</span>
<span id="cb6-285"><a href="#cb6-285" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> algorithm.labels_.astype(<span class="bu">int</span>)</span>
<span id="cb6-286"><a href="#cb6-286" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-287"><a href="#cb6-287" aria-hidden="true" tabindex="-1"></a>            y_pred <span class="op">=</span> algorithm.predict(X)</span>
<span id="cb6-288"><a href="#cb6-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-289"><a href="#cb6-289" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="bu">len</span>(datasets), <span class="bu">len</span>(clustering_algorithms), plot_num)</span>
<span id="cb6-290"><a href="#cb6-290" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> i_dataset <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-291"><a href="#cb6-291" aria-hidden="true" tabindex="-1"></a>            plt.title(name, size<span class="op">=</span><span class="dv">9</span>)</span>
<span id="cb6-292"><a href="#cb6-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-293"><a href="#cb6-293" aria-hidden="true" tabindex="-1"></a>        colors <span class="op">=</span> np.array(</span>
<span id="cb6-294"><a href="#cb6-294" aria-hidden="true" tabindex="-1"></a>            <span class="bu">list</span>(</span>
<span id="cb6-295"><a href="#cb6-295" aria-hidden="true" tabindex="-1"></a>                islice(</span>
<span id="cb6-296"><a href="#cb6-296" aria-hidden="true" tabindex="-1"></a>                    cycle(</span>
<span id="cb6-297"><a href="#cb6-297" aria-hidden="true" tabindex="-1"></a>                        [</span>
<span id="cb6-298"><a href="#cb6-298" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#377eb8"</span>,</span>
<span id="cb6-299"><a href="#cb6-299" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#ff7f00"</span>,</span>
<span id="cb6-300"><a href="#cb6-300" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#4daf4a"</span>,</span>
<span id="cb6-301"><a href="#cb6-301" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#f781bf"</span>,</span>
<span id="cb6-302"><a href="#cb6-302" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#a65628"</span>,</span>
<span id="cb6-303"><a href="#cb6-303" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#984ea3"</span>,</span>
<span id="cb6-304"><a href="#cb6-304" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#999999"</span>,</span>
<span id="cb6-305"><a href="#cb6-305" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#e41a1c"</span>,</span>
<span id="cb6-306"><a href="#cb6-306" aria-hidden="true" tabindex="-1"></a>                            <span class="st">"#dede00"</span>,</span>
<span id="cb6-307"><a href="#cb6-307" aria-hidden="true" tabindex="-1"></a>                        ]</span>
<span id="cb6-308"><a href="#cb6-308" aria-hidden="true" tabindex="-1"></a>                    ),</span>
<span id="cb6-309"><a href="#cb6-309" aria-hidden="true" tabindex="-1"></a>                    <span class="bu">int</span>(<span class="bu">max</span>(y_pred) <span class="op">+</span> <span class="dv">1</span>),</span>
<span id="cb6-310"><a href="#cb6-310" aria-hidden="true" tabindex="-1"></a>                )</span>
<span id="cb6-311"><a href="#cb6-311" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb6-312"><a href="#cb6-312" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-313"><a href="#cb6-313" aria-hidden="true" tabindex="-1"></a>        <span class="co"># add black color for outliers (if any)</span></span>
<span id="cb6-314"><a href="#cb6-314" aria-hidden="true" tabindex="-1"></a>        colors <span class="op">=</span> np.append(colors, [<span class="st">"#000000"</span>])</span>
<span id="cb6-315"><a href="#cb6-315" aria-hidden="true" tabindex="-1"></a>        plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">5</span>, color<span class="op">=</span>colors[y_pred])</span>
<span id="cb6-316"><a href="#cb6-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-317"><a href="#cb6-317" aria-hidden="true" tabindex="-1"></a>        plt.xlim(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>)</span>
<span id="cb6-318"><a href="#cb6-318" aria-hidden="true" tabindex="-1"></a>        plt.ylim(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>)</span>
<span id="cb6-319"><a href="#cb6-319" aria-hidden="true" tabindex="-1"></a>        plt.xticks(())</span>
<span id="cb6-320"><a href="#cb6-320" aria-hidden="true" tabindex="-1"></a>        plt.yticks(())</span>
<span id="cb6-321"><a href="#cb6-321" aria-hidden="true" tabindex="-1"></a>        plt.text(</span>
<span id="cb6-322"><a href="#cb6-322" aria-hidden="true" tabindex="-1"></a>            <span class="fl">0.99</span>,</span>
<span id="cb6-323"><a href="#cb6-323" aria-hidden="true" tabindex="-1"></a>            <span class="fl">0.01</span>,</span>
<span id="cb6-324"><a href="#cb6-324" aria-hidden="true" tabindex="-1"></a>            (<span class="st">"</span><span class="sc">%.2f</span><span class="st">s"</span> <span class="op">%</span> (t1 <span class="op">-</span> t0)).lstrip(<span class="st">"0"</span>),</span>
<span id="cb6-325"><a href="#cb6-325" aria-hidden="true" tabindex="-1"></a>            transform<span class="op">=</span>plt.gca().transAxes,</span>
<span id="cb6-326"><a href="#cb6-326" aria-hidden="true" tabindex="-1"></a>            size<span class="op">=</span><span class="fl">7.5</span>,</span>
<span id="cb6-327"><a href="#cb6-327" aria-hidden="true" tabindex="-1"></a>            horizontalalignment<span class="op">=</span><span class="st">"right"</span>,</span>
<span id="cb6-328"><a href="#cb6-328" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb6-329"><a href="#cb6-329" aria-hidden="true" tabindex="-1"></a>        plot_num <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb6-330"><a href="#cb6-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-331"><a href="#cb6-331" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-332"><a href="#cb6-332" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-333"><a href="#cb6-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-334"><a href="#cb6-334" aria-hidden="true" tabindex="-1"></a>Whoa, that's a lot of them!</span>
<span id="cb6-335"><a href="#cb6-335" aria-hidden="true" tabindex="-1"></a>If you've seen this image before and are particularly observant, you may notice that I threw in an extra algorithm (rightmost column) and a dataset (second-bottom row) - more on those later.</span>
<span id="cb6-336"><a href="#cb6-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-337"><a href="#cb6-337" aria-hidden="true" tabindex="-1"></a>Each of the above algorithms is deserving of a post of its own.</span>
<span id="cb6-338"><a href="#cb6-338" aria-hidden="true" tabindex="-1"></a>Here, I will just briefly focus on one, which happens to be the only showcased algorithm that properly clusters the top 5 datasets:</span>
<span id="cb6-339"><a href="#cb6-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-340"><a href="#cb6-340" aria-hidden="true" tabindex="-1"></a><span class="fu">### Spectral Clustering</span></span>
<span id="cb6-341"><a href="#cb6-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-342"><a href="#cb6-342" aria-hidden="true" tabindex="-1"></a>Yes, spectral as in *spectrum* - i.e., **eigenvalues**.</span>
<span id="cb6-343"><a href="#cb6-343" aria-hidden="true" tabindex="-1"></a>I found out about this algorithm back when I was taking intro to linear algebra, and it really stuck with me precisely because it gives a pretty neat interpretation of eigenvalues (which at the time I had a really hard time exemplifying).</span>
<span id="cb6-344"><a href="#cb6-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-345"><a href="#cb6-345" aria-hidden="true" tabindex="-1"></a>We start with a *similarity matrix* $S$, where the $ij$-th value denotes the similarity of data points indexed $i$ and $j$.</span>
<span id="cb6-346"><a href="#cb6-346" aria-hidden="true" tabindex="-1"></a>What constitutes as being similar may vary; the example in @fig-clustering simply uses Euclidean distance.</span>
<span id="cb6-347"><a href="#cb6-347" aria-hidden="true" tabindex="-1"></a>We then use $S$ to construct a *similarity graph*, a weighted graph with weights $w_{i,j} = s_{i,j}$ if they are past a certain threshold and $0$ (no edge) otherwise.</span>
<span id="cb6-348"><a href="#cb6-348" aria-hidden="true" tabindex="-1"></a>This graph's *weighted adjacency matrix* $W$ is essentially $S$ with all sub-threshold values zeroed out.</span>
<span id="cb6-349"><a href="#cb6-349" aria-hidden="true" tabindex="-1"></a>Assuming data from $k$ sufficiently distinct clusters is ordered by cluster, the adjacency matrix may look something like</span>
<span id="cb6-350"><a href="#cb6-350" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-351"><a href="#cb6-351" aria-hidden="true" tabindex="-1"></a>W = \begin{bmatrix} W_1 &amp; &amp; &amp; <span class="sc">\\</span> &amp; W_2 &amp; &amp; <span class="sc">\\</span> &amp; &amp; \ddots &amp; <span class="sc">\\</span> &amp; &amp; &amp; W_k \end{bmatrix}\ ,</span>
<span id="cb6-352"><a href="#cb6-352" aria-hidden="true" tabindex="-1"></a>$$ {#eq-block}</span>
<span id="cb6-353"><a href="#cb6-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-354"><a href="#cb6-354" aria-hidden="true" tabindex="-1"></a>which you may recognize as a block diagonal matrix.</span>
<span id="cb6-355"><a href="#cb6-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-356"><a href="#cb6-356" aria-hidden="true" tabindex="-1"></a>So, what role do eigenvalues play here?</span>
<span id="cb6-357"><a href="#cb6-357" aria-hidden="true" tabindex="-1"></a>Turns out, if $v$ is an eigenvalue of $W_1$, then the same $v$ padded by a bunch of zeros at the bottom is an eigenvalue of $W$.</span>
<span id="cb6-358"><a href="#cb6-358" aria-hidden="true" tabindex="-1"></a>You can verify this via @eq-block; $W_1 v = v \lambda$ necessarily implies $W \begin{bmatrix} v <span class="sc">\\</span> 0 \end{bmatrix} = \begin{bmatrix} v <span class="sc">\\</span> 0 \end{bmatrix} \lambda$.</span>
<span id="cb6-359"><a href="#cb6-359" aria-hidden="true" tabindex="-1"></a>The same applies for eigenvectors of any cluster, they just need to placed appropriately to act on their cluster's similarity block $W_i$.</span>
<span id="cb6-360"><a href="#cb6-360" aria-hidden="true" tabindex="-1"></a>As such, the eigenvalues of $W$ will be grouped according to cluster, having zero values in all other locations.</span>
<span id="cb6-361"><a href="#cb6-361" aria-hidden="true" tabindex="-1"></a>Finding these eigenvalues would then reveal the clusters.</span>
<span id="cb6-362"><a href="#cb6-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-363"><a href="#cb6-363" aria-hidden="true" tabindex="-1"></a>Well... sort of.</span>
<span id="cb6-364"><a href="#cb6-364" aria-hidden="true" tabindex="-1"></a>In reality, we still have some problems: the eigenvalues can have small/zero entries, and finding all $n$ eigenvalues is just too difficult.</span>
<span id="cb6-365"><a href="#cb6-365" aria-hidden="true" tabindex="-1"></a>Instead, we define $D$ to be the diagonal degree matrix, its diagonal entries being the sum of the corresponding rows/columns of $W$.</span>
<span id="cb6-366"><a href="#cb6-366" aria-hidden="true" tabindex="-1"></a>We then obtain the *graph Laplacian* $L = D - W$, another diagonal block matrix with an additional property that its rows/columns sum to zero.</span>
<span id="cb6-367"><a href="#cb6-367" aria-hidden="true" tabindex="-1"></a>This makes it so multiplying each block $L_i$ by a vector with all entries being $1$ produces the zero vector, making it an eigenvector of $L_i$ with a zero eigenvalue.</span>
<span id="cb6-368"><a href="#cb6-368" aria-hidden="true" tabindex="-1"></a>Additionally, the only vectors satisfying this property are just scalar multiples of that identity vector.</span>
<span id="cb6-369"><a href="#cb6-369" aria-hidden="true" tabindex="-1"></a>As such, the Laplacian $L$ will have its zero eigenspace spanned by precisely $k$ such identity vectors.</span>
<span id="cb6-370"><a href="#cb6-370" aria-hidden="true" tabindex="-1"></a>This adresses both of our previous problems, making it so we only have to find $k$ out of $n$ eigenvectors.</span>
<span id="cb6-371"><a href="#cb6-371" aria-hidden="true" tabindex="-1"></a>Using <span class="co">[</span><span class="ot">inverse iteration</span><span class="co">](https://en.wikipedia.org/wiki/Inverse_iteration)</span> will obtain these eigenvectors only, and do so very efficiently.</span>
<span id="cb6-372"><a href="#cb6-372" aria-hidden="true" tabindex="-1"></a>Putting the eigenvectors together as a matrix would then make its rows indicators for which cluster a particular point belongs to.</span>
<span id="cb6-373"><a href="#cb6-373" aria-hidden="true" tabindex="-1"></a>In case there is still any ambiguity, the rows can be grouped together using a simpler clustering algorithm like <span class="co">[</span><span class="ot">$k$-means</span><span class="co">](https://en.wikipedia.org/wiki/K-means_clustering)</span>.</span>
<span id="cb6-374"><a href="#cb6-374" aria-hidden="true" tabindex="-1"></a>For more details about spectral clustering, see @von_luxburg_tutorial_2007.</span>
<span id="cb6-375"><a href="#cb6-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-376"><a href="#cb6-376" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Graph resonance</span></span>
<span id="cb6-377"><a href="#cb6-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-378"><a href="#cb6-378" aria-hidden="true" tabindex="-1"></a>A pretty cool interpretation of this Laplacian comes from thinking of the nodes in the similarity graph as being connected by springs - the higher the weight between two nodes, the stronger their connecting spring.</span>
<span id="cb6-379"><a href="#cb6-379" aria-hidden="true" tabindex="-1"></a>What happens if we move a single node by some amount?</span>
<span id="cb6-380"><a href="#cb6-380" aria-hidden="true" tabindex="-1"></a>The nodes connected to it would be pulled in the same direction according to the strengths of the springs that connect them to the displaced node, the latter being pulled back with the sum of those strengths.</span>
<span id="cb6-381"><a href="#cb6-381" aria-hidden="true" tabindex="-1"></a>Note that this force is precisely described by the (negative of) the column of $L$ corresponding to the displaced node.</span>
<span id="cb6-382"><a href="#cb6-382" aria-hidden="true" tabindex="-1"></a>If $x$ is the vector representing the displacement of each node, the corresponding force (in the other direction) is given by $Lx$.</span>
<span id="cb6-383"><a href="#cb6-383" aria-hidden="true" tabindex="-1"></a>In the case where the displacement is an eigenvector of $L$, we have</span>
<span id="cb6-384"><a href="#cb6-384" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-385"><a href="#cb6-385" aria-hidden="true" tabindex="-1"></a>\sum F = - L v = - \lambda v\ ,</span>
<span id="cb6-386"><a href="#cb6-386" aria-hidden="true" tabindex="-1"></a>$$ {#eq-hookes}</span>
<span id="cb6-387"><a href="#cb6-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-388"><a href="#cb6-388" aria-hidden="true" tabindex="-1"></a>which is precisely <span class="co">[</span><span class="ot">Hooke's law</span><span class="co">](https://en.wikipedia.org/wiki/Hooke%27s_law)</span>.</span>
<span id="cb6-389"><a href="#cb6-389" aria-hidden="true" tabindex="-1"></a>Thus given an initial displacement $v$, the graph will undergo simple harmonic motion with frequency $\lambda^2$.</span>
<span id="cb6-390"><a href="#cb6-390" aria-hidden="true" tabindex="-1"></a>In other words, the eigenpairs $(\lambda, v)$ of $L$ actually describe the **resonant frequencies** $\lambda^2$ and corresponding **vibration modes** of its graph.</span>
<span id="cb6-391"><a href="#cb6-391" aria-hidden="true" tabindex="-1"></a>It is for this reason that eigenvalues are crucial to analyzing mechanical resonance - where the graph represents connected parts of a physical object.</span>
<span id="cb6-392"><a href="#cb6-392" aria-hidden="true" tabindex="-1"></a>This could be applied to, for intance, designing buildings that are resistant to strong winds and earthquakes.</span>
<span id="cb6-393"><a href="#cb6-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-394"><a href="#cb6-394" aria-hidden="true" tabindex="-1"></a>In our case we saw that the similarity graph had some zero eigenvalues.</span>
<span id="cb6-395"><a href="#cb6-395" aria-hidden="true" tabindex="-1"></a>This corresponds to zero frequency - i.e., once we displace the nodes of a single cluster, it experiences no force from the others and just stays in the same place.</span>
<span id="cb6-396"><a href="#cb6-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-397"><a href="#cb6-397" aria-hidden="true" tabindex="-1"></a><span class="fu">### Linearity</span></span>
<span id="cb6-398"><a href="#cb6-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-399"><a href="#cb6-399" aria-hidden="true" tabindex="-1"></a>So, that's all well and good when similarity relates to Euclidean distance - but as noted before, this becomes less true for high-dimensional data.</span>
<span id="cb6-400"><a href="#cb6-400" aria-hidden="true" tabindex="-1"></a>Instead, data may lie in *linear subspaces*, such as when representing the same scene illuminated from different angles, or objects moving at different speeds @elhamifar_sparse_2013.</span>
<span id="cb6-401"><a href="#cb6-401" aria-hidden="true" tabindex="-1"></a>A simplified image of what such data could look like is seen in @fig-subspaces below.</span>
<span id="cb6-402"><a href="#cb6-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-403"><a href="#cb6-403" aria-hidden="true" tabindex="-1"></a><span class="al">![Three linear subspaces. Figure by @elhamifar_sparse_2013.](subspaces.svg)</span>{width=50% fig-align="center" #fig-subspaces}</span>
<span id="cb6-404"><a href="#cb6-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-405"><a href="#cb6-405" aria-hidden="true" tabindex="-1"></a>The point where the lines and plane intersect is the origin.</span>
<span id="cb6-406"><a href="#cb6-406" aria-hidden="true" tabindex="-1"></a>You may note that this matches the mathematical definiton of linear subspaces, i.e., non-empty and closed under addition and scalar multiplication.</span>
<span id="cb6-407"><a href="#cb6-407" aria-hidden="true" tabindex="-1"></a>Alternatively, we may pick any number of vectors and have their span be a linear subspaces.</span>
<span id="cb6-408"><a href="#cb6-408" aria-hidden="true" tabindex="-1"></a>Any point in the subspaces would then be a linear combination of such vectors, which are themselves points in the subspace.</span>
<span id="cb6-409"><a href="#cb6-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-410"><a href="#cb6-410" aria-hidden="true" tabindex="-1"></a>You may note that the new dataset is somewhat like a flattened version of @fig-subspaces, with the lines $\mathcal{S}_2$ and $\mathcal{S}_3$ being the diagonals making up the 'X' shape, and the plane $\mathcal{S}_1$ being the remaining points in the background square.</span>
<span id="cb6-411"><a href="#cb6-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-412"><a href="#cb6-412" aria-hidden="true" tabindex="-1"></a><span class="in">```{.python include="ssc.py" start-line=9 end-line=18}</span></span>
<span id="cb6-413"><a href="#cb6-413" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-414"><a href="#cb6-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-415"><a href="#cb6-415" aria-hidden="true" tabindex="-1"></a>Our goal is then to separate the two diagonals and the square.</span>
<span id="cb6-416"><a href="#cb6-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-417"><a href="#cb6-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-418"><a href="#cb6-418" aria-hidden="true" tabindex="-1"></a><span class="fu">## Sparse Subspace Clustering</span></span>
<span id="cb6-419"><a href="#cb6-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-420"><a href="#cb6-420" aria-hidden="true" tabindex="-1"></a>To this end, we will analyze an algorithm based on <span class="co">[</span><span class="ot">spectral clustering</span><span class="co">](#spectral-clustering)</span>, proposed by @elhamifar_sparse_2013.</span>
<span id="cb6-421"><a href="#cb6-421" aria-hidden="true" tabindex="-1"></a>This algorithm relies on the *self-expressiveness* property described above, i.e., that points in a subspace can be described by a linear combination of other points from the same subspace.</span>
<span id="cb6-422"><a href="#cb6-422" aria-hidden="true" tabindex="-1"></a>Specifically, let $Y = \begin{bmatrix} y_1 &amp; y_2 &amp; \dots &amp; y_n \end{bmatrix}$ be a $d$-by-$n$ matrix of data.</span>
<span id="cb6-423"><a href="#cb6-423" aria-hidden="true" tabindex="-1"></a>Then, with every data point $y_i$ we can associate a coefficient vector $c_i$ such that</span>
<span id="cb6-424"><a href="#cb6-424" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-425"><a href="#cb6-425" aria-hidden="true" tabindex="-1"></a>y_i = Y c_i\ ,\qquad</span>
<span id="cb6-426"><a href="#cb6-426" aria-hidden="true" tabindex="-1"></a>c_{ii} = 0\ .</span>
<span id="cb6-427"><a href="#cb6-427" aria-hidden="true" tabindex="-1"></a>$$ {#eq-vector}</span>
<span id="cb6-428"><a href="#cb6-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-429"><a href="#cb6-429" aria-hidden="true" tabindex="-1"></a>As the above has infinitely many solutions, we will additionally $\text{minimize} ||c_i||_q$.</span>
<span id="cb6-430"><a href="#cb6-430" aria-hidden="true" tabindex="-1"></a>Using smaller $q$ will make more coefficients zero, and for $q=1$ will generally only have nonzero coefficients for points within the same subspace.<span class="ot">[^q0]</span></span>
<span id="cb6-431"><a href="#cb6-431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-432"><a href="#cb6-432" aria-hidden="true" tabindex="-1"></a><span class="ot">[^q0]: </span>Note that we could also solve for $q=0$, but this is an $\mathsf{NP}$-hard problem.</span>
<span id="cb6-433"><a href="#cb6-433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-434"><a href="#cb6-434" aria-hidden="true" tabindex="-1"></a>Letting $C = \begin{bmatrix} c_1 &amp; c_2 &amp; \dots &amp; c_n \end{bmatrix}$, we can rewrite the problem in matrix form as</span>
<span id="cb6-435"><a href="#cb6-435" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-436"><a href="#cb6-436" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb6-437"><a href="#cb6-437" aria-hidden="true" tabindex="-1"></a>    \text{minimize} \quad&amp; ||C||_1 <span class="sc">\\</span></span>
<span id="cb6-438"><a href="#cb6-438" aria-hidden="true" tabindex="-1"></a>    \text{such that} \quad&amp; Y = Y C\ ,<span class="sc">\\</span></span>
<span id="cb6-439"><a href="#cb6-439" aria-hidden="true" tabindex="-1"></a>    &amp; \mathrm{diag}(C) = 0\ .</span>
<span id="cb6-440"><a href="#cb6-440" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb6-441"><a href="#cb6-441" aria-hidden="true" tabindex="-1"></a>$$ {#eq-matrix}</span>
<span id="cb6-442"><a href="#cb6-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-443"><a href="#cb6-443" aria-hidden="true" tabindex="-1"></a>Note that the objective is convex and the constraints affine, so this can be solved efficiently using</span>
<span id="cb6-444"><a href="#cb6-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-445"><a href="#cb6-445" aria-hidden="true" tabindex="-1"></a><span class="fu">### Convex optimization</span></span>
<span id="cb6-446"><a href="#cb6-446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-447"><a href="#cb6-447" aria-hidden="true" tabindex="-1"></a>A framework for problems with certain nice properties, <span class="co">[</span><span class="ot">convex optimization</span><span class="co">](https://en.wikipedia.org/wiki/Convex_optimization)</span> can be applied to a multitude of tasks in various fields.</span>
<span id="cb6-448"><a href="#cb6-448" aria-hidden="true" tabindex="-1"></a>While I first encountered it in exactly this context of sparse subspace clustering, I now use a variant of it (semidefinite programming) all the time for quantum-related stuff.</span>
<span id="cb6-449"><a href="#cb6-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-450"><a href="#cb6-450" aria-hidden="true" tabindex="-1"></a>Let's solve an instance of @eq-matrix in practice to see why this matrix $C$ could be useful.</span>
<span id="cb6-451"><a href="#cb6-451" aria-hidden="true" tabindex="-1"></a>First, let's construct a simplified version of the dataset shown above, containing fewer points and only the diagonals.</span>
<span id="cb6-452"><a href="#cb6-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-455"><a href="#cb6-455" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-456"><a href="#cb6-456" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb6-457"><a href="#cb6-457" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Generate a simpler dataset</span></span>
<span id="cb6-458"><a href="#cb6-458" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb6-459"><a href="#cb6-459" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> np.concatenate((</span>
<span id="cb6-460"><a href="#cb6-460" aria-hidden="true" tabindex="-1"></a>    rng.rand(<span class="dv">2</span>, n<span class="op">//</span><span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb6-461"><a href="#cb6-461" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> np.repeat(rng.rand(<span class="dv">1</span>, n<span class="op">//</span><span class="dv">2</span>), <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">0</span>),  <span class="co"># / Diagonal</span></span>
<span id="cb6-462"><a href="#cb6-462" aria-hidden="true" tabindex="-1"></a>    rng.rand(<span class="dv">2</span>, n<span class="op">//</span><span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.01</span></span>
<span id="cb6-463"><a href="#cb6-463" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> np.repeat(rng.rand(<span class="dv">1</span>, n<span class="op">//</span><span class="dv">2</span>), <span class="dv">2</span>, axis<span class="op">=</span><span class="dv">0</span>)   <span class="co"># \ Diagonal</span></span>
<span id="cb6-464"><a href="#cb6-464" aria-hidden="true" tabindex="-1"></a>        <span class="op">*</span> [[<span class="dv">1</span>], [<span class="op">-</span><span class="dv">1</span>]] <span class="op">+</span> [[<span class="dv">0</span>], [<span class="dv">1</span>]]</span>
<span id="cb6-465"><a href="#cb6-465" aria-hidden="true" tabindex="-1"></a>), axis<span class="op">=</span><span class="dv">1</span>) <span class="op">-</span> [[<span class="fl">0.5</span>], [<span class="fl">0.5</span>]]</span>
<span id="cb6-466"><a href="#cb6-466" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-467"><a href="#cb6-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-468"><a href="#cb6-468" aria-hidden="true" tabindex="-1"></a>To construct and solve the convex optimization problem, we will use the python package <span class="in">`cvxpy`</span>.</span>
<span id="cb6-469"><a href="#cb6-469" aria-hidden="true" tabindex="-1"></a>We essentially just need to declare $C$ as a variable, then specify our objective and constraints.</span>
<span id="cb6-470"><a href="#cb6-470" aria-hidden="true" tabindex="-1"></a>The rest is handled by the solver - everything from verifying that the problem is convex to returning its solution.</span>
<span id="cb6-471"><a href="#cb6-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-474"><a href="#cb6-474" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb6-475"><a href="#cb6-475" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Solve and visualize a convex optimization problem</span></span>
<span id="cb6-476"><a href="#cb6-476" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: A heatmap of the obtained coefficient matrix $C$.</span></span>
<span id="cb6-477"><a href="#cb6-477" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-C</span></span>
<span id="cb6-478"><a href="#cb6-478" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> cvxpy <span class="im">import</span> Variable, Minimize, norm, diag, Problem, ECOS</span>
<span id="cb6-479"><a href="#cb6-479" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.express <span class="im">as</span> px</span>
<span id="cb6-480"><a href="#cb6-480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-481"><a href="#cb6-481" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable matrix</span></span>
<span id="cb6-482"><a href="#cb6-482" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> Variable((n, n))</span>
<span id="cb6-483"><a href="#cb6-483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-484"><a href="#cb6-484" aria-hidden="true" tabindex="-1"></a><span class="co"># Minimize ||C||_1</span></span>
<span id="cb6-485"><a href="#cb6-485" aria-hidden="true" tabindex="-1"></a>objective <span class="op">=</span> Minimize(norm(C,<span class="dv">1</span>))</span>
<span id="cb6-486"><a href="#cb6-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-487"><a href="#cb6-487" aria-hidden="true" tabindex="-1"></a><span class="co"># Subject to Y = YC, diag(C) = 0</span></span>
<span id="cb6-488"><a href="#cb6-488" aria-hidden="true" tabindex="-1"></a>constraints <span class="op">=</span> [Y <span class="op">==</span> Y <span class="op">@</span> C, diag(C) <span class="op">==</span> <span class="dv">0</span>]</span>
<span id="cb6-489"><a href="#cb6-489" aria-hidden="true" tabindex="-1"></a>prob <span class="op">=</span> Problem(objective, constraints)</span>
<span id="cb6-490"><a href="#cb6-490" aria-hidden="true" tabindex="-1"></a>prob.solve(solver<span class="op">=</span>ECOS)</span>
<span id="cb6-491"><a href="#cb6-491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-492"><a href="#cb6-492" aria-hidden="true" tabindex="-1"></a><span class="co"># Normalize coefficient matrix</span></span>
<span id="cb6-493"><a href="#cb6-493" aria-hidden="true" tabindex="-1"></a>C <span class="op">=</span> C.value <span class="op">/</span> np.<span class="bu">max</span>(np.<span class="bu">abs</span>(C.value), axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb6-494"><a href="#cb6-494" aria-hidden="true" tabindex="-1"></a>px.imshow(C)</span>
<span id="cb6-495"><a href="#cb6-495" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb6-496"><a href="#cb6-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-497"><a href="#cb6-497" aria-hidden="true" tabindex="-1"></a>@fig-C above shows what the (normalized) solution looks like - you may note that it's a block diagonal matrix much like @eq-block.</span>
<span id="cb6-498"><a href="#cb6-498" aria-hidden="true" tabindex="-1"></a>This is due to the self-expressiveness property; points from a subspace will only have nonzero coefficients corresponding to other points from the same subspace.</span>
<span id="cb6-499"><a href="#cb6-499" aria-hidden="true" tabindex="-1"></a>As such, we may essentially use this $C$ matrix as similarity for (spectral clustering)<span class="co">[</span><span class="ot">#spectral-clustering</span><span class="co">]</span>.</span>
<span id="cb6-500"><a href="#cb6-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-501"><a href="#cb6-501" aria-hidden="true" tabindex="-1"></a>More specifically, you may note that there are two rows with quite large coefficients whereas the others are quite small.</span>
<span id="cb6-502"><a href="#cb6-502" aria-hidden="true" tabindex="-1"></a>This comes from minimizing the norm of $C$, leading to us to prioritize points with larger distances from the origin.</span>
<span id="cb6-503"><a href="#cb6-503" aria-hidden="true" tabindex="-1"></a>In the case of one-dimensional subspaces like this, we end up picking the farthest point from the origin and expressing the remaining points as scalar multiples of it.</span>
<span id="cb6-504"><a href="#cb6-504" aria-hidden="true" tabindex="-1"></a>To better approximate the block structures and make the similarity graph undirected, we thus symmetrize the matrix via $W = |C| + |C|^\top$.</span>
<span id="cb6-505"><a href="#cb6-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-506"><a href="#cb6-506" aria-hidden="true" tabindex="-1"></a><span class="fu">### Implementation</span></span>
<span id="cb6-507"><a href="#cb6-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-508"><a href="#cb6-508" aria-hidden="true" tabindex="-1"></a>As one last detail, @elhamifar_sparse_2013 proposes a modified version of @eq-matrix that deals with noise</span>
<span id="cb6-509"><a href="#cb6-509" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-510"><a href="#cb6-510" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb6-511"><a href="#cb6-511" aria-hidden="true" tabindex="-1"></a>    \text{minimize} \quad&amp; ||C||_1 + \lambda_e ||E||_1 + \frac{\lambda_z}{2} ||Z||_F^2 <span class="sc">\\</span></span>
<span id="cb6-512"><a href="#cb6-512" aria-hidden="true" tabindex="-1"></a>    \text{such that} \quad&amp; Y = Y C + E + Z\ ,<span class="sc">\\</span></span>
<span id="cb6-513"><a href="#cb6-513" aria-hidden="true" tabindex="-1"></a>    &amp; \mathrm{diag}(C) = 0\ .</span>
<span id="cb6-514"><a href="#cb6-514" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb6-515"><a href="#cb6-515" aria-hidden="true" tabindex="-1"></a>$$ {#eq-noise}</span>
<span id="cb6-516"><a href="#cb6-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-517"><a href="#cb6-517" aria-hidden="true" tabindex="-1"></a>The $E$ matrix is meant to account for outliers and the $Z$ matrix for other noise.</span>
<span id="cb6-518"><a href="#cb6-518" aria-hidden="true" tabindex="-1"></a>The reference material suggests setting $\lambda_e = \alpha_e / \mu_e$ and $\lambda_e = \alpha_e / \mu_e$ with</span>
<span id="cb6-519"><a href="#cb6-519" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb6-520"><a href="#cb6-520" aria-hidden="true" tabindex="-1"></a>\mu_e = \min_i \max_{j \neq i} ||y_j||_1\ ,\qquad</span>
<span id="cb6-521"><a href="#cb6-521" aria-hidden="true" tabindex="-1"></a>\mu_z = \min_i \max_{j \neq i} |y_i^\top y_j|\ .</span>
<span id="cb6-522"><a href="#cb6-522" aria-hidden="true" tabindex="-1"></a>$$ {#eq-coef}</span>
<span id="cb6-523"><a href="#cb6-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-524"><a href="#cb6-524" aria-hidden="true" tabindex="-1"></a>Putting everything together, the algorithm looks like this:</span>
<span id="cb6-525"><a href="#cb6-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-526"><a href="#cb6-526" aria-hidden="true" tabindex="-1"></a><span class="in">```{.python include="ssc.py" start-line=27 dedent=4}</span></span>
<span id="cb6-527"><a href="#cb6-527" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb6-528"><a href="#cb6-528" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>