<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2023-12-01">
<meta name="description" content="In which we introduce random variables and describe the theory behind bounding them via concentration inequalities. We then introduce several multi-armed bandit algorithms to see how such inequalities may be used to evaluate their performance.">

<title>blog - Probability theory and random variables</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#random-variables" id="toc-random-variables" class="nav-link active" data-scroll-target="#random-variables">Random variables</a>
  <ul class="collapse">
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example">Example</a></li>
  <li><a href="#takeaway" id="toc-takeaway" class="nav-link" data-scroll-target="#takeaway">Takeaway</a></li>
  </ul></li>
  <li><a href="#concentration-bounds" id="toc-concentration-bounds" class="nav-link" data-scroll-target="#concentration-bounds">Concentration bounds</a>
  <ul class="collapse">
  <li><a href="#hoeffdings-inequality" id="toc-hoeffdings-inequality" class="nav-link" data-scroll-target="#hoeffdings-inequality">Hoeffdingâ€™s inequality</a></li>
  <li><a href="#application" id="toc-application" class="nav-link" data-scroll-target="#application">Application</a></li>
  </ul></li>
  <li><a href="#multi-armed-bandits" id="toc-multi-armed-bandits" class="nav-link" data-scroll-target="#multi-armed-bandits">Multi-armed bandits</a>
  <ul class="collapse">
  <li><a href="#explore-then-exploit" id="toc-explore-then-exploit" class="nav-link" data-scroll-target="#explore-then-exploit">Explore-then-exploit</a></li>
  <li><a href="#epsilon-greedy" id="toc-epsilon-greedy" class="nav-link" data-scroll-target="#epsilon-greedy">Epsilon-greedy</a></li>
  <li><a href="#successive-elimination" id="toc-successive-elimination" class="nav-link" data-scroll-target="#successive-elimination">Successive elimination</a></li>
  <li><a href="#ucb" id="toc-ucb" class="nav-link" data-scroll-target="#ucb">UCB</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a></li>
  <li><a href="#simulation" id="toc-simulation" class="nav-link" data-scroll-target="#simulation">Simulation</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/adidenkova/blog/blob/main/posts/1-probability.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Probability theory and random variables</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
<p class="subtitle lead">Concentration bounds and multi-armed bandits</p>
  <div class="quarto-categories">
    <div class="quarto-category">Probability theory</div>
    <div class="quarto-category">Random variables</div>
    <div class="quarto-category">Concentration inequalities</div>
    <div class="quarto-category">Multi-armed bandits</div>
    <div class="quarto-category">Online learning</div>
  </div>
  </div>

<div>
  <div class="description">
    In which we introduce random variables and describe the theory behind bounding them via concentration inequalities. We then introduce several multi-armed bandit algorithms to see how such inequalities may be used to evaluate their performance.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">December 1, 2023</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<!-- Describe the probability theory and random variables. -->
<section id="random-variables" class="level2">
<h2 class="anchored" data-anchor-id="random-variables">Random variables</h2>
<p>You may remember them from your intro to statistics class. Theyâ€™re less like a number and more like a distribution. Less like -1Â°C (the temperature here, now) and more like -3.7Â°C to 7.2Â°C (the daily mean temperature in Blacksburg in December). Less like a particular experiment outcome and more like the experiment itself. Basically, a number that isnâ€™t fixed and can vary.</p>
<p>Pretty simple, right? Hereâ€™s the definition; taken from <a href="https://en.wikipedia.org/wiki/Random_variable#Measure-theoretic_definition">Wikipedia</a>, which in order takes it from <span class="citation" data-cites="fristedt_modern_1996">Fristedt and Gray (<a href="#ref-fristedt_modern_1996" role="doc-biblioref">1996, 11</a>)</span>.</p>
<div id="def-rv" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 1</strong></span> <strong>(Random variable).</strong> Let <span class="math inline">\((\Omega, \mathcal{F}, P)\)</span> be a <a href="https://en.wikipedia.org/wiki/Probability_space">probability space</a> and <span class="math inline">\((E, \mathcal{E})\)</span> a <a href="https://en.wikipedia.org/wiki/Measurable_space">measurable space</a>. Then an <span class="math inline">\((E, \mathcal{E})\)</span><strong>-valued random variable</strong> is a measurable function <span class="math inline">\(X : \Omega \to E\)</span>, which measures that, for every subset <span class="math inline">\(B \in \mathcal{E}\)</span>, its <a href="https://en.wikipedia.org/wiki/Preimage">preimage</a> is <span class="math inline">\(\mathcal{F}\)</span>-measurable; <span class="math inline">\(X^{-1}(B) \in \mathcal{F}\)</span>, where <span class="math inline">\(X^{-1}(B) = \{\omega : X(\omega) \in B\}\)</span>.</p>
</div>
<p>Uhâ€¦ what? Letâ€™s break this down a little.</p>
<section id="example" class="level3">
<h3 class="anchored" data-anchor-id="example">Example</h3>
<p>Let <span class="math inline">\(\Omega = \{ðŸ˜¸,ðŸ˜¿\}\)</span> denote the outcomes of an experiment, with associated probabilities <span class="math inline">\(\mathrm{P}(ðŸ˜¸) = 0.5\)</span> and <span class="math inline">\(\mathrm{P}(ðŸ˜¿) = 0.5\)</span>. What is the average outcome of this experiment? Certainly, it canâ€™t be <span class="math inline">\(0.5ðŸ˜¸ + 0.5ðŸ˜¿\)</span>; that quantity doesnâ€™t make sense. We instead need something we can <em>count</em>, such as the <em>number of happy cats</em>. This we can denote by a <strong>random variable</strong> <span class="math inline">\(X\)</span>, something that maps event outcomes in <span class="math inline">\(\Omega\)</span> to measurable quantities in <span class="math inline">\(E\)</span>, which in this case is <span class="math inline">\(\{0, 1\}\)</span>. Let <span class="math inline">\(X(ðŸ˜¸) = 1\)</span> and <span class="math inline">\(X(ðŸ˜¿) = 0\)</span>; then, to get the probability of a particular outcome in <span class="math inline">\(E\)</span> we must find all entries in <span class="math inline">\(\Omega\)</span> that map to it and sum their probabilities. This can be written as <span id="eq-rv-example"><span class="math display">\[
\mathrm{P}(X = 1) = \mathrm{P}(\{ \omega \in \Omega : X(\omega) = 1 \}) = \mathrm{P}(ðŸ˜¸) = 0.5\ ,
\tag{1}\]</span></span></p>
<p>and analogously for <span class="math inline">\(\mathrm{P}(X = 0) = \mathrm{P}(ðŸ˜¿) = 0.5\)</span>. We can thus evaluate the <em>expected value</em> as <span id="eq-rv-expected"><span class="math display">\[
\mathbb{E}[X] = \sum_{x \in \Omega} x \mathrm{P}(X = x) = 0.5 \mathrm{P}(X = ðŸ˜¸) + 0.5 \mathrm{P}(X = ðŸ˜¿) = 0.5 \cdot 0 + 0.5 \cdot 1 = 0.5\ ,
\tag{2}\]</span></span></p>
<p>meaning that on average the experiment produces one half of a happy cat.</p>
<p>The reason for all the remaining clunkiness in the definition is that its formality stems from <a href="https://en.wikipedia.org/wiki/Measure_(mathematics)">measure theory</a>, a branch of probability theory that can deal with otherwise confusing situations like distributions that are part-discrete and part-continuous. For instance, we need to define <span class="math inline">\(\mathcal{F}\)</span> and <span class="math inline">\(\mathcal{E}\)</span> as collections of subsets of <span class="math inline">\(\Omega\)</span> and <span class="math inline">\(E\)</span> since we canâ€™t map events and values to probabilities directly (continuous distributions would have zero probability), and must instead map sets. When calculating <span class="math inline">\(\mathbb{E}[X]\)</span> we would then have to take the <a href="https://en.wikipedia.org/wiki/Lebesgue_integration">Lebesgue integral</a> <span class="math inline">\(\int_\Omega X dP\)</span>.</p>
<p>One additional small note: we can arrange random variables <span class="math inline">\(X_1, \ldots, X_n\)</span> in a vector to obtain a <strong>random vector</strong> <span class="math inline">\(X = \begin{bmatrix} X_1, \ldots, X_n \end{bmatrix}^\top\)</span>. The only mathematical caveat is that the variables must act on the same probability and measurable spaces.</p>
</section>
<section id="takeaway" class="level3">
<h3 class="anchored" data-anchor-id="takeaway">Takeaway</h3>
<p>In short, I think the best way to remember what random variables are, is by what they <em>arenâ€™t</em>. Specifically, they are not random, and they are not variables. They donâ€™t themselves serve as a source of randomness, instead only taking as an input the outcomes of an already random experiment. They do not vary; despite potentially giving different values upon being sampled, the mathematical object they describe is fixed. Although, given the context in which they typically appear, I can certainly see the appeal of the name.</p>
</section>
</section>
<section id="concentration-bounds" class="level2">
<h2 class="anchored" data-anchor-id="concentration-bounds">Concentration bounds</h2>
<p>Suppose we have a random variable <span class="math inline">\(X\)</span> that is promised to give values in <span class="math inline">\([0,1]\)</span>. We may study such an <span class="math inline">\(X\)</span> via its parameters, such as its expected value <span class="math inline">\(\mathbb{E}[X]\)</span>. While we may have access to that during mathematical analysis, in practice we typically have to rely on some data<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> <span class="math inline">\(\{X_i\}_{i=1}^n\)</span> sampled from <span class="math inline">\(X\)</span> to compute statistics such as the sample mean <span class="math inline">\(\frac{1}{n} \sum_{i=1}^n X_i\)</span>. But, do we know how accurate our approximations are? For instance, can we find some <span class="math inline">\(f\)</span> such that <span id="eq-bound"><span class="math display">\[
\Biggr \lvert \frac{1}{n} \sum_{i=1}^n X_i - \mathbb{E}[X] \Biggr \rvert &lt; f(n)\ ?
\tag{3}\]</span></span></p>
<section id="hoeffdings-inequality" class="level3">
<h3 class="anchored" data-anchor-id="hoeffdings-inequality">Hoeffdingâ€™s inequality</h3>
<p>This famous inequality provides one such bound.</p>
<div id="thm-hoeffding" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1</strong></span> <strong>(Hoeffdingâ€™s inequality).</strong> Let <span class="math inline">\(X_1, \ldots, X_n\)</span> be independent random variables where with probability <span class="math inline">\(1\)</span>, <span class="math inline">\(X_i \in [a_i, b_i]\)</span> (i.e., bounded). Let <span class="math inline">\(R_i \coloneqq b_i - a_i\)</span> be the range. Then for all <span class="math inline">\(\epsilon \geq 0\)</span>, <span id="eq-hoeffding"><span class="math display">\[
P \left( \Biggr \lvert \sum_{i=1}^n (X_i - \mathbb{E}[X_i]) \Biggr \rvert \leq \epsilon \right) \geq 2 \exp \left( -\frac{2 \epsilon^2}{\sum_{i=1}^n R_i^2} \right)\ .
\tag{4}\]</span></span></p>
</div>
<p>We can re-arrange the variables to obtain that for any fixed <span class="math inline">\(\delta \in (0, 1]\)</span>, with probability at least <span class="math inline">\(1 - \delta\)</span>, <span id="eq-hoeffding-alt"><span class="math display">\[
\Biggr \lvert \sum_{i=1}^n (X_i - \mathbb{E}[X_i]) \Biggr \rvert \leq \sqrt{\frac{\sum_{i=1}^n R_i^2 \log(2/\delta)}{2}}\ .
\tag{5}\]</span></span></p>
</section>
<section id="application" class="level3">
<h3 class="anchored" data-anchor-id="application">Application</h3>
<p>The following example is provided by <span class="citation" data-cites="ji_online_2022">Ji (<a href="#ref-ji_online_2022" role="doc-biblioref">2022</a>, Lecture 13)</span>:</p>
<p>Suppose you are given a coin that lands on heads with probability <span class="math inline">\(\mu\)</span>. Every time you flip it, you get an outcome <span class="math inline">\(X_i\)</span> - a Bernoulli distribution with mean <span class="math inline">\(\mu\)</span>. After <span class="math inline">\(n\)</span> flips, you compute the sample mean <span class="math inline">\(\hat{\mu}_n \coloneqq \frac{1}{n} \sum_{i=1}^n X_i\)</span>. By <a href="#thm-hoeffding">Hoeffdingâ€™s inequality</a>, with probability at least <span class="math inline">\(1-\delta\)</span>, <span id="eq-coin1"><span class="math display">\[
| \hat{\mu}_n - \mu | \leq \sqrt{\frac{\log(2/\delta)}{2 n}}\ .
\tag{6}\]</span></span></p>
<p>You may recall that this is consistent with the <a href="https://en.wikipedia.org/wiki/Central_limit_theorem">central limit theorem</a>, which states that the sampling distribution of sample means is <span class="math inline">\(\sigma_{\bar{X}} = \sigma / \sqrt{n}\)</span>.</p>
</section>
</section>
<section id="multi-armed-bandits" class="level2">
<h2 class="anchored" data-anchor-id="multi-armed-bandits">Multi-armed bandits</h2>
<p>I first encountered these through a graduate course I took with Dr.&nbsp;Bo <span class="citation" data-cites="ji_online_2022">Ji (<a href="#ref-ji_online_2022" role="doc-biblioref">2022</a>)</span>; the algorithms and analyses below (as well as the <a href="#concentration-bounds">concentration bounds</a> discussion above) are all taken from lecture notes from that class, although they are originally based on a book by <span class="citation" data-cites="slivkins_introduction_2022">Slivkins (<a href="#ref-slivkins_introduction_2022" role="doc-biblioref">2022</a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/8/82/Las_Vegas_slot_machines.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Image credit: <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit">Wikipedia</a>.</figcaption>
</figure>
</div>
<p>The image above shows a row of slot machines. They are otherwise known as one-armed bandits, as they steal money from you and have one arm you must pull to spin the wheel (although in the ones seen above it seems to have been replaced by buttons).</p>
<p>Generalizing a bit, letâ€™s imagine that we instead have <span class="math inline">\(K\)</span> such arms. Maybe they belong to the same, now much more tricky bandit. Or, maybe they model the possibility of playing different games in the same casino. In any case, at every time point <span class="math inline">\(t\)</span> we must choose one such action <span class="math inline">\(a_t \in [K]\)</span> to play, only learning information about its underlying distribution through the rewards we receive.</p>
<p>There are various possible types of the bandit setting, but here we will only consider <strong>stochastic</strong> (as opposed to adversarial) losses and <strong>multi-armed</strong> (as opposed to linear or Gaussian process) bandits.</p>
<div id="alg-mab" class="pseudocode-container" data-indent-size="1.8em" data-pseudocode-index="1" data-comment-delimiter="//" data-line-number="true" data-alg-title="Algorithm" data-no-end="false">
<div class="pseudocode">
\begin{algorithm} \caption{Stochastic MAB (Framework)} \begin{algorithmic} \Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.} \For{$t = 1, 2, \ldots$} \State Choose an action $a_t \in [K]$. \State Suffer loss $z_t[a_t]$ and also only observe $z_t[a_t]$. \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>Here, <span class="math inline">\(z_t\)</span> is a random vector sampled from the unknown distributions, i.e., <span class="math inline">\(z_t[a] \sim \mathcal{D}_a\)</span>. The defining feature separating this problem from Online Convex Optimization is being only provided one value <span class="math inline">\(z_t[a_t]\)</span> corresponding to the played arm <span class="math inline">\(a_t\)</span>, a.k.a., <strong>bandit feedback</strong>.</p>
<p>Our goal in this setting is to design an algorithm fitting this framework that minimizes the following quantity, known as regret <span id="eq-regret"><span class="math display">\[
\mathcal{R}_T = \sum_{t=1}^T z_t[a_t] - \min_i \sum_{t=1}^T z_t[i]\ .
\tag{7}\]</span></span></p>
<p>Such a definition makes regret a useful metric in many situations, even when experiencing persistent penalties or unreasonable adversaries. In particular, it evaluates performance against the best possible fixed action in hindsight - a value that will compensate for the above scenarios. Note that the definition given in <a href="#eq-regret" class="quarto-xref">Equation&nbsp;7</a> makes <span class="math inline">\(\mathcal{R}_T\)</span> a <a href="#random-variables">random variable</a>, meaning that in practice we aim to bound <span class="math inline">\(\mathbb{E}[\mathcal{R}_T]\)</span>, the expected regret.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<p>We may use the terms loss and reward interchangeably, as they can be thought of as negatives of each other. This is again owed to the definition of regret in <a href="#eq-regret" class="quarto-xref">Equation&nbsp;7</a>, by which minimizing losses is the same as maximizing rewards.</p>
<section id="explore-then-exploit" class="level3">
<h3 class="anchored" data-anchor-id="explore-then-exploit">Explore-then-exploit</h3>
<p>A central issue in the multi-armed bandit problem is that of <strong>exploration versus exploitation</strong> - whether to prioritize investigating the yet unknown, or to take advantage of information already learned. It is not a coincidence this problem appears both here and in <strong>reinforcement learning</strong> - both fall within the realm of <strong>online learning</strong> (when decisions and information are processed sequentially), the only thing separating them is the addition of states.</p>
<p>We start with a simple algorithm that does the two stages separately <span class="citation" data-cites="ji_online_2022">(<a href="#ref-ji_online_2022" role="doc-biblioref">Ji 2022</a>, Lecture 14)</span>.</p>
<div id="alg-explore-exploit" class="pseudocode-container" data-indent-size="1.8em" data-pseudocode-index="2" data-comment-delimiter="//" data-line-number="true" data-alg-title="Algorithm" data-no-end="false">
<div class="pseudocode">
\begin{algorithm} \caption{Explore-then-exploit} \begin{algorithmic} \Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.} \For{$t = 1, 2, \ldots$} \State Explore phase: try each arm $N$ times. \State Exploit phase: determine $\tilde{a}$ with the highest average reward; then play $\tilde{a}$ in all remaining rounds. \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>We wish to bound the probability of getting good approximations on all arms, which we start by bounding each arm individually. That is, we want to bound the deviation of its true mean <span class="math inline">\(\mu(a)\)</span> from its approximation <span class="math inline">\(\hat{\mu}(a)\)</span> after that arm has been pulled <span class="math inline">\(N\)</span> times. Let <span class="math inline">\(\beta_N = \sqrt{\frac{2 \log T}{N}}\)</span>, by <a href="#thm-hoeffding">Hoeffdingâ€™s inequality</a>, <span id="eq-exp-arm"><span class="math display">\[
\mathrm{P}(|\hat{\mu}(a) - \mu(a)| \leq \beta_N) \geq 1 - 2 / T^4\ .
\tag{8}\]</span></span></p>
<p>We define a <em>good event</em> <span class="math inline">\(\mathcal{E}\)</span> as the above being true for all arms, meaning that by the union bound <span id="eq-exp-good"><span class="math display">\[
\mathrm{P}(\mathcal{E}) = 1 - \mathrm{P}(\bar{\mathcal{E}}) \geq
1 - \sum_{a=1}^K \mathrm{P}(|\bar{\mu}(a) - \mu(a)| \geq \beta_N) \geq 1 - 2 K / T^4\ .
\tag{9}\]</span></span></p>
<p>Even if this good event occurs, we may still choose a suboptimal arm <span class="math inline">\(\bar{a}\)</span> in the exploit phase. In that case, the estimate errors for both <span class="math inline">\(\bar{a}\)</span> and the optimal arm <span class="math inline">\(a^*\)</span> are bounded by <span class="math inline">\(\beta_N\)</span>. As such, <span class="math inline">\(\mu(a^*) - \mu(\bar{a}) \leq 2 \beta_N\)</span>. Adding with a max regret of <span class="math inline">\(1\)</span> for <span class="math inline">\(KN\)</span> round of exploration, the total incurred regret in the good case is at most <span id="eq-exp-regret-good"><span class="math display">\[
\mathcal{R}_T \leq K N + (T - KN) \cdot 2 \beta_N \leq KN + 2 T \beta_N = KN + 2 T \sqrt{\frac{2 \log T}{N}}\ .
\tag{10}\]</span></span></p>
<p>This also lets us derive a formula for <span class="math inline">\(N\)</span> which we do by setting the resulting terms equal. In particular, <span class="math inline">\(N = 2 \sqrt[3]{T^2 \log T / K^2}\)</span>, which leads to a good case regret of <span class="math inline">\(\mathrm{O}(T^{2/3} (K \log T)^{1/3})\)</span>. The bad event happens with probability at most <span class="math inline">\(2 K / T^4\)</span>, which when multiplied by a max per-round regret of <span class="math inline">\(1\)</span> gets absorbed by the big O.</p>
<p>For implementations of this and the following algorithms, we make a function <code>play</code> that returns an arm <code>a</code>, and a function <code>feedback</code> that records the resulting reward <code>r</code>. Both functions are supplied with other contextual parameters for convenience.</p>
<div id="29210076" class="cell" data-execution_count="1">
<details open="" class="code-fold">
<summary>Code for Explore-then-exploit</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> log</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> argmax</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ExploreExploit:</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, K, T):</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> K</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N <span class="op">=</span> <span class="bu">round</span>(<span class="dv">2</span> <span class="op">*</span> (T<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> log(T) <span class="op">/</span> K<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>))</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__str__</span>(<span class="va">self</span>):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Explore-then-exploit"</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> play(<span class="va">self</span>, t):</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Choose an arm to play.'''</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">&lt;=</span> <span class="va">self</span>.K<span class="op">*</span><span class="va">self</span>.N:</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Play each arm N times</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> t <span class="op">%</span> <span class="va">self</span>.K</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Play best arm</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.best</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedback(<span class="va">self</span>, t, a, r):</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Receive a reward.'''</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">&lt;=</span> <span class="va">self</span>.K<span class="op">*</span><span class="va">self</span>.N:</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Record reward</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.totals[a] <span class="op">+=</span> r</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">==</span> <span class="va">self</span>.K<span class="op">*</span><span class="va">self</span>.N:</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute best arm</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best <span class="op">=</span> argmax(<span class="va">self</span>.totals)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="epsilon-greedy" class="level3">
<h3 class="anchored" data-anchor-id="epsilon-greedy">Epsilon-greedy</h3>
<p>Instead of doing exploration all at once, we may spread it out over all rounds, making it less frequent over time <span class="citation" data-cites="ji_online_2022">(<a href="#ref-ji_online_2022" role="doc-biblioref">Ji 2022</a>, Lecture 14)</span>. Youâ€™ll see this strategy used quite frequently in reinforcement learning, as it is pretty simple to implement.</p>
<div id="alg-epsilon-greedy" class="pseudocode-container" data-indent-size="1.8em" data-pseudocode-index="3" data-comment-delimiter="//" data-line-number="true" data-alg-title="Algorithm" data-no-end="false">
<div class="pseudocode">
\begin{algorithm} \caption{Epsilon-greedy} \begin{algorithmic} \Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.} \For{$t = 1, 2, \ldots$} \State Toss a coin with success rate $\epsilon_t$. \If{success} \State Explore: choose an arm uniformly at random. \Else \State Exploit: choose an arm with the highest average reward so far. \EndIf \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>With <span class="math inline">\(\epsilon_t = t^{-1/3} (K \log t)^{1/3}\)</span>, Epsilon-greedy achieves the same regret bound, <span class="math inline">\(\mathrm{O}(t^{2/3} (K \log t)^{1/3})\)</span>. We wonâ€™t show it here for brevity, but it uses the same techniques as shown, similarly relying on <a href="#thm-hoeffding">Hoeffdingâ€™s inequality</a>. Note in addition that <a href="#alg-epsilon-greedy">Algorithm 3</a> does not rely on <span class="math inline">\(T\)</span>, which makes it an <strong>anytime</strong> algorithm.</p>
<div id="256864fe" class="cell" data-execution_count="2">
<details open="" class="code-fold">
<summary>Code for Epsilon-greedy</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> log</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> random, randrange</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> argmax, divide, errstate, inf, nan</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EpsilonGreedy:</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, K, _):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> K</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__str__</span>(<span class="va">self</span>):</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Epsilon-greedy"</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eps(<span class="va">self</span>, t):</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">self</span>.K<span class="op">*</span>log(t)<span class="op">/</span>t)<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _best(<span class="va">self</span>):</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>, invalid<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>            avg <span class="op">=</span> divide(<span class="va">self</span>.totals, <span class="va">self</span>.counts)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        avg[avg <span class="op">==</span> inf] <span class="op">=</span> <span class="op">-</span>inf</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        avg[avg <span class="op">==</span> nan] <span class="op">=</span> <span class="op">-</span>inf</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> argmax(avg)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> play(<span class="va">self</span>, t):</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Choose an arm to play.'''</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> random() <span class="op">&lt;</span> <span class="va">self</span>._eps(t):</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Play random arm</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> randrange(<span class="va">self</span>.K)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Play best arm</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>._best()</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedback(<span class="va">self</span>, t, a, r):</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Receive a reward.'''</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals[a] <span class="op">+=</span> r</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts[a] <span class="op">+=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="successive-elimination" class="level3">
<h3 class="anchored" data-anchor-id="successive-elimination">Successive elimination</h3>
<p>We can further incorporate the concept of means and confidence bounds into the algorithm by considering their values at any <span class="math inline">\(t \in [T]\)</span>. In particular, <span id="eq-azuma"><span class="math display">\[
\mathrm{P} \left( |\hat{\mu}_t(a) - \mu(a)| \leq \beta_t(a) \right) \geq \sqrt{\frac{\log (2 K T / \delta)}{2 N_t (a)}}\ .
\tag{11}\]</span></span></p>
<p>This feels very similar to Hoeffdingâ€™s inequality, but actually requires a version generalized to <a href="https://en.wikipedia.org/wiki/Martingale_(probability_theory)">martingales</a>, known as the <a href="https://en.wikipedia.org/wiki/Azuma%27s_inequality">Azuma-Hoeffding inequality</a>.</p>
<p>For convenience, we define <span class="citation" data-cites="ji_online_2022">(<a href="#ref-ji_online_2022" role="doc-biblioref">Ji 2022</a>, Lecture 14)</span> <span id="eq-ucb"><span class="math display">\[
\begin{align}
    \mathrm{UCB}_t(a) &amp;= \hat{\mu}_t(a) + \beta_t(a)\ ,\\
    \mathrm{LCB}_t(a) &amp;= \hat{\mu}_t(a) - \beta_t(a)\ .
\end{align}
\tag{12}\]</span></span></p>
<div id="alg-elimination" class="pseudocode-container" data-indent-size="1.8em" data-pseudocode-index="4" data-comment-delimiter="//" data-line-number="true" data-alg-title="Algorithm" data-no-end="false">
<div class="pseudocode">
\begin{algorithm} \caption{Successive Elimination} \begin{algorithmic} \Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.} \State Initialize active arm set $\mathcal{A}_1 = [K]$. \For{$p = 1, 2, \ldots$} \State Play each arm in $\mathcal{A}_p$ once. \State Let $t$ be the time at the end of the current phase $p$. \State $\mathcal{A}_{p+1} = \{ a \in \mathcal{A}_p : \mathrm{UCB}_t (a) \geq \max_{a' \in \mathcal{A}_p} \mathrm{LCB}_t (a) \}$ \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>We define the good event as before, and assume that it holds. If we at some point eliminate <span class="math inline">\(a^*\)</span>, it means <span class="math inline">\(\mathrm{UCB}_t(a^*) &lt; \mathrm{LCB}_t(a')\)</span> for some other arm <span class="math inline">\(a'\)</span>, implying <span class="math inline">\(\mu(a^*) &lt; \mu(a')\)</span> and thus a contradiction. Then, assume there is some arm <span class="math inline">\(a \in \mathcal{A}_{p+1}\)</span> during phase <span class="math inline">\(p\)</span> ending at time <span class="math inline">\(t\)</span> such that <span class="math inline">\(\mu(a^*) - \mu(a) &gt; 4 \beta_t(a)\)</span>. Then, <span id="eq-elimination1"><span class="math display">\[
\mathrm{LCB}_t(a) \leq \mu(a) + 2 \beta_t(a) &lt; \mu(a^*) - 2 \beta_t(a^*) \leq \mathrm{UCB}_t(a^*)\ ,
\tag{13}\]</span></span> implying that this arm should have been eliminated. Thus, the regret contributed by arm <span class="math inline">\(a\)</span> is <span id="eq-elimination2"><span class="math display">\[
\mathcal{R}_{a,t} \leq 4 N_t(a) \sqrt{\frac{\log(2 K T / \delta)}{2 N_t(a)}} = \mathrm{O}(\sqrt{N_t(a) \log(K T / \delta)})\ .
\tag{14}\]</span></span></p>
<p>Using the Cauchy-Schwarz inequality, <span class="math inline">\(\sum_a \sqrt{N_t(a)} \leq \sqrt{\sum_a N_t (a) \cdot \sum_a 1} =  \sqrt{t K}\)</span>, meaning <span id="eq-elimination3"><span class="math display">\[
\mathcal{R}_t = \sum_{a \in [K]} \mathcal{R}_{a,t} = \mathrm{O}(\sqrt{\log(K T / \delta)}) \cdot \sum_a \sqrt{N_t(a)} \leq \mathrm{O}(\sqrt{K t \log (K T / \delta)})\ .
\tag{15}\]</span></span></p>
<p>We thus have that <span class="math inline">\(\mathcal{R}_T = \mathrm{O}(\sqrt{K T \log (K T / \delta)})\)</span>.</p>
<p>Note that the above bounds have a configurable value <span class="math inline">\(\delta \in (0, 1]\)</span>, which makes them take effect with probability at least <span class="math inline">\(1 - \delta\)</span>. In practice, we need to set <code>delta</code> to a ridiculously high value for any arms to actually become eliminated within a reasonable amount of time.</p>
<div id="bfb1d081" class="cell" data-execution_count="3">
<details open="" class="code-fold">
<summary>Code for Successive elimination</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> random, randrange</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> argmax, divide, errstate, inf, nan, log, sqrt</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SuccessiveElimination:</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, K, T, delta<span class="op">=</span><span class="dv">1500</span>):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num <span class="op">=</span> log(<span class="dv">2</span> <span class="op">*</span> K <span class="op">*</span> T <span class="op">/</span> delta) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="va">self</span>.num <span class="op">&gt;</span> <span class="dv">0</span>, <span class="st">"delta too large"</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.A <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(K))</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__str__</span>(<span class="va">self</span>):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Successive elimination"</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _mu(<span class="va">self</span>):</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>, invalid<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>            mu <span class="op">=</span> divide(<span class="va">self</span>.totals, <span class="va">self</span>.counts)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>        mu[mu <span class="op">==</span> inf] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>        mu[mu <span class="op">==</span> nan] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mu</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _beta(<span class="va">self</span>):</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>            beta <span class="op">=</span> sqrt(divide(<span class="va">self</span>.num, <span class="va">self</span>.counts))</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> beta</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> play(<span class="va">self</span>, t):</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Choose an arm to play.'''</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.idx <span class="op">==</span> <span class="bu">len</span>(<span class="va">self</span>.A):</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update arm set A</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>            u, b <span class="op">=</span> <span class="va">self</span>._mu(), <span class="va">self</span>._beta()</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>            lcb, ucb <span class="op">=</span> u<span class="op">-</span>b, u<span class="op">+</span>b</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.A <span class="op">=</span> [a <span class="cf">for</span> a <span class="kw">in</span> <span class="va">self</span>.A <span class="cf">if</span> ucb[a] <span class="op">&gt;=</span> np.<span class="bu">max</span>(lcb)]</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Play each arm in A</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> <span class="va">self</span>.A[<span class="va">self</span>.idx]</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.idx <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedback(<span class="va">self</span>, t, a, r):</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Receive a reward.'''</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals[a] <span class="op">+=</span> r</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts[a] <span class="op">+=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="ucb" class="level3">
<h3 class="anchored" data-anchor-id="ucb">UCB</h3>
<p>Since the event of eliminating an arm may be quite rare, we may instead just sample the arm with the highest <span class="math inline">\(\mathrm{UCB}_t(a)\)</span>. This strategy demonstrates a principle known as <em>optimism in the face of uncertainty</em> <span class="citation" data-cites="ji_online_2022">(<a href="#ref-ji_online_2022" role="doc-biblioref">Ji 2022</a>, Lecture 15)</span> - that is, both arms that have high sample mean and arms with fewer samples will have a larger UCB and thus more likely to get chosen.</p>
<div id="alg-ucb" class="pseudocode-container" data-indent-size="1.8em" data-pseudocode-index="5" data-comment-delimiter="//" data-line-number="true" data-alg-title="Algorithm" data-no-end="false">
<div class="pseudocode">
\begin{algorithm} \caption{UCB} \begin{algorithmic} \Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.} \For{$t = 1, 2, \ldots$} \State $a_t = \arg\max_{a \in [K]} \mathrm{UCB}_t (a)$ \EndFor \end{algorithmic} \end{algorithm}
</div>
</div>
<p>Similar to before, <span class="math inline">\(\mu(a^*) - \mu(a_t) \leq 2 \beta_t (a_t)\)</span> in the good event. We thus have <span id="eq-ucb1"><span class="math display">\[
\mathcal{R}_T = \sum_{t=1}^T r_t \leq c \sqrt{\log (2 K T / \delta)} \sum_{t=1}^T \sqrt{\frac{1}{N_t(a_t)}}\ ,
\tag{16}\]</span></span></p>
<p>where the latter summation is bounded by <span id="eq-ucb2"><span class="math display">\[
\sum_{t=1}^T \sqrt{\frac{1}{N_t(a_t)}} = \sum_{a=1}^K \sum_{m=1}^{N_T(a)} \sqrt{1/m} \leq c' \sum_{a=1}^K \sqrt{N_T(a)} = \mathrm{O}(\sqrt{K T})\ .
\tag{17}\]</span></span></p>
<p>Thus, the regret of <a href="#alg-ucb">UCB</a> is <span class="math inline">\(\mathrm{O}(\sqrt{K T \log (K T / \delta)})\)</span>.</p>
<div id="c6efd185" class="cell" data-execution_count="4">
<details open="" class="code-fold">
<summary>Code for UCB</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> random, randrange</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> argmax, divide, errstate, inf, nan, log, sqrt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UCB:</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, K, T, delta<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num <span class="op">=</span> log(<span class="dv">2</span> <span class="op">*</span> K <span class="op">*</span> T <span class="op">/</span> delta) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="va">self</span>.num <span class="op">&gt;</span> <span class="dv">0</span>, <span class="st">"delta too large"</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__str__</span>(<span class="va">self</span>):</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"UCB"</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _mu(<span class="va">self</span>):</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>, invalid<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            mu <span class="op">=</span> divide(<span class="va">self</span>.totals, <span class="va">self</span>.counts)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        mu[mu <span class="op">==</span> inf] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        mu[mu <span class="op">==</span> nan] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mu</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _beta(<span class="va">self</span>):</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>            beta <span class="op">=</span> sqrt(divide(<span class="va">self</span>.num, <span class="va">self</span>.counts))</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> beta</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> play(<span class="va">self</span>, t):</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Choose an arm to play.'''</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>        ucb <span class="op">=</span> <span class="va">self</span>._mu() <span class="op">+</span> <span class="va">self</span>._beta()</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> argmax(ucb)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedback(<span class="va">self</span>, t, a, r):</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Receive a reward.'''</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals[a] <span class="op">+=</span> r</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts[a] <span class="op">+=</span> <span class="dv">1</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary">Summary</h3>
<p>Here is a compilation of the derived bounds so far:</p>
<table class="table">
<caption>Summary of theoretic regret bounds.</caption>
<thead>
<tr class="header">
<th>Algorithm</th>
<th>Regret</th>
<th>Anytime</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><a href="#alg-explore-exploit">Explore-then-exploit</a></td>
<td><span class="math inline">\(\mathrm{O}(T^{2/3} (K \log T)^{1/3})\)</span></td>
<td>âŒ</td>
</tr>
<tr class="even">
<td><a href="#alg-epsilon-greedy">Epsilon-greedy</a></td>
<td><span class="math inline">\(\mathrm{O}(t^{2/3} (K \log t)^{1/3})\)</span></td>
<td>âœ…</td>
</tr>
<tr class="odd">
<td><a href="#alg-elimination">Successive elimination</a></td>
<td><span class="math inline">\(\mathrm{O}(\sqrt{K T \log (K T / \delta)})\)</span></td>
<td>âŒ</td>
</tr>
<tr class="even">
<td><a href="#alg-ucb">UCB</a></td>
<td><span class="math inline">\(\mathrm{O}(\sqrt{K T \log (K T / \delta)})\)</span></td>
<td>âŒ</td>
</tr>
</tbody>
</table>
<p>On a final note, the above bounds are all problem-independent. We can instead derive <em>problem-dependent</em> bounds, such as <span id="eq-ucb-prob"><span class="math display">\[
\mathcal{R}_T = \sum_{a : \Delta(a) &gt; 0} \mathrm{O} \left( \frac{\log(K T / \delta)}{\delta(a)} \right)\ ,
\tag{18}\]</span></span></p>
<p>for <a href="#alg-ucb">UCB</a>, where <span class="math inline">\(\Delta(a) \coloneqq \mu(a^*) - \mu(a)\)</span>.</p>
</section>
<section id="simulation" class="level3">
<h3 class="anchored" data-anchor-id="simulation">Simulation</h3>
<p>Now, itâ€™s time to put the algorithms to the test!</p>
<section id="technical-note" class="level4">
<h4 class="anchored" data-anchor-id="technical-note">Technical note</h4>
<p>But first, a small note on the simulation details. As the rewards (and thus performance) are highly stochastic, we will need to run many trials to get an accurate result. Even when results are recorded once every <code>F</code> steps, we still run into situations where the times for storing and churning data may compete with those of running the algorithms. We have several possible approaches:</p>
<ul>
<li><em>Store them all:</em> pre-allocate a huge array, and process it once afterwards. This understandably causes slowdowns.</li>
<li><em>Aggregate last:</em> i.e., iterate over algorithms and timesteps first, then trials. This may seem like a perfect solution at first, but it runs into a caveat of the algorithms storing internal parameters. That is, algorithms from some runs will have more information about certain arms than others, so we canâ€™t just re-sample the same instance many times. The way to address this would involve storing an array of algorithms proportional to the number of trials, which is again inefficient.</li>
<li><em>Online aggregation:</em> iterate over trials first, and store a statistic for each algorithm/timestep. The way we avoid having a separate dimension for trials is via an approximation algorithm that aggregates statistics as they come in - <a href="https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm">Welfordâ€™s online algorithm</a>.</li>
</ul>
<p>We will use the latter approach, which is what lets us compute 1000 samples for each data point.</p>
<div id="67c4ee73" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>Seed random number generators</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> seed <span class="im">as</span> py_seed</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> seed <span class="im">as</span> np_seed</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>py_seed(<span class="dv">5805</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>np_seed(<span class="dv">5805</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>In particular, we will simulate having to choose between <span class="math inline">\(K=2\)</span> arms:</p>
<ol type="1">
<li>A uniform distribution on <span class="math inline">\([0,1]\)</span>, i.e., mean <span class="math inline">\(0.5\)</span> and standard deviation <span class="math inline">\(\sqrt{1/12} \approx 0.29\)</span>.</li>
<li>A normal distribution with mean <span class="math inline">\(0.6\)</span> and standard deviation <span class="math inline">\(0.2\)</span>.</li>
</ol>
<p>The above statistics indicate that arm 2 is more optimal, but arm 1 has a wider distribution of rewards.</p>
<div id="a60e448a" class="cell" data-execution_count="6">
<details open="" class="code-fold">
<summary>Simulation code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> random</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> normal</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> zeros, sqrt</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation parameters</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="dv">1000</span>    <span class="co"># Number of rounds</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>F <span class="op">=</span> <span class="dv">10</span>      <span class="co"># Logging frequency</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">1000</span>    <span class="co"># Number of trials</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Arms to explore</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fl">0.6</span>]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> <span class="bu">max</span>(means)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>arms <span class="op">=</span> [random, <span class="kw">lambda</span>: normal(means[<span class="dv">1</span>], <span class="fl">0.2</span>, <span class="dv">1</span>).item()]</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> <span class="bu">len</span>(arms)</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithms to use</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>cs <span class="op">=</span> [ExploreExploit, EpsilonGreedy, SuccessiveElimination, UCB]</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> <span class="bu">len</span>(cs)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate algorithms</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> zeros((T<span class="op">//</span>F<span class="op">+</span><span class="dv">1</span>, A))</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> zeros((T<span class="op">//</span>F<span class="op">+</span><span class="dv">1</span>, A))</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, N<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, c <span class="kw">in</span> <span class="bu">enumerate</span>(cs):</span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>        alg <span class="op">=</span> c(K, T)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>        rgt <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, T<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>            a <span class="op">=</span> alg.play(t)</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>            r <span class="op">=</span> arms[a]()</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>            alg.feedback(t, a, r)</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>            rgt <span class="op">+=</span> best <span class="op">-</span> r</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> t <span class="op">%</span> F <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Welford's online algorithm</span></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>                xn1 <span class="op">=</span> x[t<span class="op">//</span>F, i]</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>                x[t<span class="op">//</span>F, i] <span class="op">=</span> ((n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>xn1 <span class="op">+</span> rgt) <span class="op">/</span> n</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>                s[t<span class="op">//</span>F, i] <span class="op">+=</span> (rgt <span class="op">-</span> xn1) <span class="op">*</span> (rgt <span class="op">-</span> x[t<span class="op">//</span>F, i])</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="fl">0.2</span><span class="op">*</span>sqrt(s <span class="op">/</span> (N<span class="op">-</span><span class="dv">1</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>We now plot the mean regret <span class="math inline">\(\mathcal{R}_t\)</span> of each algorithm, as well as the <span class="math inline">\(\pm 0.2\)</span> sample standard deviation margins.</p>
<div id="cell-fig-line" class="cell" data-execution_count="7">
<details class="code-fold">
<summary>Code for plotting regret</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> np.arange(<span class="dv">1</span>, T<span class="op">+</span><span class="dv">2</span>, F)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.plot(t, x)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(A):</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    plt.fill_between(t, x[:,i]<span class="op">-</span>s[:,i], x[:,i]<span class="op">+</span>s[:,i], alpha<span class="op">=</span><span class="fl">.15</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Timestep"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Regret"</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>plt.legend([c(K, T) <span class="cf">for</span> c <span class="kw">in</span> cs])<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-line" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-line-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="1-probability_files/figure-html/fig-line-output-1.png" width="585" height="429" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-line-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Performance of MAB algorithms
</figcaption>
</figure>
</div>
</div>
</div>
<p>The above performance roughly matches what we should expect. Most notably, <a href="#alg-explore-exploit">Explore-then-exploit</a> accumulates linear regret until a certain time, where it sharply switches to exploitation and plateus. The other algorithms gently bend down towards it instead, allowing them to achieve lower final regrets.</p>
<p>Note that the above shouldnâ€™t be used as a definitive guide for how the algorithms compare, as itâ€™s specific to the problem instance and algorithm parameters. In particular, the performance of <a href="#alg-elimination">Successive elimination</a> is highly dependent on its artificial parameter <span class="math inline">\(\delta = 1500\)</span>, as it determines how soon the trend starts bending toward a plateu. Still, it may give an indication as to why the <a href="#alg-ucb">UCB</a> algorithm and its variants are so common in practice.</p>


<!-- -->


</section>
</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-fristedt_modern_1996" class="csl-entry" role="listitem">
Fristedt, Bert E., and Lawrence F. Gray. 1996. <em>A <span>Modern</span> <span>Approach</span> to <span>Probability</span> <span>Theory</span></em>. Springer Science &amp; Business Media.
</div>
<div id="ref-ji_online_2022" class="csl-entry" role="listitem">
Ji, Bo. 2022. <span>â€œOnline <span>Learning</span> and <span>Sequential</span> <span>Decision</span> <span>Making</span>.â€</span> CS6104 Advanced Topics in Theory of Computation.
</div>
<div id="ref-slivkins_introduction_2022" class="csl-entry" role="listitem">
Slivkins, Aleksandrs. 2022. <span>â€œIntroduction to <span>Multi</span>-<span>Armed</span> <span>Bandits</span>.â€</span> arXiv. <a href="http://arxiv.org/abs/1904.07272">http://arxiv.org/abs/1904.07272</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>These <span class="math inline">\(X_i\)</span> can either be thought of as fixed values or i.i.d. random variables. In coming examples, we will use the latter.<a href="#fnref1" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
<li id="fn2"><p>In practice, it often ends up more convenient to bound the <em>pseudo-regret</em> <span class="math inline">\(\bar{\mathcal{R}}_T\)</span>, which swaps the order of <span class="math inline">\(\mathbb{E}\)</span> and <span class="math inline">\(\min\)</span>, turning it into a <span class="math inline">\(\max\)</span>. By Jensenâ€™s inequality, <span class="math inline">\(\mathbb{E}[\mathcal{R}_T] \geq \bar{\mathcal{R}}_T\)</span>.<a href="#fnref2" class="footnote-back" role="doc-backlink">â†©ï¸Ž</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/zheng-alice\.github\.io\/blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="adidenkova/blog-comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb8" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> Probability theory and random variables</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> Concentration bounds and multi-armed bandits</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> In which we introduce random variables and describe the theory behind bounding them via concentration inequalities. We then introduce several multi-armed bandit algorithms to see how such inequalities may be used to evaluate their performance.</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 2023/12/01</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - Probability theory</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - Random variables</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">  - Concentration inequalities</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">  - Multi-armed bandits</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">  - Online learning</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> blog.bib</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="an">filters:</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co">  - pseudocode</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- Describe the probability theory and random variables. --&gt;</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="fu">## Random variables</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>You may remember them from your intro to statistics class.</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>They're less like a number and more like a distribution.</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>Less like -1Â°C (the temperature here, now) and more like -3.7Â°C to 7.2Â°C (the daily mean temperature in Blacksburg in December).</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>Less like a particular experiment outcome and more like the experiment itself.</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>Basically, a number that isn't fixed and can vary.</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>Pretty simple, right?</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>Here's the definition; taken from <span class="co">[</span><span class="ot">Wikipedia</span><span class="co">](https://en.wikipedia.org/wiki/Random_variable#Measure-theoretic_definition)</span>, which in order takes it from @fristedt_modern_1996 <span class="co">[</span><span class="ot">page 11</span><span class="co">]</span>.</span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>::: {#def-rv}</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>**(Random variable).**</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>Let $(\Omega, \mathcal{F}, P)$ be a <span class="co">[</span><span class="ot">probability space</span><span class="co">](https://en.wikipedia.org/wiki/Probability_space)</span> and $(E, \mathcal{E})$ a <span class="co">[</span><span class="ot">measurable space</span><span class="co">](https://en.wikipedia.org/wiki/Measurable_space)</span>.</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>Then an $(E, \mathcal{E})$**-valued random variable** is a measurable function $X : \Omega \to E$, which measures that, for every subset $B \in \mathcal{E}$, its <span class="co">[</span><span class="ot">preimage</span><span class="co">](https://en.wikipedia.org/wiki/Preimage)</span> is $\mathcal{F}$-measurable; $X^{-1}(B) \in \mathcal{F}$, where $X^{-1}(B) = <span class="sc">\{</span>\omega : X(\omega) \in B<span class="sc">\}</span>$.</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>Uh... what?</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>Let's break this down a little.</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example</span></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>Let $\Omega = <span class="sc">\{</span>ðŸ˜¸,ðŸ˜¿<span class="sc">\}</span>$ denote the outcomes of an experiment, with associated probabilities $\mathrm{P}(ðŸ˜¸) = 0.5$ and $\mathrm{P}(ðŸ˜¿) = 0.5$.</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>What is the average outcome of this experiment?</span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a>Certainly, it can't be $0.5ðŸ˜¸ + 0.5ðŸ˜¿$; that quantity doesn't make sense.</span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>We instead need something we can *count*, such as the *number of happy cats*.</span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>This we can denote by a **random variable** $X$, something that maps event outcomes in $\Omega$ to measurable quantities in $E$, which in this case is $<span class="sc">\{</span>0, 1<span class="sc">\}</span>$.</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>Let $X(ðŸ˜¸) = 1$ and $X(ðŸ˜¿) = 0$; then, to get the probability of a particular outcome in $E$ we must find all entries in $\Omega$ that map to it and sum their probabilities.</span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a>This can be written as</span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>\mathrm{P}(X = 1) = \mathrm{P}(<span class="sc">\{</span> \omega \in \Omega : X(\omega) = 1 <span class="sc">\}</span>) = \mathrm{P}(ðŸ˜¸) = 0.5\ ,</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>$$ {#eq-rv-example}</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a>and analogously for $\mathrm{P}(X = 0) = \mathrm{P}(ðŸ˜¿) = 0.5$.</span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a>We can thus evaluate the *expected value* as</span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span> = \sum_{x \in \Omega} x \mathrm{P}(X = x) = 0.5 \mathrm{P}(X = ðŸ˜¸) + 0.5 \mathrm{P}(X = ðŸ˜¿) = 0.5 \cdot 0 + 0.5 \cdot 1 = 0.5\ ,</span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a>$$ {#eq-rv-expected}</span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>meaning that on average the experiment produces one half of a happy cat.</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>The reason for all the remaining clunkiness in the definition is that its formality stems from <span class="co">[</span><span class="ot">measure theory</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Measure_(mathematics)), a branch of probability theory that can deal with otherwise confusing situations like distributions that are part-discrete and part-continuous.</span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>For instance, we need to define $\mathcal{F}$ and $\mathcal{E}$ as collections of subsets of $\Omega$ and $E$ since we can't map events and values to probabilities directly (continuous distributions would have zero probability), and must instead map sets.</span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>When calculating $\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span>$ we would then have to take the <span class="co">[</span><span class="ot">Lebesgue integral</span><span class="co">](https://en.wikipedia.org/wiki/Lebesgue_integration)</span> $\int_\Omega X dP$.</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>One additional small note: we can arrange random variables $X_1, \ldots, X_n$ in a vector to obtain a **random vector** $X = \begin{bmatrix} X_1, \ldots, X_n \end{bmatrix}^\top$.</span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>The only mathematical caveat is that the variables must act on the same probability and measurable spaces.</span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a><span class="fu">### Takeaway</span></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a>In short, I think the best way to remember what random variables are, is by what they *aren't*.</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>Specifically, they are not random, and they are not variables.</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a>They don't themselves serve as a source of randomness, instead only taking as an input the outcomes of an already random experiment.</span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>They do not vary; despite potentially giving different values upon being sampled, the mathematical object they describe is fixed.</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>Although, given the context in which they typically appear, I can certainly see the appeal of the name.</span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a><span class="fu">## Concentration bounds</span></span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a>Suppose we have a random variable $X$ that is promised to give values in $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$.</span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>We may study such an $X$ via its parameters, such as its expected value $\mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span>$.</span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a>While we may have access to that during mathematical analysis, in practice we typically have to rely on some data<span class="ot">[^rv]</span> $<span class="sc">\{</span>X_i<span class="sc">\}</span>_{i=1}^n$ sampled from $X$ to compute statistics such as the sample mean $\frac{1}{n} \sum_{i=1}^n X_i$.</span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a>But, do we know how accurate our approximations are?</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a>For instance, can we find some $f$ such that</span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a>\Biggr \lvert \frac{1}{n} \sum_{i=1}^n X_i - \mathbb{E}<span class="co">[</span><span class="ot">X</span><span class="co">]</span> \Biggr \rvert &lt; f(n)\ ?</span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bound}</span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a><span class="ot">[^rv]: </span>These $X_i$ can either be thought of as fixed values or i.i.d. random variables. In coming examples, we will use the latter.</span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a><span class="fu">### Hoeffding's inequality</span></span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a>This famous inequality provides one such bound.</span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a>::: {#thm-hoeffding}</span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a>**(Hoeffding's inequality).**</span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a>Let $X_1, \ldots, X_n$ be independent random variables where with probability $1$, $X_i \in <span class="co">[</span><span class="ot">a_i, b_i</span><span class="co">]</span>$ (i.e., bounded).</span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a>Let $R_i \coloneqq b_i - a_i$ be the range.</span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a>Then for all $\epsilon \geq 0$,</span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a>P \left( \Biggr \lvert \sum_{i=1}^n (X_i - \mathbb{E}<span class="co">[</span><span class="ot">X_i</span><span class="co">]</span>) \Biggr \rvert \leq \epsilon \right) \geq 2 \exp \left( -\frac{2 \epsilon^2}{\sum_{i=1}^n R_i^2} \right)\ .</span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a>$$ {#eq-hoeffding}</span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a>We can re-arrange the variables to obtain that for any fixed $\delta \in (0, 1]$, with probability at least $1 - \delta$,</span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true" tabindex="-1"></a>\Biggr \lvert \sum_{i=1}^n (X_i - \mathbb{E}<span class="co">[</span><span class="ot">X_i</span><span class="co">]</span>) \Biggr \rvert \leq \sqrt{\frac{\sum_{i=1}^n R_i^2 \log(2/\delta)}{2}}\ .</span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true" tabindex="-1"></a>$$ {#eq-hoeffding-alt}</span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true" tabindex="-1"></a><span class="fu">### Application</span></span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true" tabindex="-1"></a>The following example is provided by @ji_online_2022 <span class="co">[</span><span class="ot">Lecture 13</span><span class="co">]</span>:</span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true" tabindex="-1"></a>Suppose you are given a coin that lands on heads with probability $\mu$.</span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true" tabindex="-1"></a>Every time you flip it, you get an outcome $X_i$ - a Bernoulli distribution with mean $\mu$.</span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true" tabindex="-1"></a>After $n$ flips, you compute the sample mean $\hat{\mu}_n \coloneqq \frac{1}{n} \sum_{i=1}^n X_i$.</span>
<span id="cb8-115"><a href="#cb8-115" aria-hidden="true" tabindex="-1"></a>By <span class="co">[</span><span class="ot">Hoeffding's inequality</span><span class="co">](#thm-hoeffding)</span>, with probability at least $1-\delta$,</span>
<span id="cb8-116"><a href="#cb8-116" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-117"><a href="#cb8-117" aria-hidden="true" tabindex="-1"></a>| \hat{\mu}_n - \mu | \leq \sqrt{\frac{\log(2/\delta)}{2 n}}\ .</span>
<span id="cb8-118"><a href="#cb8-118" aria-hidden="true" tabindex="-1"></a>$$ {#eq-coin1}</span>
<span id="cb8-119"><a href="#cb8-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-120"><a href="#cb8-120" aria-hidden="true" tabindex="-1"></a>You may recall that this is consistent with the <span class="co">[</span><span class="ot">central limit theorem</span><span class="co">](https://en.wikipedia.org/wiki/Central_limit_theorem)</span>, which states that the sampling distribution of sample means is $\sigma_{\bar{X}} = \sigma / \sqrt{n}$.</span>
<span id="cb8-121"><a href="#cb8-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-122"><a href="#cb8-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-123"><a href="#cb8-123" aria-hidden="true" tabindex="-1"></a><span class="fu">## Multi-armed bandits</span></span>
<span id="cb8-124"><a href="#cb8-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-125"><a href="#cb8-125" aria-hidden="true" tabindex="-1"></a>I first encountered these through a graduate course I took with Dr. Bo @ji_online_2022; the algorithms and analyses below (as well as the <span class="co">[</span><span class="ot">concentration bounds</span><span class="co">](#concentration-bounds)</span> discussion above) are all taken from lecture notes from that class, although they are originally based on a book by @slivkins_introduction_2022.</span>
<span id="cb8-126"><a href="#cb8-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-127"><a href="#cb8-127" aria-hidden="true" tabindex="-1"></a>!<span class="co">[</span><span class="ot">Image credit: [Wikipedia](https://en.wikipedia.org/wiki/Multi-armed_bandit).</span><span class="co">](https://upload.wikimedia.org/wikipedia/commons/8/82/Las_Vegas_slot_machines.jpg)</span>{width=50%}</span>
<span id="cb8-128"><a href="#cb8-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-129"><a href="#cb8-129" aria-hidden="true" tabindex="-1"></a>The image above shows a row of slot machines.</span>
<span id="cb8-130"><a href="#cb8-130" aria-hidden="true" tabindex="-1"></a>They are otherwise known as one-armed bandits, as they steal money from you and have one arm you must pull to spin the wheel (although in the ones seen above it seems to have been replaced by buttons).</span>
<span id="cb8-131"><a href="#cb8-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-132"><a href="#cb8-132" aria-hidden="true" tabindex="-1"></a>Generalizing a bit, let's imagine that we instead have $K$ such arms.</span>
<span id="cb8-133"><a href="#cb8-133" aria-hidden="true" tabindex="-1"></a>Maybe they belong to the same, now much more tricky bandit.</span>
<span id="cb8-134"><a href="#cb8-134" aria-hidden="true" tabindex="-1"></a>Or, maybe they model the possibility of playing different games in the same casino.</span>
<span id="cb8-135"><a href="#cb8-135" aria-hidden="true" tabindex="-1"></a>In any case, at every time point $t$ we must choose one such action $a_t \in <span class="co">[</span><span class="ot">K</span><span class="co">]</span>$ to play, only learning information about its underlying distribution through the rewards we receive.</span>
<span id="cb8-136"><a href="#cb8-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-137"><a href="#cb8-137" aria-hidden="true" tabindex="-1"></a>There are various possible types of the bandit setting, but here we will only consider **stochastic** (as opposed to adversarial) losses and **multi-armed** (as opposed to linear or Gaussian process) bandits.</span>
<span id="cb8-138"><a href="#cb8-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-139"><a href="#cb8-139" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb8-140"><a href="#cb8-140" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: alg-mab</span></span>
<span id="cb8-141"><a href="#cb8-141" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.8em"</span></span>
<span id="cb8-142"><a href="#cb8-142" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb8-143"><a href="#cb8-143" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb8-144"><a href="#cb8-144" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb8-145"><a href="#cb8-145" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb8-146"><a href="#cb8-146" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-&amp;number: true</span></span>
<span id="cb8-147"><a href="#cb8-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-148"><a href="#cb8-148" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb8-149"><a href="#cb8-149" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Stochastic MAB (Framework)}</span></span>
<span id="cb8-150"><a href="#cb8-150" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb8-151"><a href="#cb8-151" aria-hidden="true" tabindex="-1"></a><span class="in">\Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.}</span></span>
<span id="cb8-152"><a href="#cb8-152" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$t = 1, 2, \ldots$}</span></span>
<span id="cb8-153"><a href="#cb8-153" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Choose an action $a_t \in [K]$.</span></span>
<span id="cb8-154"><a href="#cb8-154" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Suffer loss $z_t[a_t]$ and also only observe $z_t[a_t]$.</span></span>
<span id="cb8-155"><a href="#cb8-155" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb8-156"><a href="#cb8-156" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb8-157"><a href="#cb8-157" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb8-158"><a href="#cb8-158" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-159"><a href="#cb8-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-160"><a href="#cb8-160" aria-hidden="true" tabindex="-1"></a>Here, $z_t$ is a random vector sampled from the unknown distributions, i.e., $z_t<span class="co">[</span><span class="ot">a</span><span class="co">]</span> \sim \mathcal{D}_a$.</span>
<span id="cb8-161"><a href="#cb8-161" aria-hidden="true" tabindex="-1"></a>The defining feature separating this problem from Online Convex Optimization is being only provided one value $z_t<span class="co">[</span><span class="ot">a_t</span><span class="co">]</span>$ corresponding to the played arm $a_t$, a.k.a., **bandit feedback**.</span>
<span id="cb8-162"><a href="#cb8-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-163"><a href="#cb8-163" aria-hidden="true" tabindex="-1"></a>Our goal in this setting is to design an algorithm fitting this framework that minimizes the following quantity, known as regret</span>
<span id="cb8-164"><a href="#cb8-164" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-165"><a href="#cb8-165" aria-hidden="true" tabindex="-1"></a>\mathcal{R}_T = \sum_{t=1}^T z_t[a_t] - \min_i \sum_{t=1}^T z_t<span class="co">[</span><span class="ot">i</span><span class="co">]</span>\ .</span>
<span id="cb8-166"><a href="#cb8-166" aria-hidden="true" tabindex="-1"></a>$$ {#eq-regret}</span>
<span id="cb8-167"><a href="#cb8-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-168"><a href="#cb8-168" aria-hidden="true" tabindex="-1"></a>Such a definition makes regret a useful metric in many situations, even when experiencing persistent penalties or unreasonable adversaries.</span>
<span id="cb8-169"><a href="#cb8-169" aria-hidden="true" tabindex="-1"></a>In particular, it evaluates performance against the best possible fixed action in hindsight - a value that will compensate for the above scenarios.</span>
<span id="cb8-170"><a href="#cb8-170" aria-hidden="true" tabindex="-1"></a>Note that the definition given in @eq-regret makes $\mathcal{R}_T$ a <span class="co">[</span><span class="ot">random variable</span><span class="co">](#random-variables)</span>, meaning that in practice we aim to bound $\mathbb{E}<span class="co">[</span><span class="ot">\mathcal{R}_T</span><span class="co">]</span>$, the expected regret.<span class="ot">[^pseudo]</span></span>
<span id="cb8-171"><a href="#cb8-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-172"><a href="#cb8-172" aria-hidden="true" tabindex="-1"></a><span class="ot">[^pseudo]: </span>In practice, it often ends up more convenient to bound the *pseudo-regret* $\bar{\mathcal{R}}_T$, which swaps the order of $\mathbb{E}$ and $\min$, turning it into a $\max$.</span>
<span id="cb8-173"><a href="#cb8-173" aria-hidden="true" tabindex="-1"></a>By Jensen's inequality, $\mathbb{E}<span class="co">[</span><span class="ot">\mathcal{R}_T</span><span class="co">]</span> \geq \bar{\mathcal{R}}_T$.</span>
<span id="cb8-174"><a href="#cb8-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-175"><a href="#cb8-175" aria-hidden="true" tabindex="-1"></a>We may use the terms loss and reward interchangeably, as they can be thought of as negatives of each other.</span>
<span id="cb8-176"><a href="#cb8-176" aria-hidden="true" tabindex="-1"></a>This is again owed to the definition of regret in @eq-regret, by which minimizing losses is the same as maximizing rewards.</span>
<span id="cb8-177"><a href="#cb8-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-178"><a href="#cb8-178" aria-hidden="true" tabindex="-1"></a><span class="fu">### Explore-then-exploit</span></span>
<span id="cb8-179"><a href="#cb8-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-180"><a href="#cb8-180" aria-hidden="true" tabindex="-1"></a>A central issue in the multi-armed bandit problem is that of **exploration versus exploitation** - whether to prioritize investigating the yet unknown, or to take advantage of information already learned.</span>
<span id="cb8-181"><a href="#cb8-181" aria-hidden="true" tabindex="-1"></a>It is not a coincidence this problem appears both here and in **reinforcement learning** - both fall within the realm of **online learning** (when decisions and information are processed sequentially), the only thing separating them is the addition of states.</span>
<span id="cb8-182"><a href="#cb8-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-183"><a href="#cb8-183" aria-hidden="true" tabindex="-1"></a>We start with a simple algorithm that does the two stages separately <span class="co">[</span><span class="ot">@ji_online_2022, Lecture 14</span><span class="co">]</span>.</span>
<span id="cb8-184"><a href="#cb8-184" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb8-185"><a href="#cb8-185" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: alg-explore-exploit</span></span>
<span id="cb8-186"><a href="#cb8-186" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.8em"</span></span>
<span id="cb8-187"><a href="#cb8-187" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb8-188"><a href="#cb8-188" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb8-189"><a href="#cb8-189" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb8-190"><a href="#cb8-190" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb8-191"><a href="#cb8-191" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-&amp;number: true</span></span>
<span id="cb8-192"><a href="#cb8-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-193"><a href="#cb8-193" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb8-194"><a href="#cb8-194" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Explore-then-exploit}</span></span>
<span id="cb8-195"><a href="#cb8-195" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb8-196"><a href="#cb8-196" aria-hidden="true" tabindex="-1"></a><span class="in">\Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.}</span></span>
<span id="cb8-197"><a href="#cb8-197" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$t = 1, 2, \ldots$}</span></span>
<span id="cb8-198"><a href="#cb8-198" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Explore phase: try each arm $N$ times.</span></span>
<span id="cb8-199"><a href="#cb8-199" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Exploit phase: determine $\tilde{a}$ with the highest average reward; then play $\tilde{a}$ in all remaining rounds.</span></span>
<span id="cb8-200"><a href="#cb8-200" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb8-201"><a href="#cb8-201" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb8-202"><a href="#cb8-202" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb8-203"><a href="#cb8-203" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-204"><a href="#cb8-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-205"><a href="#cb8-205" aria-hidden="true" tabindex="-1"></a>We wish to bound the probability of getting good approximations on all arms, which we start by bounding each arm individually.</span>
<span id="cb8-206"><a href="#cb8-206" aria-hidden="true" tabindex="-1"></a>That is, we want to bound the deviation of its true mean $\mu(a)$ from its approximation $\hat{\mu}(a)$ after that arm has been pulled $N$ times.</span>
<span id="cb8-207"><a href="#cb8-207" aria-hidden="true" tabindex="-1"></a>Let $\beta_N = \sqrt{\frac{2 \log T}{N}}$, by <span class="co">[</span><span class="ot">Hoeffding's inequality</span><span class="co">](#thm-hoeffding)</span>,</span>
<span id="cb8-208"><a href="#cb8-208" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-209"><a href="#cb8-209" aria-hidden="true" tabindex="-1"></a>\mathrm{P}(|\hat{\mu}(a) - \mu(a)| \leq \beta_N) \geq 1 - 2 / T^4\ .</span>
<span id="cb8-210"><a href="#cb8-210" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp-arm}</span>
<span id="cb8-211"><a href="#cb8-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-212"><a href="#cb8-212" aria-hidden="true" tabindex="-1"></a>We define a *good event* $\mathcal{E}$ as the above being true for all arms, meaning that by the union bound</span>
<span id="cb8-213"><a href="#cb8-213" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-214"><a href="#cb8-214" aria-hidden="true" tabindex="-1"></a>\mathrm{P}(\mathcal{E}) = 1 - \mathrm{P}(\bar{\mathcal{E}}) \geq</span>
<span id="cb8-215"><a href="#cb8-215" aria-hidden="true" tabindex="-1"></a>1 - \sum_{a=1}^K \mathrm{P}(|\bar{\mu}(a) - \mu(a)| \geq \beta_N) \geq 1 - 2 K / T^4\ .</span>
<span id="cb8-216"><a href="#cb8-216" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp-good}</span>
<span id="cb8-217"><a href="#cb8-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-218"><a href="#cb8-218" aria-hidden="true" tabindex="-1"></a>Even if this good event occurs, we may still choose a suboptimal arm $\bar{a}$ in the exploit phase.</span>
<span id="cb8-219"><a href="#cb8-219" aria-hidden="true" tabindex="-1"></a>In that case, the estimate errors for both $\bar{a}$ and the optimal arm $a^*$ are bounded by $\beta_N$.</span>
<span id="cb8-220"><a href="#cb8-220" aria-hidden="true" tabindex="-1"></a>As such, $\mu(a^*) - \mu(\bar{a}) \leq 2 \beta_N$.</span>
<span id="cb8-221"><a href="#cb8-221" aria-hidden="true" tabindex="-1"></a>Adding with a max regret of $1$ for $KN$ round of exploration, the total incurred regret in the good case is at most </span>
<span id="cb8-222"><a href="#cb8-222" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-223"><a href="#cb8-223" aria-hidden="true" tabindex="-1"></a>\mathcal{R}_T \leq K N + (T - KN) \cdot 2 \beta_N \leq KN + 2 T \beta_N = KN + 2 T \sqrt{\frac{2 \log T}{N}}\ .</span>
<span id="cb8-224"><a href="#cb8-224" aria-hidden="true" tabindex="-1"></a>$$ {#eq-exp-regret-good}</span>
<span id="cb8-225"><a href="#cb8-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-226"><a href="#cb8-226" aria-hidden="true" tabindex="-1"></a>This also lets us derive a formula for $N$ which we do by setting the resulting terms equal.</span>
<span id="cb8-227"><a href="#cb8-227" aria-hidden="true" tabindex="-1"></a>In particular, $N = 2 \sqrt<span class="co">[</span><span class="ot">3</span><span class="co">]</span>{T^2 \log T / K^2}$, which leads to a good case regret of $\mathrm{O}(T^{2/3} (K \log T)^{1/3})$.</span>
<span id="cb8-228"><a href="#cb8-228" aria-hidden="true" tabindex="-1"></a>The bad event happens with probability at most $2 K / T^4$, which when multiplied by a max per-round regret of $1$ gets absorbed by the big O.</span>
<span id="cb8-229"><a href="#cb8-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-230"><a href="#cb8-230" aria-hidden="true" tabindex="-1"></a>For implementations of this and the following algorithms, we make a function <span class="in">`play`</span> that returns an arm <span class="in">`a`</span>, and a function <span class="in">`feedback`</span> that records the resulting reward <span class="in">`r`</span>.</span>
<span id="cb8-231"><a href="#cb8-231" aria-hidden="true" tabindex="-1"></a>Both functions are supplied with other contextual parameters for convenience.</span>
<span id="cb8-232"><a href="#cb8-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-235"><a href="#cb8-235" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-236"><a href="#cb8-236" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Code for Explore-then-exploit</span></span>
<span id="cb8-237"><a href="#cb8-237" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> log</span>
<span id="cb8-238"><a href="#cb8-238" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> argmax</span>
<span id="cb8-239"><a href="#cb8-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-240"><a href="#cb8-240" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ExploreExploit:</span>
<span id="cb8-241"><a href="#cb8-241" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, K, T):</span>
<span id="cb8-242"><a href="#cb8-242" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> K</span>
<span id="cb8-243"><a href="#cb8-243" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.N <span class="op">=</span> <span class="bu">round</span>(<span class="dv">2</span> <span class="op">*</span> (T<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> log(T) <span class="op">/</span> K<span class="op">**</span><span class="dv">2</span>)<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>))</span>
<span id="cb8-244"><a href="#cb8-244" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb8-245"><a href="#cb8-245" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-246"><a href="#cb8-246" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__str__</span>(<span class="va">self</span>):</span>
<span id="cb8-247"><a href="#cb8-247" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Explore-then-exploit"</span></span>
<span id="cb8-248"><a href="#cb8-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-249"><a href="#cb8-249" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> play(<span class="va">self</span>, t):</span>
<span id="cb8-250"><a href="#cb8-250" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Choose an arm to play.'''</span></span>
<span id="cb8-251"><a href="#cb8-251" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">&lt;=</span> <span class="va">self</span>.K<span class="op">*</span><span class="va">self</span>.N:</span>
<span id="cb8-252"><a href="#cb8-252" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Play each arm N times</span></span>
<span id="cb8-253"><a href="#cb8-253" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> t <span class="op">%</span> <span class="va">self</span>.K</span>
<span id="cb8-254"><a href="#cb8-254" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-255"><a href="#cb8-255" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Play best arm</span></span>
<span id="cb8-256"><a href="#cb8-256" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.best</span>
<span id="cb8-257"><a href="#cb8-257" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-258"><a href="#cb8-258" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedback(<span class="va">self</span>, t, a, r):</span>
<span id="cb8-259"><a href="#cb8-259" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Receive a reward.'''</span></span>
<span id="cb8-260"><a href="#cb8-260" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">&lt;=</span> <span class="va">self</span>.K<span class="op">*</span><span class="va">self</span>.N:</span>
<span id="cb8-261"><a href="#cb8-261" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Record reward</span></span>
<span id="cb8-262"><a href="#cb8-262" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.totals[a] <span class="op">+=</span> r</span>
<span id="cb8-263"><a href="#cb8-263" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t <span class="op">==</span> <span class="va">self</span>.K<span class="op">*</span><span class="va">self</span>.N:</span>
<span id="cb8-264"><a href="#cb8-264" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute best arm</span></span>
<span id="cb8-265"><a href="#cb8-265" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best <span class="op">=</span> argmax(<span class="va">self</span>.totals)</span>
<span id="cb8-266"><a href="#cb8-266" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-267"><a href="#cb8-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-268"><a href="#cb8-268" aria-hidden="true" tabindex="-1"></a><span class="fu">### Epsilon-greedy</span></span>
<span id="cb8-269"><a href="#cb8-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-270"><a href="#cb8-270" aria-hidden="true" tabindex="-1"></a>Instead of doing exploration all at once, we may spread it out over all rounds, making it less frequent over time <span class="co">[</span><span class="ot">@ji_online_2022, Lecture 14</span><span class="co">]</span>.</span>
<span id="cb8-271"><a href="#cb8-271" aria-hidden="true" tabindex="-1"></a>You'll see this strategy used quite frequently in reinforcement learning, as it is pretty simple to implement.</span>
<span id="cb8-272"><a href="#cb8-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-273"><a href="#cb8-273" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb8-274"><a href="#cb8-274" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: alg-epsilon-greedy</span></span>
<span id="cb8-275"><a href="#cb8-275" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.8em"</span></span>
<span id="cb8-276"><a href="#cb8-276" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb8-277"><a href="#cb8-277" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb8-278"><a href="#cb8-278" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb8-279"><a href="#cb8-279" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb8-280"><a href="#cb8-280" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-&amp;number: true</span></span>
<span id="cb8-281"><a href="#cb8-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-282"><a href="#cb8-282" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb8-283"><a href="#cb8-283" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Epsilon-greedy}</span></span>
<span id="cb8-284"><a href="#cb8-284" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb8-285"><a href="#cb8-285" aria-hidden="true" tabindex="-1"></a><span class="in">\Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.}</span></span>
<span id="cb8-286"><a href="#cb8-286" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$t = 1, 2, \ldots$}</span></span>
<span id="cb8-287"><a href="#cb8-287" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Toss a coin with success rate $\epsilon_t$.</span></span>
<span id="cb8-288"><a href="#cb8-288" aria-hidden="true" tabindex="-1"></a><span class="in">  \If{success}</span></span>
<span id="cb8-289"><a href="#cb8-289" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Explore: choose an arm uniformly at random.</span></span>
<span id="cb8-290"><a href="#cb8-290" aria-hidden="true" tabindex="-1"></a><span class="in">  \Else</span></span>
<span id="cb8-291"><a href="#cb8-291" aria-hidden="true" tabindex="-1"></a><span class="in">    \State Exploit: choose an arm with the highest average reward so far.</span></span>
<span id="cb8-292"><a href="#cb8-292" aria-hidden="true" tabindex="-1"></a><span class="in">  \EndIf</span></span>
<span id="cb8-293"><a href="#cb8-293" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb8-294"><a href="#cb8-294" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb8-295"><a href="#cb8-295" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb8-296"><a href="#cb8-296" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-297"><a href="#cb8-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-298"><a href="#cb8-298" aria-hidden="true" tabindex="-1"></a>With $\epsilon_t = t^{-1/3} (K \log t)^{1/3}$, Epsilon-greedy achieves the same regret bound, $\mathrm{O}(t^{2/3} (K \log t)^{1/3})$.</span>
<span id="cb8-299"><a href="#cb8-299" aria-hidden="true" tabindex="-1"></a>We won't show it here for brevity, but it uses the same techniques as shown, similarly relying on <span class="co">[</span><span class="ot">Hoeffding's inequality</span><span class="co">](#thm-hoeffding)</span>.</span>
<span id="cb8-300"><a href="#cb8-300" aria-hidden="true" tabindex="-1"></a>Note in addition that @alg-epsilon-greedy does not rely on $T$, which makes it an **anytime** algorithm.</span>
<span id="cb8-301"><a href="#cb8-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-304"><a href="#cb8-304" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-305"><a href="#cb8-305" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Code for Epsilon-greedy</span></span>
<span id="cb8-306"><a href="#cb8-306" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> math <span class="im">import</span> log</span>
<span id="cb8-307"><a href="#cb8-307" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> random, randrange</span>
<span id="cb8-308"><a href="#cb8-308" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> argmax, divide, errstate, inf, nan</span>
<span id="cb8-309"><a href="#cb8-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-310"><a href="#cb8-310" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EpsilonGreedy:</span>
<span id="cb8-311"><a href="#cb8-311" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, K, _):</span>
<span id="cb8-312"><a href="#cb8-312" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.K <span class="op">=</span> K</span>
<span id="cb8-313"><a href="#cb8-313" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb8-314"><a href="#cb8-314" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb8-315"><a href="#cb8-315" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-316"><a href="#cb8-316" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__str__</span>(<span class="va">self</span>):</span>
<span id="cb8-317"><a href="#cb8-317" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Epsilon-greedy"</span></span>
<span id="cb8-318"><a href="#cb8-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-319"><a href="#cb8-319" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _eps(<span class="va">self</span>, t):</span>
<span id="cb8-320"><a href="#cb8-320" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> (<span class="va">self</span>.K<span class="op">*</span>log(t)<span class="op">/</span>t)<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)</span>
<span id="cb8-321"><a href="#cb8-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-322"><a href="#cb8-322" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _best(<span class="va">self</span>):</span>
<span id="cb8-323"><a href="#cb8-323" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>, invalid<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb8-324"><a href="#cb8-324" aria-hidden="true" tabindex="-1"></a>            avg <span class="op">=</span> divide(<span class="va">self</span>.totals, <span class="va">self</span>.counts)</span>
<span id="cb8-325"><a href="#cb8-325" aria-hidden="true" tabindex="-1"></a>        avg[avg <span class="op">==</span> inf] <span class="op">=</span> <span class="op">-</span>inf</span>
<span id="cb8-326"><a href="#cb8-326" aria-hidden="true" tabindex="-1"></a>        avg[avg <span class="op">==</span> nan] <span class="op">=</span> <span class="op">-</span>inf</span>
<span id="cb8-327"><a href="#cb8-327" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> argmax(avg)</span>
<span id="cb8-328"><a href="#cb8-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-329"><a href="#cb8-329" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> play(<span class="va">self</span>, t):</span>
<span id="cb8-330"><a href="#cb8-330" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Choose an arm to play.'''</span></span>
<span id="cb8-331"><a href="#cb8-331" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> random() <span class="op">&lt;</span> <span class="va">self</span>._eps(t):</span>
<span id="cb8-332"><a href="#cb8-332" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Play random arm</span></span>
<span id="cb8-333"><a href="#cb8-333" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> randrange(<span class="va">self</span>.K)</span>
<span id="cb8-334"><a href="#cb8-334" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb8-335"><a href="#cb8-335" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Play best arm</span></span>
<span id="cb8-336"><a href="#cb8-336" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>._best()</span>
<span id="cb8-337"><a href="#cb8-337" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-338"><a href="#cb8-338" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedback(<span class="va">self</span>, t, a, r):</span>
<span id="cb8-339"><a href="#cb8-339" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Receive a reward.'''</span></span>
<span id="cb8-340"><a href="#cb8-340" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals[a] <span class="op">+=</span> r</span>
<span id="cb8-341"><a href="#cb8-341" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts[a] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-342"><a href="#cb8-342" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-343"><a href="#cb8-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-344"><a href="#cb8-344" aria-hidden="true" tabindex="-1"></a><span class="fu">### Successive elimination</span></span>
<span id="cb8-345"><a href="#cb8-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-346"><a href="#cb8-346" aria-hidden="true" tabindex="-1"></a>We can further incorporate the concept of means and confidence bounds into the algorithm by considering their values at any $t \in <span class="co">[</span><span class="ot">T</span><span class="co">]</span>$.</span>
<span id="cb8-347"><a href="#cb8-347" aria-hidden="true" tabindex="-1"></a>In particular,</span>
<span id="cb8-348"><a href="#cb8-348" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-349"><a href="#cb8-349" aria-hidden="true" tabindex="-1"></a>\mathrm{P} \left( |\hat{\mu}_t(a) - \mu(a)| \leq \beta_t(a) \right) \geq \sqrt{\frac{\log (2 K T / \delta)}{2 N_t (a)}}\ .</span>
<span id="cb8-350"><a href="#cb8-350" aria-hidden="true" tabindex="-1"></a>$$ {#eq-azuma}</span>
<span id="cb8-351"><a href="#cb8-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-352"><a href="#cb8-352" aria-hidden="true" tabindex="-1"></a>This feels very similar to Hoeffding's inequality, but actually requires a version generalized to <span class="co">[</span><span class="ot">martingales</span><span class="co">]</span>(https://en.wikipedia.org/wiki/Martingale_(probability_theory)), known as the <span class="co">[</span><span class="ot">Azuma-Hoeffding inequality</span><span class="co">](https://en.wikipedia.org/wiki/Azuma%27s_inequality)</span>.</span>
<span id="cb8-353"><a href="#cb8-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-354"><a href="#cb8-354" aria-hidden="true" tabindex="-1"></a>For convenience, we define <span class="co">[</span><span class="ot">@ji_online_2022, Lecture 14</span><span class="co">]</span></span>
<span id="cb8-355"><a href="#cb8-355" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-356"><a href="#cb8-356" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb8-357"><a href="#cb8-357" aria-hidden="true" tabindex="-1"></a>    \mathrm{UCB}_t(a) &amp;= \hat{\mu}_t(a) + \beta_t(a)\ ,<span class="sc">\\</span></span>
<span id="cb8-358"><a href="#cb8-358" aria-hidden="true" tabindex="-1"></a>    \mathrm{LCB}_t(a) &amp;= \hat{\mu}_t(a) - \beta_t(a)\ .</span>
<span id="cb8-359"><a href="#cb8-359" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb8-360"><a href="#cb8-360" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ucb}</span>
<span id="cb8-361"><a href="#cb8-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-362"><a href="#cb8-362" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb8-363"><a href="#cb8-363" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: alg-elimination</span></span>
<span id="cb8-364"><a href="#cb8-364" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.8em"</span></span>
<span id="cb8-365"><a href="#cb8-365" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb8-366"><a href="#cb8-366" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb8-367"><a href="#cb8-367" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb8-368"><a href="#cb8-368" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb8-369"><a href="#cb8-369" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-&amp;number: true</span></span>
<span id="cb8-370"><a href="#cb8-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-371"><a href="#cb8-371" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb8-372"><a href="#cb8-372" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{Successive Elimination}</span></span>
<span id="cb8-373"><a href="#cb8-373" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb8-374"><a href="#cb8-374" aria-hidden="true" tabindex="-1"></a><span class="in">\Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.}</span></span>
<span id="cb8-375"><a href="#cb8-375" aria-hidden="true" tabindex="-1"></a><span class="in">\State Initialize active arm set $\mathcal{A}_1 = [K]$.</span></span>
<span id="cb8-376"><a href="#cb8-376" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$p = 1, 2, \ldots$}</span></span>
<span id="cb8-377"><a href="#cb8-377" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Play each arm in $\mathcal{A}_p$ once.</span></span>
<span id="cb8-378"><a href="#cb8-378" aria-hidden="true" tabindex="-1"></a><span class="in">  \State Let $t$ be the time at the end of the current phase $p$.</span></span>
<span id="cb8-379"><a href="#cb8-379" aria-hidden="true" tabindex="-1"></a><span class="in">  \State $\mathcal{A}_{p+1} = \{ a \in \mathcal{A}_p : \mathrm{UCB}_t (a) \geq \max_{a' \in \mathcal{A}_p} \mathrm{LCB}_t (a) \}$</span></span>
<span id="cb8-380"><a href="#cb8-380" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb8-381"><a href="#cb8-381" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb8-382"><a href="#cb8-382" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb8-383"><a href="#cb8-383" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-384"><a href="#cb8-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-385"><a href="#cb8-385" aria-hidden="true" tabindex="-1"></a>We define the good event as before, and assume that it holds.</span>
<span id="cb8-386"><a href="#cb8-386" aria-hidden="true" tabindex="-1"></a>If we at some point eliminate $a^*$, it means $\mathrm{UCB}_t(a^*) &lt; \mathrm{LCB}_t(a')$ for some other arm $a'$, implying $\mu(a^*) &lt; \mu(a')$ and thus a contradiction.</span>
<span id="cb8-387"><a href="#cb8-387" aria-hidden="true" tabindex="-1"></a>Then, assume there is some arm $a \in \mathcal{A}_{p+1}$ during phase $p$ ending at time $t$ such that $\mu(a^*) - \mu(a) &gt; 4 \beta_t(a)$.</span>
<span id="cb8-388"><a href="#cb8-388" aria-hidden="true" tabindex="-1"></a>Then,</span>
<span id="cb8-389"><a href="#cb8-389" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-390"><a href="#cb8-390" aria-hidden="true" tabindex="-1"></a>\mathrm{LCB}_t(a) \leq \mu(a) + 2 \beta_t(a) &lt; \mu(a^*) - 2 \beta_t(a^*) \leq \mathrm{UCB}_t(a^*)\ ,</span>
<span id="cb8-391"><a href="#cb8-391" aria-hidden="true" tabindex="-1"></a>$$ {#eq-elimination1}</span>
<span id="cb8-392"><a href="#cb8-392" aria-hidden="true" tabindex="-1"></a>implying that this arm should have been eliminated.</span>
<span id="cb8-393"><a href="#cb8-393" aria-hidden="true" tabindex="-1"></a>Thus, the regret contributed by arm $a$ is</span>
<span id="cb8-394"><a href="#cb8-394" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-395"><a href="#cb8-395" aria-hidden="true" tabindex="-1"></a>\mathcal{R}_{a,t} \leq 4 N_t(a) \sqrt{\frac{\log(2 K T / \delta)}{2 N_t(a)}} = \mathrm{O}(\sqrt{N_t(a) \log(K T / \delta)})\ .</span>
<span id="cb8-396"><a href="#cb8-396" aria-hidden="true" tabindex="-1"></a>$$ {#eq-elimination2}</span>
<span id="cb8-397"><a href="#cb8-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-398"><a href="#cb8-398" aria-hidden="true" tabindex="-1"></a>Using the Cauchy-Schwarz inequality, $\sum_a \sqrt{N_t(a)} \leq \sqrt{\sum_a N_t (a) \cdot \sum_a 1} =  \sqrt{t K}$, meaning</span>
<span id="cb8-399"><a href="#cb8-399" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-400"><a href="#cb8-400" aria-hidden="true" tabindex="-1"></a>\mathcal{R}_t = \sum_{a \in [K]} \mathcal{R}_{a,t} = \mathrm{O}(\sqrt{\log(K T / \delta)}) \cdot \sum_a \sqrt{N_t(a)} \leq \mathrm{O}(\sqrt{K t \log (K T / \delta)})\ .</span>
<span id="cb8-401"><a href="#cb8-401" aria-hidden="true" tabindex="-1"></a>$$ {#eq-elimination3}</span>
<span id="cb8-402"><a href="#cb8-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-403"><a href="#cb8-403" aria-hidden="true" tabindex="-1"></a>We thus have that $\mathcal{R}_T = \mathrm{O}(\sqrt{K T \log (K T / \delta)})$.</span>
<span id="cb8-404"><a href="#cb8-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-405"><a href="#cb8-405" aria-hidden="true" tabindex="-1"></a>Note that the above bounds have a configurable value $\delta \in (0, 1]$, which makes them take effect with probability at least $1 - \delta$.</span>
<span id="cb8-406"><a href="#cb8-406" aria-hidden="true" tabindex="-1"></a>In practice, we need to set <span class="in">`delta`</span> to a ridiculously high value for any arms to actually become eliminated within a reasonable amount of time.</span>
<span id="cb8-407"><a href="#cb8-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-410"><a href="#cb8-410" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-411"><a href="#cb8-411" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Code for Successive elimination</span></span>
<span id="cb8-412"><a href="#cb8-412" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> random, randrange</span>
<span id="cb8-413"><a href="#cb8-413" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> argmax, divide, errstate, inf, nan, log, sqrt</span>
<span id="cb8-414"><a href="#cb8-414" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-415"><a href="#cb8-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-416"><a href="#cb8-416" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SuccessiveElimination:</span>
<span id="cb8-417"><a href="#cb8-417" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, K, T, delta<span class="op">=</span><span class="dv">1500</span>):</span>
<span id="cb8-418"><a href="#cb8-418" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num <span class="op">=</span> log(<span class="dv">2</span> <span class="op">*</span> K <span class="op">*</span> T <span class="op">/</span> delta) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb8-419"><a href="#cb8-419" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="va">self</span>.num <span class="op">&gt;</span> <span class="dv">0</span>, <span class="st">"delta too large"</span></span>
<span id="cb8-420"><a href="#cb8-420" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb8-421"><a href="#cb8-421" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb8-422"><a href="#cb8-422" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.A <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(K))</span>
<span id="cb8-423"><a href="#cb8-423" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-424"><a href="#cb8-424" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-425"><a href="#cb8-425" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__str__</span>(<span class="va">self</span>):</span>
<span id="cb8-426"><a href="#cb8-426" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"Successive elimination"</span></span>
<span id="cb8-427"><a href="#cb8-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-428"><a href="#cb8-428" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _mu(<span class="va">self</span>):</span>
<span id="cb8-429"><a href="#cb8-429" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>, invalid<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb8-430"><a href="#cb8-430" aria-hidden="true" tabindex="-1"></a>            mu <span class="op">=</span> divide(<span class="va">self</span>.totals, <span class="va">self</span>.counts)</span>
<span id="cb8-431"><a href="#cb8-431" aria-hidden="true" tabindex="-1"></a>        mu[mu <span class="op">==</span> inf] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-432"><a href="#cb8-432" aria-hidden="true" tabindex="-1"></a>        mu[mu <span class="op">==</span> nan] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-433"><a href="#cb8-433" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mu</span>
<span id="cb8-434"><a href="#cb8-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-435"><a href="#cb8-435" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _beta(<span class="va">self</span>):</span>
<span id="cb8-436"><a href="#cb8-436" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb8-437"><a href="#cb8-437" aria-hidden="true" tabindex="-1"></a>            beta <span class="op">=</span> sqrt(divide(<span class="va">self</span>.num, <span class="va">self</span>.counts))</span>
<span id="cb8-438"><a href="#cb8-438" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> beta</span>
<span id="cb8-439"><a href="#cb8-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-440"><a href="#cb8-440" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> play(<span class="va">self</span>, t):</span>
<span id="cb8-441"><a href="#cb8-441" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Choose an arm to play.'''</span></span>
<span id="cb8-442"><a href="#cb8-442" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.idx <span class="op">==</span> <span class="bu">len</span>(<span class="va">self</span>.A):</span>
<span id="cb8-443"><a href="#cb8-443" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update arm set A</span></span>
<span id="cb8-444"><a href="#cb8-444" aria-hidden="true" tabindex="-1"></a>            u, b <span class="op">=</span> <span class="va">self</span>._mu(), <span class="va">self</span>._beta()</span>
<span id="cb8-445"><a href="#cb8-445" aria-hidden="true" tabindex="-1"></a>            lcb, ucb <span class="op">=</span> u<span class="op">-</span>b, u<span class="op">+</span>b</span>
<span id="cb8-446"><a href="#cb8-446" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.A <span class="op">=</span> [a <span class="cf">for</span> a <span class="kw">in</span> <span class="va">self</span>.A <span class="cf">if</span> ucb[a] <span class="op">&gt;=</span> np.<span class="bu">max</span>(lcb)]</span>
<span id="cb8-447"><a href="#cb8-447" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.idx <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-448"><a href="#cb8-448" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Play each arm in A</span></span>
<span id="cb8-449"><a href="#cb8-449" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> <span class="va">self</span>.A[<span class="va">self</span>.idx]</span>
<span id="cb8-450"><a href="#cb8-450" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.idx <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-451"><a href="#cb8-451" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a</span>
<span id="cb8-452"><a href="#cb8-452" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-453"><a href="#cb8-453" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedback(<span class="va">self</span>, t, a, r):</span>
<span id="cb8-454"><a href="#cb8-454" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Receive a reward.'''</span></span>
<span id="cb8-455"><a href="#cb8-455" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals[a] <span class="op">+=</span> r</span>
<span id="cb8-456"><a href="#cb8-456" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts[a] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-457"><a href="#cb8-457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-458"><a href="#cb8-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-459"><a href="#cb8-459" aria-hidden="true" tabindex="-1"></a><span class="fu">### UCB</span></span>
<span id="cb8-460"><a href="#cb8-460" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-461"><a href="#cb8-461" aria-hidden="true" tabindex="-1"></a>Since the event of eliminating an arm may be quite rare, we may instead just sample the arm with the highest $\mathrm{UCB}_t(a)$.</span>
<span id="cb8-462"><a href="#cb8-462" aria-hidden="true" tabindex="-1"></a>This strategy demonstrates a principle known as *optimism in the face of uncertainty* <span class="co">[</span><span class="ot">@ji_online_2022, Lecture 15</span><span class="co">]</span> - that is, both arms that have high sample mean and arms with fewer samples will have a larger UCB and thus more likely to get chosen.</span>
<span id="cb8-463"><a href="#cb8-463" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb8-464"><a href="#cb8-464" aria-hidden="true" tabindex="-1"></a><span class="in">#| label: alg-ucb</span></span>
<span id="cb8-465"><a href="#cb8-465" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.8em"</span></span>
<span id="cb8-466"><a href="#cb8-466" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb8-467"><a href="#cb8-467" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb8-468"><a href="#cb8-468" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb8-469"><a href="#cb8-469" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb8-470"><a href="#cb8-470" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-&amp;number: true</span></span>
<span id="cb8-471"><a href="#cb8-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-472"><a href="#cb8-472" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb8-473"><a href="#cb8-473" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{UCB}</span></span>
<span id="cb8-474"><a href="#cb8-474" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb8-475"><a href="#cb8-475" aria-hidden="true" tabindex="-1"></a><span class="in">\Require{$K$ and $T$ (both known), unknown reward distributions $\mathcal{D}_a$.}</span></span>
<span id="cb8-476"><a href="#cb8-476" aria-hidden="true" tabindex="-1"></a><span class="in">\For{$t = 1, 2, \ldots$}</span></span>
<span id="cb8-477"><a href="#cb8-477" aria-hidden="true" tabindex="-1"></a><span class="in">  \State $a_t = \arg\max_{a \in [K]} \mathrm{UCB}_t (a)$</span></span>
<span id="cb8-478"><a href="#cb8-478" aria-hidden="true" tabindex="-1"></a><span class="in">\EndFor</span></span>
<span id="cb8-479"><a href="#cb8-479" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb8-480"><a href="#cb8-480" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb8-481"><a href="#cb8-481" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-482"><a href="#cb8-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-483"><a href="#cb8-483" aria-hidden="true" tabindex="-1"></a>Similar to before, $\mu(a^*) - \mu(a_t) \leq 2 \beta_t (a_t)$ in the good event.</span>
<span id="cb8-484"><a href="#cb8-484" aria-hidden="true" tabindex="-1"></a>We thus have</span>
<span id="cb8-485"><a href="#cb8-485" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-486"><a href="#cb8-486" aria-hidden="true" tabindex="-1"></a>\mathcal{R}_T = \sum_{t=1}^T r_t \leq c \sqrt{\log (2 K T / \delta)} \sum_{t=1}^T \sqrt{\frac{1}{N_t(a_t)}}\ ,</span>
<span id="cb8-487"><a href="#cb8-487" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ucb1}</span>
<span id="cb8-488"><a href="#cb8-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-489"><a href="#cb8-489" aria-hidden="true" tabindex="-1"></a>where the latter summation is bounded by</span>
<span id="cb8-490"><a href="#cb8-490" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-491"><a href="#cb8-491" aria-hidden="true" tabindex="-1"></a>\sum_{t=1}^T \sqrt{\frac{1}{N_t(a_t)}} = \sum_{a=1}^K \sum_{m=1}^{N_T(a)} \sqrt{1/m} \leq c' \sum_{a=1}^K \sqrt{N_T(a)} = \mathrm{O}(\sqrt{K T})\ .</span>
<span id="cb8-492"><a href="#cb8-492" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ucb2}</span>
<span id="cb8-493"><a href="#cb8-493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-494"><a href="#cb8-494" aria-hidden="true" tabindex="-1"></a>Thus, the regret of <span class="co">[</span><span class="ot">UCB</span><span class="co">](#alg-ucb)</span> is $\mathrm{O}(\sqrt{K T \log (K T / \delta)})$.</span>
<span id="cb8-495"><a href="#cb8-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-498"><a href="#cb8-498" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-499"><a href="#cb8-499" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Code for UCB</span></span>
<span id="cb8-500"><a href="#cb8-500" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> random, randrange</span>
<span id="cb8-501"><a href="#cb8-501" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> argmax, divide, errstate, inf, nan, log, sqrt</span>
<span id="cb8-502"><a href="#cb8-502" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-503"><a href="#cb8-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-504"><a href="#cb8-504" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> UCB:</span>
<span id="cb8-505"><a href="#cb8-505" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, K, T, delta<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb8-506"><a href="#cb8-506" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num <span class="op">=</span> log(<span class="dv">2</span> <span class="op">*</span> K <span class="op">*</span> T <span class="op">/</span> delta) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb8-507"><a href="#cb8-507" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="va">self</span>.num <span class="op">&gt;</span> <span class="dv">0</span>, <span class="st">"delta too large"</span></span>
<span id="cb8-508"><a href="#cb8-508" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb8-509"><a href="#cb8-509" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts <span class="op">=</span> [<span class="dv">0</span>] <span class="op">*</span> K</span>
<span id="cb8-510"><a href="#cb8-510" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-511"><a href="#cb8-511" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__str__</span>(<span class="va">self</span>):</span>
<span id="cb8-512"><a href="#cb8-512" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="st">"UCB"</span></span>
<span id="cb8-513"><a href="#cb8-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-514"><a href="#cb8-514" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _mu(<span class="va">self</span>):</span>
<span id="cb8-515"><a href="#cb8-515" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>, invalid<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb8-516"><a href="#cb8-516" aria-hidden="true" tabindex="-1"></a>            mu <span class="op">=</span> divide(<span class="va">self</span>.totals, <span class="va">self</span>.counts)</span>
<span id="cb8-517"><a href="#cb8-517" aria-hidden="true" tabindex="-1"></a>        mu[mu <span class="op">==</span> inf] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-518"><a href="#cb8-518" aria-hidden="true" tabindex="-1"></a>        mu[mu <span class="op">==</span> nan] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-519"><a href="#cb8-519" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> mu</span>
<span id="cb8-520"><a href="#cb8-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-521"><a href="#cb8-521" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _beta(<span class="va">self</span>):</span>
<span id="cb8-522"><a href="#cb8-522" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> errstate(divide<span class="op">=</span><span class="st">'ignore'</span>):</span>
<span id="cb8-523"><a href="#cb8-523" aria-hidden="true" tabindex="-1"></a>            beta <span class="op">=</span> sqrt(divide(<span class="va">self</span>.num, <span class="va">self</span>.counts))</span>
<span id="cb8-524"><a href="#cb8-524" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> beta</span>
<span id="cb8-525"><a href="#cb8-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-526"><a href="#cb8-526" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> play(<span class="va">self</span>, t):</span>
<span id="cb8-527"><a href="#cb8-527" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Choose an arm to play.'''</span></span>
<span id="cb8-528"><a href="#cb8-528" aria-hidden="true" tabindex="-1"></a>        ucb <span class="op">=</span> <span class="va">self</span>._mu() <span class="op">+</span> <span class="va">self</span>._beta()</span>
<span id="cb8-529"><a href="#cb8-529" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> argmax(ucb)</span>
<span id="cb8-530"><a href="#cb8-530" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb8-531"><a href="#cb8-531" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> feedback(<span class="va">self</span>, t, a, r):</span>
<span id="cb8-532"><a href="#cb8-532" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''Receive a reward.'''</span></span>
<span id="cb8-533"><a href="#cb8-533" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.totals[a] <span class="op">+=</span> r</span>
<span id="cb8-534"><a href="#cb8-534" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counts[a] <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb8-535"><a href="#cb8-535" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-536"><a href="#cb8-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-537"><a href="#cb8-537" aria-hidden="true" tabindex="-1"></a><span class="fu">### Summary</span></span>
<span id="cb8-538"><a href="#cb8-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-539"><a href="#cb8-539" aria-hidden="true" tabindex="-1"></a>Here is a compilation of the derived bounds so far:</span>
<span id="cb8-540"><a href="#cb8-540" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-541"><a href="#cb8-541" aria-hidden="true" tabindex="-1"></a>| Algorithm | Regret | Anytime |</span>
<span id="cb8-542"><a href="#cb8-542" aria-hidden="true" tabindex="-1"></a>|-----------|--------|---------|</span>
<span id="cb8-543"><a href="#cb8-543" aria-hidden="true" tabindex="-1"></a>| <span class="co">[</span><span class="ot">Explore-then-exploit</span><span class="co">](#alg-explore-exploit)</span> | $\mathrm{O}(T^{2/3} (K \log T)^{1/3})$ | âŒ |</span>
<span id="cb8-544"><a href="#cb8-544" aria-hidden="true" tabindex="-1"></a>| <span class="co">[</span><span class="ot">Epsilon-greedy</span><span class="co">](#alg-epsilon-greedy)</span> | $\mathrm{O}(t^{2/3} (K \log t)^{1/3})$ | âœ… |</span>
<span id="cb8-545"><a href="#cb8-545" aria-hidden="true" tabindex="-1"></a>| <span class="co">[</span><span class="ot">Successive elimination</span><span class="co">](#alg-elimination)</span> | $\mathrm{O}(\sqrt{K T \log (K T / \delta)})$ | âŒ |</span>
<span id="cb8-546"><a href="#cb8-546" aria-hidden="true" tabindex="-1"></a>| <span class="co">[</span><span class="ot">UCB</span><span class="co">](#alg-ucb)</span> | $\mathrm{O}(\sqrt{K T \log (K T / \delta)})$ | âŒ |</span>
<span id="cb8-547"><a href="#cb8-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-548"><a href="#cb8-548" aria-hidden="true" tabindex="-1"></a>: Summary of theoretic regret bounds.</span>
<span id="cb8-549"><a href="#cb8-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-550"><a href="#cb8-550" aria-hidden="true" tabindex="-1"></a>On a final note, the above bounds are all problem-independent.</span>
<span id="cb8-551"><a href="#cb8-551" aria-hidden="true" tabindex="-1"></a>We can instead derive *problem-dependent* bounds, such as</span>
<span id="cb8-552"><a href="#cb8-552" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-553"><a href="#cb8-553" aria-hidden="true" tabindex="-1"></a>\mathcal{R}_T = \sum_{a : \Delta(a) &gt; 0} \mathrm{O} \left( \frac{\log(K T / \delta)}{\delta(a)} \right)\ ,</span>
<span id="cb8-554"><a href="#cb8-554" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ucb-prob}</span>
<span id="cb8-555"><a href="#cb8-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-556"><a href="#cb8-556" aria-hidden="true" tabindex="-1"></a>for <span class="co">[</span><span class="ot">UCB</span><span class="co">](#alg-ucb)</span>, where $\Delta(a) \coloneqq \mu(a^*) - \mu(a)$.</span>
<span id="cb8-557"><a href="#cb8-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-558"><a href="#cb8-558" aria-hidden="true" tabindex="-1"></a><span class="fu">### Simulation</span></span>
<span id="cb8-559"><a href="#cb8-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-560"><a href="#cb8-560" aria-hidden="true" tabindex="-1"></a>Now, it's time to put the algorithms to the test!</span>
<span id="cb8-561"><a href="#cb8-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-562"><a href="#cb8-562" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Technical note</span></span>
<span id="cb8-563"><a href="#cb8-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-564"><a href="#cb8-564" aria-hidden="true" tabindex="-1"></a>But first, a small note on the simulation details.</span>
<span id="cb8-565"><a href="#cb8-565" aria-hidden="true" tabindex="-1"></a>As the rewards (and thus performance) are highly stochastic, we will need to run many trials to get an accurate result.</span>
<span id="cb8-566"><a href="#cb8-566" aria-hidden="true" tabindex="-1"></a>Even when results are recorded once every <span class="in">`F`</span> steps, we still run into situations where the times for storing and churning data may compete with those of running the algorithms.</span>
<span id="cb8-567"><a href="#cb8-567" aria-hidden="true" tabindex="-1"></a>We have several possible approaches:</span>
<span id="cb8-568"><a href="#cb8-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-569"><a href="#cb8-569" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>*Store them all:* pre-allocate a huge array, and process it once afterwards.</span>
<span id="cb8-570"><a href="#cb8-570" aria-hidden="true" tabindex="-1"></a>  This understandably causes slowdowns.</span>
<span id="cb8-571"><a href="#cb8-571" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>*Aggregate last:* i.e., iterate over algorithms and timesteps first, then trials.</span>
<span id="cb8-572"><a href="#cb8-572" aria-hidden="true" tabindex="-1"></a>  This may seem like a perfect solution at first, but it runs into a caveat of the algorithms storing internal parameters.</span>
<span id="cb8-573"><a href="#cb8-573" aria-hidden="true" tabindex="-1"></a>  That is, algorithms from some runs will have more information about certain arms than others, so we can't just re-sample the same instance many times.</span>
<span id="cb8-574"><a href="#cb8-574" aria-hidden="true" tabindex="-1"></a>  The way to address this would involve storing an array of algorithms proportional to the number of trials, which is again inefficient.</span>
<span id="cb8-575"><a href="#cb8-575" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>*Online aggregation:* iterate over trials first, and store a statistic for each algorithm/timestep.</span>
<span id="cb8-576"><a href="#cb8-576" aria-hidden="true" tabindex="-1"></a>  The way we avoid having a separate dimension for trials is via an approximation algorithm that aggregates statistics as they come in - <span class="co">[</span><span class="ot">Welford's online algorithm</span><span class="co">](https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm)</span>.</span>
<span id="cb8-577"><a href="#cb8-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-578"><a href="#cb8-578" aria-hidden="true" tabindex="-1"></a>We will use the latter approach, which is what lets us compute 1000 samples for each data point.</span>
<span id="cb8-579"><a href="#cb8-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-582"><a href="#cb8-582" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-583"><a href="#cb8-583" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb8-584"><a href="#cb8-584" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Seed random number generators</span></span>
<span id="cb8-585"><a href="#cb8-585" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> seed <span class="im">as</span> py_seed</span>
<span id="cb8-586"><a href="#cb8-586" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> seed <span class="im">as</span> np_seed</span>
<span id="cb8-587"><a href="#cb8-587" aria-hidden="true" tabindex="-1"></a>py_seed(<span class="dv">5805</span>)</span>
<span id="cb8-588"><a href="#cb8-588" aria-hidden="true" tabindex="-1"></a>np_seed(<span class="dv">5805</span>)</span>
<span id="cb8-589"><a href="#cb8-589" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-590"><a href="#cb8-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-591"><a href="#cb8-591" aria-hidden="true" tabindex="-1"></a>In particular, we will simulate having to choose between $K=2$ arms:</span>
<span id="cb8-592"><a href="#cb8-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-593"><a href="#cb8-593" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>A uniform distribution on $<span class="co">[</span><span class="ot">0,1</span><span class="co">]</span>$, i.e., mean $0.5$ and standard deviation $\sqrt{1/12} \approx 0.29$.</span>
<span id="cb8-594"><a href="#cb8-594" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>A normal distribution with mean $0.6$ and standard deviation $0.2$.</span>
<span id="cb8-595"><a href="#cb8-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-596"><a href="#cb8-596" aria-hidden="true" tabindex="-1"></a>The above statistics indicate that arm 2 is more optimal, but arm 1 has a wider distribution of rewards.</span>
<span id="cb8-597"><a href="#cb8-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-600"><a href="#cb8-600" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-601"><a href="#cb8-601" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: Simulation code</span></span>
<span id="cb8-602"><a href="#cb8-602" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> random <span class="im">import</span> random</span>
<span id="cb8-603"><a href="#cb8-603" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> normal</span>
<span id="cb8-604"><a href="#cb8-604" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy <span class="im">import</span> zeros, sqrt</span>
<span id="cb8-605"><a href="#cb8-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-606"><a href="#cb8-606" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulation parameters</span></span>
<span id="cb8-607"><a href="#cb8-607" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="dv">1000</span>    <span class="co"># Number of rounds</span></span>
<span id="cb8-608"><a href="#cb8-608" aria-hidden="true" tabindex="-1"></a>F <span class="op">=</span> <span class="dv">10</span>      <span class="co"># Logging frequency</span></span>
<span id="cb8-609"><a href="#cb8-609" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="dv">1000</span>    <span class="co"># Number of trials</span></span>
<span id="cb8-610"><a href="#cb8-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-611"><a href="#cb8-611" aria-hidden="true" tabindex="-1"></a><span class="co"># Arms to explore</span></span>
<span id="cb8-612"><a href="#cb8-612" aria-hidden="true" tabindex="-1"></a>means <span class="op">=</span> [<span class="fl">0.5</span>, <span class="fl">0.6</span>]</span>
<span id="cb8-613"><a href="#cb8-613" aria-hidden="true" tabindex="-1"></a>best <span class="op">=</span> <span class="bu">max</span>(means)</span>
<span id="cb8-614"><a href="#cb8-614" aria-hidden="true" tabindex="-1"></a>arms <span class="op">=</span> [random, <span class="kw">lambda</span>: normal(means[<span class="dv">1</span>], <span class="fl">0.2</span>, <span class="dv">1</span>).item()]</span>
<span id="cb8-615"><a href="#cb8-615" aria-hidden="true" tabindex="-1"></a>K <span class="op">=</span> <span class="bu">len</span>(arms)</span>
<span id="cb8-616"><a href="#cb8-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-617"><a href="#cb8-617" aria-hidden="true" tabindex="-1"></a><span class="co"># Algorithms to use</span></span>
<span id="cb8-618"><a href="#cb8-618" aria-hidden="true" tabindex="-1"></a>cs <span class="op">=</span> [ExploreExploit, EpsilonGreedy, SuccessiveElimination, UCB]</span>
<span id="cb8-619"><a href="#cb8-619" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> <span class="bu">len</span>(cs)</span>
<span id="cb8-620"><a href="#cb8-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-621"><a href="#cb8-621" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate algorithms</span></span>
<span id="cb8-622"><a href="#cb8-622" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> zeros((T<span class="op">//</span>F<span class="op">+</span><span class="dv">1</span>, A))</span>
<span id="cb8-623"><a href="#cb8-623" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> zeros((T<span class="op">//</span>F<span class="op">+</span><span class="dv">1</span>, A))</span>
<span id="cb8-624"><a href="#cb8-624" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> n <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, N<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb8-625"><a href="#cb8-625" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, c <span class="kw">in</span> <span class="bu">enumerate</span>(cs):</span>
<span id="cb8-626"><a href="#cb8-626" aria-hidden="true" tabindex="-1"></a>        alg <span class="op">=</span> c(K, T)</span>
<span id="cb8-627"><a href="#cb8-627" aria-hidden="true" tabindex="-1"></a>        rgt <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb8-628"><a href="#cb8-628" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, T<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb8-629"><a href="#cb8-629" aria-hidden="true" tabindex="-1"></a>            a <span class="op">=</span> alg.play(t)</span>
<span id="cb8-630"><a href="#cb8-630" aria-hidden="true" tabindex="-1"></a>            r <span class="op">=</span> arms[a]()</span>
<span id="cb8-631"><a href="#cb8-631" aria-hidden="true" tabindex="-1"></a>            alg.feedback(t, a, r)</span>
<span id="cb8-632"><a href="#cb8-632" aria-hidden="true" tabindex="-1"></a>            rgt <span class="op">+=</span> best <span class="op">-</span> r</span>
<span id="cb8-633"><a href="#cb8-633" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> t <span class="op">%</span> F <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb8-634"><a href="#cb8-634" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Welford's online algorithm</span></span>
<span id="cb8-635"><a href="#cb8-635" aria-hidden="true" tabindex="-1"></a>                xn1 <span class="op">=</span> x[t<span class="op">//</span>F, i]</span>
<span id="cb8-636"><a href="#cb8-636" aria-hidden="true" tabindex="-1"></a>                x[t<span class="op">//</span>F, i] <span class="op">=</span> ((n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>xn1 <span class="op">+</span> rgt) <span class="op">/</span> n</span>
<span id="cb8-637"><a href="#cb8-637" aria-hidden="true" tabindex="-1"></a>                s[t<span class="op">//</span>F, i] <span class="op">+=</span> (rgt <span class="op">-</span> xn1) <span class="op">*</span> (rgt <span class="op">-</span> x[t<span class="op">//</span>F, i])</span>
<span id="cb8-638"><a href="#cb8-638" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="fl">0.2</span><span class="op">*</span>sqrt(s <span class="op">/</span> (N<span class="op">-</span><span class="dv">1</span>))</span>
<span id="cb8-639"><a href="#cb8-639" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-640"><a href="#cb8-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-641"><a href="#cb8-641" aria-hidden="true" tabindex="-1"></a>We now plot the mean regret $\mathcal{R}_t$ of each algorithm, as well as the $\pm 0.2$ sample standard deviation margins.</span>
<span id="cb8-642"><a href="#cb8-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-645"><a href="#cb8-645" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb8-646"><a href="#cb8-646" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb8-647"><a href="#cb8-647" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-summary: "Code for plotting regret"</span></span>
<span id="cb8-648"><a href="#cb8-648" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-line</span></span>
<span id="cb8-649"><a href="#cb8-649" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Performance of MAB algorithms"</span></span>
<span id="cb8-650"><a href="#cb8-650" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb8-651"><a href="#cb8-651" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb8-652"><a href="#cb8-652" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-653"><a href="#cb8-653" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> np.arange(<span class="dv">1</span>, T<span class="op">+</span><span class="dv">2</span>, F)</span>
<span id="cb8-654"><a href="#cb8-654" aria-hidden="true" tabindex="-1"></a>plt.plot(t, x)</span>
<span id="cb8-655"><a href="#cb8-655" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(A):</span>
<span id="cb8-656"><a href="#cb8-656" aria-hidden="true" tabindex="-1"></a>    plt.fill_between(t, x[:,i]<span class="op">-</span>s[:,i], x[:,i]<span class="op">+</span>s[:,i], alpha<span class="op">=</span><span class="fl">.15</span>)</span>
<span id="cb8-657"><a href="#cb8-657" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Timestep"</span>)</span>
<span id="cb8-658"><a href="#cb8-658" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Regret"</span>)</span>
<span id="cb8-659"><a href="#cb8-659" aria-hidden="true" tabindex="-1"></a>plt.legend([c(K, T) <span class="cf">for</span> c <span class="kw">in</span> cs])<span class="op">;</span></span>
<span id="cb8-660"><a href="#cb8-660" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-661"><a href="#cb8-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-662"><a href="#cb8-662" aria-hidden="true" tabindex="-1"></a>The above performance roughly matches what we should expect.</span>
<span id="cb8-663"><a href="#cb8-663" aria-hidden="true" tabindex="-1"></a>Most notably, <span class="co">[</span><span class="ot">Explore-then-exploit</span><span class="co">](#alg-explore-exploit)</span> accumulates linear regret until a certain time, where it sharply switches to exploitation and plateus.</span>
<span id="cb8-664"><a href="#cb8-664" aria-hidden="true" tabindex="-1"></a>The other algorithms gently bend down towards it instead, allowing them to achieve lower final regrets.</span>
<span id="cb8-665"><a href="#cb8-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-666"><a href="#cb8-666" aria-hidden="true" tabindex="-1"></a>Note that the above shouldn't be used as a definitive guide for how the algorithms compare, as it's specific to the problem instance and algorithm parameters.</span>
<span id="cb8-667"><a href="#cb8-667" aria-hidden="true" tabindex="-1"></a>In particular, the performance of <span class="co">[</span><span class="ot">Successive elimination</span><span class="co">](#alg-elimination)</span> is highly dependent on its artificial parameter $\delta = 1500$, as it determines how soon the trend starts bending toward a plateu.</span>
<span id="cb8-668"><a href="#cb8-668" aria-hidden="true" tabindex="-1"></a>Still, it may give an indication as to why the <span class="co">[</span><span class="ot">UCB</span><span class="co">](#alg-ucb)</span> algorithm and its variants are so common in practice.</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
    <footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/adidenkova/blog/blob/main/posts/1-probability.qmd" class="toc-action"><i class="bi bi-github"></i>View source</a></li></ul></div></div></div></footer><script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.algTitle || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        titlePrefix = el.dataset.algTitle;
        titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
        titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
      });
    })(document);
    </script>
  




</body></html>